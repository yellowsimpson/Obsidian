{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "98a2037ccf1545fca22ea805231b7ba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_53fd9d1ccebc476f8c3e15faa471dc6e",
              "IPY_MODEL_6f729b57260c43f2aa1021bfb89c053d",
              "IPY_MODEL_8d7a65f840014a1baabad80534da7c9a"
            ],
            "layout": "IPY_MODEL_8abeff0d76854586b4971ce9d9285c93"
          }
        },
        "53fd9d1ccebc476f8c3e15faa471dc6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d32f548730da4720afd6d9a93f46d5aa",
            "placeholder": "​",
            "style": "IPY_MODEL_f4f451b672e94472b4016dcafc0daa23",
            "value": "100%"
          }
        },
        "6f729b57260c43f2aa1021bfb89c053d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76239392347f480298fc2bd341704c41",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f25f92b9748d41a496a74489fe472ec7",
            "value": 2
          }
        },
        "8d7a65f840014a1baabad80534da7c9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dda12fc624b446c98cfcb1dc76c93453",
            "placeholder": "​",
            "style": "IPY_MODEL_4cca8a25ec5b4d548ddc324722412b85",
            "value": " 2/2 [00:00&lt;00:00, 55.46it/s]"
          }
        },
        "8abeff0d76854586b4971ce9d9285c93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d32f548730da4720afd6d9a93f46d5aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4f451b672e94472b4016dcafc0daa23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76239392347f480298fc2bd341704c41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f25f92b9748d41a496a74489fe472ec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dda12fc624b446c98cfcb1dc76c93453": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cca8a25ec5b4d548ddc324722412b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSLILnwi2sBQ",
        "outputId": "6c57ad96-5881-45a4-97e2-2f3a70776af9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.15.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
        "from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n",
        "import torch\n",
        "\n",
        "# initialize question and context encoders and their tokenizers\n",
        "question_encoder = DPRQuestionEncoder.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
        "question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
        "\n",
        "context_encoder = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
        "context_tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
        "\n",
        "# here is a random context and a related question\n",
        "context = \"Artificial intelligence (AI) is intelligence demonstrated by machines, unlike the natural intelligence displayed by humans and animals, which involves consciousness and emotionality. The distinction between the former and the latter categories is often revealed by the acronym chosen. 'Strong' AI is usually labelled as AGI (Artificial General Intelligence) while attempts to emulate 'natural' intelligence have been called ABI (Artificial Biological Intelligence).\"\n",
        "question = \"What is artificial intelligence?\"\n",
        "\n",
        "# tokenize the input (both question and context)\n",
        "question_inputs = question_tokenizer(question, return_tensors='pt')\n",
        "context_inputs = context_tokenizer(context, return_tensors='pt')\n",
        "\n",
        "# encode the input to get embeddings\n",
        "question_emb = question_encoder(**question_inputs).pooler_output\n",
        "context_emb = context_encoder(**context_inputs).pooler_output\n",
        "\n",
        "# compute the similarity between the embeddings (we can use cosine similarity here)\n",
        "similarity = torch.nn.functional.cosine_similarity(question_emb, context_emb)\n",
        "\n",
        "print(similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gppEUAOi2980",
        "outputId": "03110944-499d-430d-db5e-da721ab5ace5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizer'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.7218], grad_fn=<SumBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizerFast\n",
        "from transformers import DPRContextEncoder, DPRContextEncoderTokenizerFast\n",
        "from transformers import AdamW\n",
        "import torch"
      ],
      "metadata": {
        "id": "TpzzSY2Q-1lI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the 'squad' dataset\n",
        "squad_dataset = load_dataset('squad')\n",
        "\n",
        "# Let's consider a subset for demonstration\n",
        "squad_dataset = {\n",
        "    'train': squad_dataset['train'].select(range(1000)),\n",
        "    'validation': squad_dataset['validation'].select(range(500)),\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "98a2037ccf1545fca22ea805231b7ba8",
            "53fd9d1ccebc476f8c3e15faa471dc6e",
            "6f729b57260c43f2aa1021bfb89c053d",
            "8d7a65f840014a1baabad80534da7c9a",
            "8abeff0d76854586b4971ce9d9285c93",
            "d32f548730da4720afd6d9a93f46d5aa",
            "f4f451b672e94472b4016dcafc0daa23",
            "76239392347f480298fc2bd341704c41",
            "f25f92b9748d41a496a74489fe472ec7",
            "dda12fc624b446c98cfcb1dc76c93453",
            "4cca8a25ec5b4d548ddc324722412b85"
          ]
        },
        "id": "rYpphm0g-39k",
        "outputId": "89f46384-acef-4af4-d0c0-762ffce5a19c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98a2037ccf1545fca22ea805231b7ba8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the DPR tokenizers and models\n",
        "question_tokenizer = DPRQuestionEncoderTokenizerFast.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
        "ctx_tokenizer = DPRContextEncoderTokenizerFast.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
        "\n",
        "question_model = DPRQuestionEncoder.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
        "ctx_model = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONbbDuN6-5we",
        "outputId": "c805cbdb-7f07-4a6e-c462-c602e80cf663"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(example):\n",
        "    # Tokenize questions and contexts\n",
        "    question = question_tokenizer(example['question'], truncation=True, padding='max_length', max_length=256)\n",
        "    context = ctx_tokenizer(example['context'], truncation=True, padding='max_length', max_length=256)\n",
        "\n",
        "    return {\n",
        "        'question_input_ids': torch.tensor(question['input_ids']),\n",
        "        'question_attention_mask': torch.tensor(question['attention_mask']),\n",
        "        'context_input_ids': torch.tensor(context['input_ids']),\n",
        "        'context_attention_mask': torch.tensor(context['attention_mask']),\n",
        "        'labels': torch.tensor(0),  # for SQuAD, we don't have labels as in NQ, so just a dummy label\n",
        "    }\n",
        "\n",
        "# Prepare datasets\n",
        "squad_dataset = {\n",
        "    'train': squad_dataset['train'].map(prepare_dataset),\n",
        "    'validation': squad_dataset['validation'].map(prepare_dataset),\n",
        "}\n",
        "\n",
        "# Convert to PyTorch DataLoader\n",
        "dataloader = {\n",
        "    'train': DataLoader(squad_dataset['train'], batch_size=16, shuffle=True),\n",
        "    'validation': DataLoader(squad_dataset['validation'], batch_size=16, shuffle=True),\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tw57OqVD_CWg",
        "outputId": "e436e970-b05f-4466-ca1a-a6ebb65eb612"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453/cache-461707e800c07ae8.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453/cache-f7ba350136fed184.arrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move models to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "question_model = question_model.to(device)\n",
        "ctx_model = ctx_model.to(device)\n",
        "\n",
        "# Initialize optimizer\n",
        "optimizer = AdamW(list(question_model.parameters()) + list(ctx_model.parameters()), lr=1e-5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0OfpeoC_Dyf",
        "outputId": "b771486d-4dc0-4ce0-b862-0e43b632123b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(3):\n",
        "    for i, batch in enumerate(dataloader['train']):\n",
        "        # Move the batch tensors to the same device as the models\n",
        "        question_input_ids = torch.stack(batch['question_input_ids']).to(device)\n",
        "        question_attention_mask = torch.stack(batch['question_attention_mask']).to(device)\n",
        "        context_input_ids = torch.stack(batch['context_input_ids']).to(device)\n",
        "        context_attention_mask = torch.stack(batch['context_attention_mask']).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass\n",
        "        question_outputs = question_model(input_ids=question_input_ids, attention_mask=question_attention_mask)\n",
        "        ctx_outputs = ctx_model(input_ids=context_input_ids, attention_mask=context_attention_mask)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = ((question_outputs.pooler_output - ctx_outputs.pooler_output)**2).mean()\n",
        "\n",
        "        print(f\"Batch {i}, Loss: {loss.item()}\")\n",
        "\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch} completed.\")"
      ],
      "metadata": {
        "id": "B0J47xOc4m7N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73a5ac7a-aae9-44a7-b62b-74f2fffd35bf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0, Loss: 0.32967501878738403\n",
            "Batch 1, Loss: 0.17341338098049164\n",
            "Batch 2, Loss: 0.16407400369644165\n",
            "Batch 3, Loss: 0.10851892083883286\n",
            "Batch 4, Loss: 0.09284375607967377\n",
            "Batch 5, Loss: 0.08512582629919052\n",
            "Batch 6, Loss: 0.07281264662742615\n",
            "Batch 7, Loss: 0.07587005943059921\n",
            "Batch 8, Loss: 0.06397303193807602\n",
            "Batch 9, Loss: 0.0580436997115612\n",
            "Batch 10, Loss: 0.05110041797161102\n",
            "Batch 11, Loss: 0.044356055557727814\n",
            "Batch 12, Loss: 0.04068971425294876\n",
            "Batch 13, Loss: 0.03799150139093399\n",
            "Batch 14, Loss: 0.03221898898482323\n",
            "Batch 15, Loss: 0.03291810303926468\n",
            "Batch 16, Loss: 0.02922913245856762\n",
            "Batch 17, Loss: 0.02888689562678337\n",
            "Batch 18, Loss: 0.03085346519947052\n",
            "Batch 19, Loss: 0.02645936608314514\n",
            "Batch 20, Loss: 0.023925697430968285\n",
            "Batch 21, Loss: 0.020839959383010864\n",
            "Batch 22, Loss: 0.024798911064863205\n",
            "Batch 23, Loss: 0.019117332994937897\n",
            "Batch 24, Loss: 0.019314497709274292\n",
            "Batch 25, Loss: 0.018070977181196213\n",
            "Batch 26, Loss: 0.020015103742480278\n",
            "Batch 27, Loss: 0.016189448535442352\n",
            "Batch 28, Loss: 0.015591248869895935\n",
            "Batch 29, Loss: 0.016227107495069504\n",
            "Batch 30, Loss: 0.014370843768119812\n",
            "Batch 31, Loss: 0.01773032173514366\n",
            "Batch 32, Loss: 0.013300437480211258\n",
            "Batch 33, Loss: 0.012122313492000103\n",
            "Batch 34, Loss: 0.012376328930258751\n",
            "Batch 35, Loss: 0.013847403228282928\n",
            "Batch 36, Loss: 0.011528631672263145\n",
            "Batch 37, Loss: 0.011734746396541595\n",
            "Batch 38, Loss: 0.011800786480307579\n",
            "Batch 39, Loss: 0.011242613196372986\n",
            "Batch 40, Loss: 0.010258462280035019\n",
            "Batch 41, Loss: 0.00918720755726099\n",
            "Batch 42, Loss: 0.009501295164227486\n",
            "Batch 43, Loss: 0.010459418408572674\n",
            "Batch 44, Loss: 0.009268037974834442\n",
            "Batch 45, Loss: 0.00861348956823349\n",
            "Batch 46, Loss: 0.00916961394250393\n",
            "Batch 47, Loss: 0.010740738362073898\n",
            "Batch 48, Loss: 0.009022913873195648\n",
            "Batch 49, Loss: 0.007857437245547771\n",
            "Batch 50, Loss: 0.008467169478535652\n",
            "Batch 51, Loss: 0.008646002039313316\n",
            "Batch 52, Loss: 0.008225655183196068\n",
            "Batch 53, Loss: 0.00698184734210372\n",
            "Batch 54, Loss: 0.006551014259457588\n",
            "Batch 55, Loss: 0.008236645720899105\n",
            "Batch 56, Loss: 0.0067636012099683285\n",
            "Batch 57, Loss: 0.005505257286131382\n",
            "Batch 58, Loss: 0.006877878215163946\n",
            "Batch 59, Loss: 0.007457477506250143\n",
            "Batch 60, Loss: 0.005841800477355719\n",
            "Batch 61, Loss: 0.006954047828912735\n",
            "Batch 62, Loss: 0.0069864410907030106\n",
            "Epoch 0 completed.\n",
            "Batch 0, Loss: 0.006775382440537214\n",
            "Batch 1, Loss: 0.0068823182955384254\n",
            "Batch 2, Loss: 0.006244177930057049\n",
            "Batch 3, Loss: 0.0057834722101688385\n",
            "Batch 4, Loss: 0.005244299303740263\n",
            "Batch 5, Loss: 0.005200800020247698\n",
            "Batch 6, Loss: 0.006826271302998066\n",
            "Batch 7, Loss: 0.006395389791578054\n",
            "Batch 8, Loss: 0.004605133086442947\n",
            "Batch 9, Loss: 0.00517126964405179\n",
            "Batch 10, Loss: 0.005776088219136\n",
            "Batch 11, Loss: 0.005868390202522278\n",
            "Batch 12, Loss: 0.004762663971632719\n",
            "Batch 13, Loss: 0.004566757008433342\n",
            "Batch 14, Loss: 0.004831884056329727\n",
            "Batch 15, Loss: 0.0043327705934643745\n",
            "Batch 16, Loss: 0.00404996145516634\n",
            "Batch 17, Loss: 0.004258165135979652\n",
            "Batch 18, Loss: 0.004041648004204035\n",
            "Batch 19, Loss: 0.005239414982497692\n",
            "Batch 20, Loss: 0.004690191708505154\n",
            "Batch 21, Loss: 0.004502569325268269\n",
            "Batch 22, Loss: 0.004809876438230276\n",
            "Batch 23, Loss: 0.004331775009632111\n",
            "Batch 24, Loss: 0.004081232938915491\n",
            "Batch 25, Loss: 0.005303995683789253\n",
            "Batch 26, Loss: 0.0037119174376130104\n",
            "Batch 27, Loss: 0.004054781049489975\n",
            "Batch 28, Loss: 0.003732573240995407\n",
            "Batch 29, Loss: 0.004166360013186932\n",
            "Batch 30, Loss: 0.0032652344089001417\n",
            "Batch 31, Loss: 0.004938281141221523\n",
            "Batch 32, Loss: 0.003368239849805832\n",
            "Batch 33, Loss: 0.003560250159353018\n",
            "Batch 34, Loss: 0.003698425367474556\n",
            "Batch 35, Loss: 0.003956748638302088\n",
            "Batch 36, Loss: 0.0032944201957434416\n",
            "Batch 37, Loss: 0.0036638514138758183\n",
            "Batch 38, Loss: 0.003358387155458331\n",
            "Batch 39, Loss: 0.004425386898219585\n",
            "Batch 40, Loss: 0.003924979828298092\n",
            "Batch 41, Loss: 0.0036991951055824757\n",
            "Batch 42, Loss: 0.003051552688702941\n",
            "Batch 43, Loss: 0.0035246615298092365\n",
            "Batch 44, Loss: 0.0028871321119368076\n",
            "Batch 45, Loss: 0.00300399586558342\n",
            "Batch 46, Loss: 0.0029632782097905874\n",
            "Batch 47, Loss: 0.0031879513990134\n",
            "Batch 48, Loss: 0.0029437821358442307\n",
            "Batch 49, Loss: 0.0031534440349787474\n",
            "Batch 50, Loss: 0.0027121095918118954\n",
            "Batch 51, Loss: 0.0028630467131733894\n",
            "Batch 52, Loss: 0.0038231112994253635\n",
            "Batch 53, Loss: 0.002811465412378311\n",
            "Batch 54, Loss: 0.0029485372360795736\n",
            "Batch 55, Loss: 0.003671725047752261\n",
            "Batch 56, Loss: 0.002779025351628661\n",
            "Batch 57, Loss: 0.0030153640545904636\n",
            "Batch 58, Loss: 0.0032270257361233234\n",
            "Batch 59, Loss: 0.0029918355867266655\n",
            "Batch 60, Loss: 0.004038452170789242\n",
            "Batch 61, Loss: 0.0029605021700263023\n",
            "Batch 62, Loss: 0.0033490583300590515\n",
            "Epoch 1 completed.\n",
            "Batch 0, Loss: 0.0035431296564638615\n",
            "Batch 1, Loss: 0.0024745967239141464\n",
            "Batch 2, Loss: 0.0027758078649640083\n",
            "Batch 3, Loss: 0.0029094605706632137\n",
            "Batch 4, Loss: 0.003495443146675825\n",
            "Batch 5, Loss: 0.002473304746672511\n",
            "Batch 6, Loss: 0.0029338428284972906\n",
            "Batch 7, Loss: 0.0032098907977342606\n",
            "Batch 8, Loss: 0.004335266537964344\n",
            "Batch 9, Loss: 0.002238561399281025\n",
            "Batch 10, Loss: 0.0035370835103094578\n",
            "Batch 11, Loss: 0.0024474021047353745\n",
            "Batch 12, Loss: 0.0026004062965512276\n",
            "Batch 13, Loss: 0.0028198701329529285\n",
            "Batch 14, Loss: 0.003107656491920352\n",
            "Batch 15, Loss: 0.0027149864472448826\n",
            "Batch 16, Loss: 0.0029139057733118534\n",
            "Batch 17, Loss: 0.0024215467274188995\n",
            "Batch 18, Loss: 0.002044659573584795\n",
            "Batch 19, Loss: 0.0022911950945854187\n",
            "Batch 20, Loss: 0.0030323145911097527\n",
            "Batch 21, Loss: 0.003645187709480524\n",
            "Batch 22, Loss: 0.0026853966992348433\n",
            "Batch 23, Loss: 0.002105825114995241\n",
            "Batch 24, Loss: 0.002614289987832308\n",
            "Batch 25, Loss: 0.002267327858135104\n",
            "Batch 26, Loss: 0.002394947223365307\n",
            "Batch 27, Loss: 0.0022948933765292168\n",
            "Batch 28, Loss: 0.00223020208068192\n",
            "Batch 29, Loss: 0.002208795165643096\n",
            "Batch 30, Loss: 0.0019940584897994995\n",
            "Batch 31, Loss: 0.002568650059401989\n",
            "Batch 32, Loss: 0.002102150348946452\n",
            "Batch 33, Loss: 0.002190816681832075\n",
            "Batch 34, Loss: 0.0027219669427722692\n",
            "Batch 35, Loss: 0.0027418225072324276\n",
            "Batch 36, Loss: 0.0028179888613522053\n",
            "Batch 37, Loss: 0.0026444080285727978\n",
            "Batch 38, Loss: 0.002080880803987384\n",
            "Batch 39, Loss: 0.0025120326317846775\n",
            "Batch 40, Loss: 0.0020438411738723516\n",
            "Batch 41, Loss: 0.0018311641179025173\n",
            "Batch 42, Loss: 0.0021675415337085724\n",
            "Batch 43, Loss: 0.001825238112360239\n",
            "Batch 44, Loss: 0.0017762057250365615\n",
            "Batch 45, Loss: 0.0023455421905964613\n",
            "Batch 46, Loss: 0.0017740776529535651\n",
            "Batch 47, Loss: 0.0019077830947935581\n",
            "Batch 48, Loss: 0.002379375509917736\n",
            "Batch 49, Loss: 0.002021034713834524\n",
            "Batch 50, Loss: 0.0021439502015709877\n",
            "Batch 51, Loss: 0.0019031667616218328\n",
            "Batch 52, Loss: 0.0019797030836343765\n",
            "Batch 53, Loss: 0.0019043183419853449\n",
            "Batch 54, Loss: 0.0016163125401362777\n",
            "Batch 55, Loss: 0.0015001160791143775\n",
            "Batch 56, Loss: 0.0016796812415122986\n",
            "Batch 57, Loss: 0.001723551657050848\n",
            "Batch 58, Loss: 0.0018995311111211777\n",
            "Batch 59, Loss: 0.00152210786473006\n",
            "Batch 60, Loss: 0.002052363008260727\n",
            "Batch 61, Loss: 0.0016286912141367793\n",
            "Batch 62, Loss: 0.0018182825297117233\n",
            "Epoch 2 completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "etV5XG885fvq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}