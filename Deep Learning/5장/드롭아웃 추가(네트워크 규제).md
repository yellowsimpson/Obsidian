->train data의 파라미터 중 쓸데없는 부분을 떨어뜨릴는 것

![[Pasted image 20250416185333.png]]

-> 드롭 아웃을 적용하면 훈련하는 동안 무작위로 층의 출력 특성을 일부 제외시킨다. (0으로 만든다.)


```python
layer_output *= np.random.randint(0, high=2, size=layer_output.shape)

#훈련할때 유닛의 출력 중 50%를 버린다.

layer_output *= 0.5     # 테스트 단계

layer_output *= np.random.randint(0, hight = 2, size=layer_output.shape) #훈련단계
layer_output /= 0.5
```



[코드 5-15]
```python
model = keras.Sequential([
	layers.Dense(16, activation="relu"),
	layers.Dropout(0.5),                    #다음에 데이터의 0.5만 참여시킨다는 의미
	layers.Dense(16, activation="relu"),
	layers.Dropout(0.5),                    #다음에 데이터의 0.5만 참여시킨다는 의미
	layers.Dense(1, activation="sigmoid")
])

model.compile(optimizer="rmsprop",
			loss="binary_crossentropy",
			metrics=["accuracy"])

history_dropout = model.fit(
		train_data, train_labels,
		epochs=20, batch_size=512, validation_split=0.4)
```

![[Pasted image 20250416191735.png]]


참고!! [[드롭아웃과 가지치기의 차이점]]
