
- 5.4.1 데이터셋 큐레이션 (조직하는거)

1. 데이터가 충분한지 확인한다.
2. 레이블 할당 에러를 최소화한다.
3. 데이터를 정제하고 누락된 값을 처리한다.
4. 많은 특성 중에서 어떤 것이 유용한지 확실하지 않다면 특성 선택을 수행하세요

데이터의 일반화 가능성을 향상시키는 매우 중요한 방법은 특성 공학이다.

- 5.4.2 __특성 공학(feature engineering)__
특성 공학의 핵심 -> 특성을 더 간단한 방식으로 표현해서 문제를 쉽게 만든다.
심층 신경망을 사용할 때 특성 공학에 대해 신경쓰지 않아도 되는 이유?
1. 좋은 특성은 적은 자원을 사용해서 문제를 풀어낼 수 있다.
2. 좋은 특성은 더 적은 데이터로 문제를 풀 수 있다.

딥러닝 이전에는 특성공학이 머신러닝에서 가장 중요한 부분이다.
but 최근 딥러닝에서는 특성공학이 필요하지 않음!!

why? 
	-> 적은 자원
	-> 더 적은 데이터 로 좋은 문제를 풀 수 있음


- 5.4.3 조기 종료 사용하기 (= early stopping)



- 5.4.4 모델 규제하기
규제 기법은 훈련 데이터에 완벽하게 맞추려는 모델의 능력을 적극적으로 방해하는 일련의 모범 사례이다.
너무 작은 모델은 과대적합되지 않는다.

*여기 시험!!*
<모델 성능을 높이는 방법 3가지>
1. __[[모델 용량 규제(커페시터 규제)]]__
	너무 작은 모델은 과대적합되지 않는다. __과대적합을 완화시키는 방법은 모델의 크기를 줄이는 것__ 이다.
2. __[[파라미터 값을 규제(L1, L2 규제)]]__
	L1 규제: 가중치의 절대값에 비례하는 비용이 추가된다.
	L2 규제: 가중치의 제곱에 비례하는 비용이 추가된다. 
3. __[[드롭아웃 추가]]__



