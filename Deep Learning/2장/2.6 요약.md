- 텐서는 현대 머신 러닝 시스템의 기초이다.
- 텐서 연산(덧셈, 텐서 곱셈, 원소별 곱셈)을 통해 수치 텐서를 조작 할 수 있다.
- 연산은 기하학적 변형을 적용하는 것으로 이해 할 수 있다. 
- 딥러닝 모델은 가중치 텐서를 매개변수로 받는 간단한 텐서 연산을 연결하여 구성된다.
- __학습은 훈련 데이터 샘플과 그에 사응하는 타깃이 주어졌을 때 손실 함수를 최소화하는 모델의 가중치 값을 찾는 것을 의미한다.__
- 데이터 샘플과 타깃의 배치를 **랜덤하게** 뽑고 이 배치에서 모델 파라미터에 대한 손실의 **gradient를** 계산함으로써 학습이 진행된다. 모델의 파라미터는 __gradient의 반대방향__ 으로 조금씩 움직인다. 이것을 __미니 배치 경사 하강법__ 이라고 한다.
- 전체 학습 과정은 신경망에 있는 모든 텐서 연산이 미분 가능하기 때문에 가능하다. 따라서 현재 파라미터와 배치 데이터를 gradient값에 매핑해 주는 gradient 함수를 구성하기 위해 미분의 연쇄법칙을 사용할 수 있다. 이를 역전파라고 부른다.
- 손실과 옵티마이전는 모델에 데이터가 주입되기 전에 정의 되어야한다.
- 손실은 훈련하는 동안 최소화해야 할 양이므로 해결하려는 문제의 성공을 측하는데 사용한다.
- 옵티마이저는 손실에  대한 gradient가 파라미터를 업데이트하는 정확한 방식을 정의한다. 
