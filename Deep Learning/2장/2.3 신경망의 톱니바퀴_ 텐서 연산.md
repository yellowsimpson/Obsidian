
__output = relu(dot(input, W) + b)
-> W : 행렬, b: 벡터

1. 입력 텐서와 텐서 W 사이의 점곱
2. 점곱으로 만들어진 행렬과 벡터 b 사이의 뎃셈(+)
3. relu 연산.relu(x)는 max(x, 0)입니다.

- 2.3.1 원소별 연산
__relu 함수와 덧셈은 원소별 연산이다.__
**이 연산은 텐서에 있는 각 원소에 독립적으로 적용됨**

[원소별 연산]
```python
def naive_felu(x):
	assert len(x.shape) == 2    #x는 랭크_2 넘파이 배열이다.
	x = x.copy()                #입력 텐서 자체를 바꾸지 않도록 복사한다.
	for i in range(x.shape[0]):
		for j in range(x.shape[1]):
			x[i, j] = max(x[i, j], 0)
	return x
```

[덧셈]
```python
def naive_add(x, y):
	assert len(x.shape) == 2        #x와 y는 랭크_2 넘파이 배열이다.
	assert x.shape == y.shape
	x = x.copy()                    #입력 텐서 자체를 바꾸지 않도록 복사한다.
	for i in range(x.shape[0]):
		for j in range(x.shape[1]):
			x[i, j] += y[i, j]
	return x
```

넘파이는 **BLAS(Basic Linear Algebra Subprogram)** 구현에 복잡한 일들을 위임한다.
BLAS는 고도로 병렬화되고 효율적인 저수준의 텐서 조작 루틴이며, 전형적인 포트란이나 C 언어로 구현되어 있다.

__넘파이는 원소별 연산에 속도가 빠르다!!__
```python
import numpy as np

z = x + y
z = np.maximum(z, 0.)
```

```python
import time

x = np.random.random((20, 100))
y = np.random.random((20, 100))

t0 = time.time()
for _ in range(1000):
	z = x + y
	z = np.maximum(z, 0)
print("걸린 시간: {0:.2f}s".format(time.time() - t0))

```

```python
t0 = time.time()
for _ in range(1000):
	z = naive_add(x, y)
	z = naive_relu(z)
print("걸린 시간: {0:.2f}s".format(time.time() - t0))
```

- 2.3.2 브로드캐스팅
브로드캐스팅 2단계
1. 큰 텐서의 ndim에 맞도록 작은 텐서에 축이 추가됩니다.
2. 작은 텐서가 새 축을 따라서 큰 텐서의 크기에 맞도록 반복됩니다.

```python
import numpy as np
	X = np.random.random((32, 10)) #X는 크기가 (32, 10)인 랜덤한 행렬
	y = np.random.random((10,)) #y는 크기가(10,)인 랜덤한 벡터

	y = np.expand_dims(y, axis=0) #y의 크기는 (1, 10)

	Y = np.concatenate([y] * 32, axis=0) #축 0을 따라 y를 32번 반복하여 크기가 (32, 10)인 Y값 얻음

def naive_add_matrix_and_vector(x, y):
	assert len(x.shape) == 2 #x는 랭크 -2 넘파이 배열
	assert len(y.shape) == 1 #y는 넘파이 벡터
	assert x.shape[1] == y.shape[0]
	x = x.copy() #입력 텐서 자체를 바꾸지 않도록 복사
	for i in range(x.shape[0]):
		for j in range(x.shape[1]):
			x[i, j] += y[j]
	return x
```

- 2.3.3 텐서 곱셈
**텐서 곱셈(tensor product) == 점곱(dot product)**
넘파이에서 텐서 곱셈은 np.dot을 사용한다.

```python
x = np.random.random((32,))
y = np.random.random((32,))
z = np.dot(x, y)
```

[점곱 연산]
```python
def naive_vector_dot(x, y):
	assert len(x.shape) == 1
	assert len(y.shape) == 1
	assert x.shape[0] == y.shape[0]
	z = 0.
	for i in range(x.shape[0]):
		z += x[i] * y[i]
	return z
```

```python
def naive_matrix_vector_dot(x, y):
	assert len(x.shape) == 2
	assert len(y.shape) == 1
	assert x.shape[1] == y.shape[0]
	z = np.zeros(x.shape[0])
	for i in range(x.shape[0]):
		for j in range(x.shape[1]):
			z[i] += x[i, j] * y[j]
	return z
```

```python
def naive_matrix_vector_dot(x, y):
	z = np.zeros(x.shape[0])
	for i in range(x.shape[0]):
		z[i] = naive_vector_dot(x[i, :], y)
	return z
```

```python
def naive_matrix_dot(x, y):
	assert len(x.shape) == 2
	assert len(y.shape) == 2
	assert x.shape[1] == y.shape[0]
	z = np.zeros((x.shape[0], y.shape[1]))
	for i in range(x.shape[0]):
		for j in range(y.shape[1]):
			row_x = x[i, :]
			column_y = y[:, j]
			z[i, j] = naive_vector_dot(row_x, column_y)
	return z
```

![[스크린샷 2025-02-12 오후 12.44.15.png]]
-> 걍 행렬 끼리 곱하는거 계산 *시험!!!* 
![[스크린샷 2025-02-12 오후 12.57.54.png]]

- 2.3.4 텐서 크기 변환
텐서 크기 변환(tensor reshaping) : 특정 크기에 맞게 *열과 행을 재배열* 한다는 뜻.

```python
train_images = train_images.reshape((60000, 28 * 28))

x = np.array([[0., 1.],
			  [2., 3.],
			  [4., 5.]])
x.shape
#(3, 2) -> 3행 2열
1
x = x.reshape((6, 1)) #x행렬을 6행 1열로 재배열
x
'''
array([[0.],
       [1.],
       [2.],
       [3.],
       [4.],
       [5.]])
'''

x = x.reshape((2, 3)) #x행렬을 2행 3열로 재배열
x

#array([[0., 1., 2.],
#       [3., 4., 5.]])
       
x = np.zeros((300, 20)) #모두 0으로 채원진 (300, 20) 크긱의 행렬을 만듬
x = np.transpose(x) #전치행렬로 변환
x.shape
```

- 2.3.5 텐서 연산의 기하학적 해석
__일반적으로 이동(translation), 회전(rotation), 크기 변경(scaling), 기울이기(skewing)이 가능__

1.이동: 한 점에 벡터를 더하면 고정된 방향으로 고정된 양만큼 점을 이동시킨다.
![[스크린샷 2025-02-12 오후 2.13.50.png]]

2.회전: 각도 theta만큼 2D 벡터를 반시계 방향 회전한 결과 2x2 행렬 R=[[cos(theta), -sin(theta)], [sin(theta), cos(theta)] ]와 점곱 하여 계산 가능
![[스크린샷 2025-02-12 오후 2.14.00.png]]

3.크기 변경: 
2x2 행렬 S=[[horizontal_factor, 0], [0, vertical_factor]] 와 점곱하여 수직과 수평방향으로 크기를 변경시킨 이미지이다.
![[스크린샷 2025-02-12 오후 2.17.10.png]]

4.선형 변환(linear transfrom): 임의의 행렬과 점곱하면 선형 변환이 수행된다. 
크기 변경과 회전은 선형 변환에 해당됨

5.어파인(affine transform): 어파인 변환은 선형 변환과 이동의 조합이다.
![[스크린샷 2025-02-12 오후 2.17.16.png]]

relu 활성화 함수를 사용하는 Dense 층: 어파인 변환의 중요한 성질 하나는 어파인 변환을 반복해서 적용해도 결국 하나의 어파인 변환이 된다는것

![[Pasted image 20250418155139.png]]


- 2.3.6 딥러닝의 기하학적 해석
![[23259AF5-395C-4684-8150-0DDD1A5DC563_4_5005_c.jpeg]]

