딥러닝 day3_1
2025.03.12 수 오전 10:04 ・ 52분 38초
심승환


참석자 1 00:00
근데 여러분 일단 교과서가 다 준비가 됐나요? 일주일이 지났으니 됐지 그쵸?
아니에요. 교과서 이거 이게 교과서예요. 여러분 이거 없는 사람은 학과 사무실에서 빌리세요.
계속 계속 여전히 진짜 하는 사람이 많아서 빌릴 수 있더라고요.
그리고 PDF로만 있을 경우에 본인이 교과서를 갖고 있지 않으면 저작권 침해에 걸려요.
여러분 조심하세요. 저는 분명히 알렸어요. 여러분

참석자 1 00:36
PDF를 이제 본인이 책을 갖고 있는 상태에서 갖고 있으면 문제가 없고 책이 없는데 PDF만 갖고 있으면 저작권 침해가 돼요.
여러분 알겠죠 그다음에 그거는 어쩔 수 없이 제가 준비한 강의 자료를 보면서 하는 거를 하지 않고 책으로 그냥 바로 들어갈게요.
여러분 갔다 갔다 해도 상관없어요. 책을 봅시다.
책에 교과서를 보면 여러분 교과서 없는 사람은 옆에 살이라도 같이 다 옮겨가 알겠죠 열심히 할 때도 많아가지고 그래요.
그래서 보면 이제 지금 제가 보고 있는 목차를 볼게요.
목차 목차 목차가 머리 말 나온 다음에 바로 나와요.
목차 목차 밖에 없었어요. 여러분 목차에 보면은 1장 딥러닝이란 무엇인가 이렇게 적혀 있죠 그렇죠 딥러닝 2장의 제목이 뭐예요?
신경망의 수학적 구성 요소 이렇게 적혀 있죠 그렇죠 신경망이 이제 영어로 뭐냐 색깔 들어가나 그래 가까운 데 있어 가까워요.

참석자 1 01:39
신경망이 영어로 뭐냐 이런 거 그래요 상관없을 것 같아요.
안 들어도 이렇게 할게요. 여러분 영어로 뭔지 다 알아야 된다고 그랬죠.
그래서 신경망이 영어로 뭐예요? 그냥 정확하게 뉴얼 네트워크 그렇죠 이렇게 나와야 돼요.
뉴얼 네트워크 근데 사실 보통 신경만 이렇게 부르는 경우는 별로 없어요.
영어로 뭐라고 불러요? 보통 아티피셜 뉴얼 네트워크나 딥 뉴럴 네트워크 이렇게 부르죠.
그래서 줄여서 al는 dl는 이렇게 불러요. 그쵸 그쵸 여러분 그래서 거기에 나오는 거기에서 필요한 수학적 구성 요소래요 그렇죠 근데 사실 이거 요 2장 내용은 딥러닝이라 살아있는 내용이 아니라 사실 그냥 원래 그냥 머신러닝 내용이에요.
쓱 지나가죠. 왜냐면은 머신러닝 있잖아요. 우리 집 방문이 우리 과목에서 할 게 더 많아서 그다음에 이 3장이 케라스와 텐스 플로 소개라고 돼 있죠.
그쵸?

참석자 1 02:28
캐러스 센서 블로 여러분이 이제 딥러닝 이제 코딩을 해야 되는데 거기 쓰기 위해서 라이브러리가 있는 게 좋죠.
그렇죠 우리가 다 생으로 짤 수 없잖아요. 있는 고차원 라이브러리를 쓰는 건데 그중에 이제 제일 유명한 게 지금은 제일 많이 쓰는 게 이제 학생들은 제일 많이 쓰는 게 파이토치라는 거예요.
왜냐하면 파이토치가 오픈 소스가 엄청 많거든요.
근데 실제로 회사에서 많이 쓰는 건 텍스 플로우고 그리고 펜스 플로우가 원래 되게 API가 어려웠었어요.
좀 할 수 있는 걸 원래 옵션을 많이 주면 API가 어려워요.
가마솥으로 뭔가 답을 만들려고 그러면 되게 힘들잖아요.

참석자 1 03:02
정렬 수술로 만들면 쉽고 근데 이제 텍스 플로우 너무 가마솥처럼 만들어 놓은 거지 할 수 있는 거 너무 많은데 너무 힘들어요.
그렇죠 그래서 조금만 잘못하면 어떻게 돼요? 여러분 가게 다 타버리고 난리도 아니죠.
그쵸 진짜 맛있나 할 수도 있지만 펜스 플로우는 웬만하면 잘 안 돌아가는 거예요.
사람들이 사람들이 다 버리기 시작해서 파이처럼 이렇게 번성을 한 거죠.
그래서 케라스가 뭐냐면은 케라스가 원래 이제 여러분이 지금 파이토치랑 테스도 플로우만 알고 있지만 그전에는 필라노니 많았어요.
딥러닝 라이브리들이 근데 걔네들을 전부 다 표준 API로 만들어버린 약간 래퍼처럼 만든 그런 API도 있었거든요.
그거 만든 사람이 이 저자예요. 케라스라는 걸 만든 사람이 이 저자예요.
이제 저자 이 사람이 주로 만들었지. 그런데 이제 테스터 플로우가 망하기 시작하니까 망해가니까 이제 아무도 안 쓰잖아요.

참석자 1 03:50
어려워서 그래서 과감하게 텐서 플로우가 이제 버전이 원래 1점대 0점대 시작하다가 1점 대 가다가 2.0으로 바뀌면서 그게 언제냐면은 2009년 9월이거든요.
되게 옛날인데 지금 2019년 9월이다. 2019년 9월 2019년 맞았어.
2020년 2019년 2019년 9월이면 임금이 얼마 안 됐죠.
여러분 그때 통합 해서기 직전에 캐러스로 API를 바꿔버렸어요.
전격 전격 바꿨죠. 그래서 이제 이제 사용하기 싫으니까 제발 돌아가자고 하는데 잘 안 돌아가고 있지 사람들이 여전히 파이터치로 워낙 오피스가 많으니까 그런 상황이에요.
알겠죠 어쨌든 이 책은 그래서 캐라스를 캐라스 위주로 되어 있어요.
알겠죠? 텐서 플로우 API인데 얼리디서플로이고 어렵던 API가 아니라 쉬운 캐라스트 API에서 사실은 거의 파이토치랑 유사해요.
그렇지만 파이토치랑 유사하지만 파이토치가 워낙 또 이제 중요하고 파이토치에서 뭔가 철학이 약간 다른 게 있거든요.
그래서 제가 파이토치도 강의를 해 줄 거예요.

참석자 1 04:53
왜냐하면 실제로 8주치 갖고 갖다 쓸 게 되게 많으니까 그래서 비교해 주고 이런 것도 슬라이드 만들어 놨어요.
제가 나중에 보여줄게요. 여러분 그래요. 어쨌든 이런 게 돼야지 다 그런 강의를 할 수 있는데 그렇죠 알겠죠 그러면 그다음에 사장이 이제 드디어 디뉴럴 네트워크 시작을 하는 거죠.
그래서 근데 또 하면서 바로 분류화 핵이라고 적혀 있잖아요.
그렇죠 분류와 획이 분류하고 획인데 이제 원래 종류 뭔가 이제 AI로 할 수 있는 가장 기본적인 일 중에 하나가 이제 분류란 획이거든요.
행위는 값을 예측하는 거고 분류는 원래 정해진 클래스 중에서 뭐냐 종류 중에서 뭐냐 이렇게 맞추는 거거든요.
이거를 이제 딥뉴럴 네트워크로 푸는 내용인데 사실 이거 원래 이제 머신러닝에서도 이걸 하고 있지.
당연히 그냥 그냥 빈말 레터가 아닌 거에서도 그거 내용을 먼저 좀 아는 상태에서 하는 게 좋은데 제가 약간 리뷰에 두고 할게요.

참석자 1 05:52
알겠죠 그다음에 이제 5장 또 들어가면 바로 재미있는 게 5장 6장은 바로 머신러닝 들어가잖아요.
또 그쵸 사실은 머신러닝이랑 딥 뉴럴 네트워크이랑 딥러닝이랑 공통 부분이 되게 많겠죠.
러 못하면 망하는 거잖아요. 지니 라이트도 못하기 때문에 다시 5장 6장에서는 사실 머신러닝 내용이 나와요.
알겠죠 그래요. 어쨌든 전 리뷰는 어쨌든 여기서 또 할 수 있겠지만 워낙 중요한 내용이라서 하고 7장에서 이제 케라스 완전 정보라고 적혀 있는데 캐라스 워낙 쉬우니까 한 장에서 끝내버리겠다 이러면서 있는 거고요.
이때 제가 이제 파이토치도 비교해 줄 거예요. 알겠죠?
그래 그다음에 이제 8장부터 좀 이제 8장이 사실 디뉴럴 네트워크는 이게 DNN 지금 딥러닝이 딥러닝이 중요한 게 이제 공동 신경망이라는 게 나왔고 그 아키텍처가 되게 다양한 다양하게 생겼어요.
이제 원래 생긴 모양이 가장 기본적인 게 있고 그다음에 이제 약간 좀 모양 변형들이 이렇게 나오기 시작하거든요.

참석자 1 06:52
그 변형들 하나하나가 응용 분야별로 특성화가 약간 달라요.
잘 되는 게 어떤 분야에서 잘 될지를 이제 여러분이 이제 이걸 배우고 나면 알아야 되는 건데 첫 번째가 이제 팔자니 컴퓨터 비전이죠.
그쵸 그다음에 10장이 시계열이죠. 그쵸 그리고 11장이 텍스트 그다음에 12장이 생성 모델 이런 식으로 나와 있잖아요.
그쵸 이런 식으로 일단 컴퓨터 비전에서는 기본적으로 어떤 딥뉴럴 네트워크 마케터가 좋은가 이걸 배우는 거예요.

참석자 1 07:21
그래서 이제 여러분도 나중에 이미 들어본 사람 많을 텐데 여기는 컨볼루션 뉴얼 네트웍이라는 거 CNN이라는 거 컨볼루션 디뉴얼 네트워크이 사실은 그래서 이제 CNN이라는 거를 배울 거고 그리고 9장에서는 이제 CNN 여러 가지 워낙 유명한 변형들 이런 걸 배울 거고 갖다 쓰는 거 그리고 여기에 사실 여기도 있지 여기도 재미있는 게 또 8장 자체에 보면은 8장에서도 재미있는 게 여기 중요한 게 뭐가 있냐면은 8장에 8점 3절이 보이면 8자 3절 제목을 보면 뭐라고 돼 있어요?
여러분 사전 훈련된 모델 활용하기로 돼 있죠. 사전 훈련 사도 훈련이 이제 영어로는 뭐냐면 프리트레인이거든요.
프리트레인 여러분 그 유명한 챗gpt의 GPT의 플랜이 뭐겠어요?

참석자 1 08:09
이제 알아야 돼요 여러분 지 에너티 그렇죠 p 프리 체 사전 훈련 사전 훈련 사전 훈련 된 모델 하라고 하는데 트리 트레이드 모델을 활용하는 GPT 트리 트레이드 그렇죠 사전 훈련된 모델 누가 많이 이제 만들어 놓은 웨이트를 우리가 얻을 수 있으면 그걸 활용해서 뭔가 일을 하겠다는 거잖아요.
이게 요즘에는 거의 맨탈 헤딩하는 거 이상한 거죠.
오픈소스 소프트웨어 안 하려고 하는 거 이상한 거예요.
그쵸 여러분이 텐서플로우 안 쓰고 내가 다 짜겠다 미친 일이거든.
그죠? 여러분 파이토치를 해서 플로우 안 짜고 내가 다 짜겠다 알아도 여러분 있는 걸 갖다 써야 돼요.
그쵸 빨리 하려고 그러면 제대로 하려면 검증도 워낙 중요하기 때문에 여러분 뭔가 내가 다 짜는 건 안 돼요.
그렇죠 같이 일해야지. 그래서 이게 지금 모델도 마찬가지 이제 딥러닝 할 때 제일 중요한 것 중에 하나가 이미 존재하는 세상에 존재하는 필 트레인드 모델을 갖다 쓰는 게 되게 중요해요.

참석자 1 09:04
그거에 대해서 계속 공부하는 게 필요하고 갖다 쓸 수 있는 거 안 갖다 쓰는 건 나쁜 짓이야.
그렇죠 왜냐면 굉장히 자원 당분이 또 트레이드 하는 거잖아요.
사실 여기 그래서 8.2절 내용은 밑바닥부터 프롬 스크래치라고 돼 있어요.
영어로는 밑바닥부터가 프롬 스크래치라고 그래요.
바닥부터 하는 거 프로 스크레처에는 스크래치를 긁어 모으는 거잖아요.
그렇죠 이게 바로 8.2 바로 그냥 데이터 바로 올려놓는 거고 8.3절은 원래 훈련된 그가 모델이 프리트레이드 모델을 가지고 다시 활용해서 어떻게 할 것이냐 이런 내용이에요.
그쵸 사실 여기 보통 전문 용어가 안 나오는데 이 기터에도 나오고 하는데 이거 이거 미리 제가 여러분 여러 번 들으면 좋으니까 다른 데서 이게 이게 이름이 뭔지 알아요 여러분 이런 거 전문 용어로 보면은 우리가 지금 러닝 딥러닝 머신 러닝 계속 러닝 러닝 하고 있잖아요.

참석자 1 09:53
그리고 우리나라 말로는 기계 학습 그다음에 심층 학습 이런 식으로 학습 이렇게 듣잖아요.
그렇죠 이것도 뭔가 무슨 학습이라고 부르는 거 있는데 아세요?
여러분 무슨 모양이라고 부르는데 이제 여러분 이제 여러분이 예측하다 보면 이제 나중에 이상하게 용어가 잘못 구어질 수 있으니까 바로 답을 알려줄게요.
우리나라 말로 전이 학습이라고 하고 영어로 트랜스퍼 러닝이라고 해요.
이거 되게 중요한 용어 외워야 되는 거야. 트랜스퍼 러닝 해야겠다.
무조건 트랜스퍼 러닝 해야 돼요. 트랜스퍼 러닝이나 전이 학습 우리나라가 그러잖아요.
그런 걸 해야지 그냥 맨땅에 헤딩하는 거는 안 돼요.

참석자 1 10:28
요즘에는 알겠죠 오픈소스 쓰는 거랑 똑같은 거 오픈 소스 중에 오픈 웨이트가 있는 거지 뭔지 알겠어요 여러분 여러분 미키 세븐틴이라는 그런 영화가 망했던데 소설은 되게 재미있었는데 영화를 했더 영화를 너무 다르게 만드셨더라고 그래요.
나는 할 말이 많지만 여러분 영화 안 본 사람도 많아서 이렇게 그래서 거기 보면 그게 중요한 게 복제 인간을 만들 수 있는데 원래 머리를 다 이렇게 뭔가 딱 메모리 넣어놨다가 싹 다시 넣을 수 있거든요.
디스크 이만한 거 보여주거든요. 영화에서도 돌더리 같은 거 보여주는데 그런 게 웨이트예요.
여러분 머리를 거기 그 머리를 다시 안 씌우면은 옛날 기억을 못해 새로운 경험을 기억 못해 그 머리가 웨이트 같은 거라고 여러분 저기 트랜스포러닝은 그 머리를 가지고 와서 다시 새로운 걸 해야지 빈트 껍데기 소용없잖아요.
여러분 귀 껍데기로 선부터 학습시키려고 그러면 몇 년이 걸릴 거 아니에요?
그쵸? 알겠어 여러분 전 학생이 뭔지 알겠어요?

참석자 1 11:23
여러분 알겠지 그쵸 그리고 그 미키 세븐틴도 그렇게 왜 열심히 그렇게 맨날 백업시켜놓냐면은 이 경험을 쌓아놓은 거를 알아야 될 거 아니에요?
그쵸? 그래야지 새로운 미션도 하고 이러니까 어쨌든 사전 랜드 모델 활용하기 이게 트랜스포 러닝이다 전 학습이다 이런 거를 미리 알 거예요.

참석자 2 11:42
그 프리 트레이닝이랑 파인투닝도 따로 있는 걸로 알고

참석자 1 11:45
그래요. 그거 좋은 질문인데 두 개 차이 이겨버릴게요.
지금 나왔으니까 지금 이 친구는 파인 튜닝이라는 말을 들어본 거예요.
그쵸? 그럼 파인 튜닝이랑 프리 트렌드랑 무슨 상관이냐 전의 학습이랑 무슨 상관이냐 그렇죠 그런 건데 전이 학습을 할 때 사실 여러분이 지금 미리 들어놔도 별로 상관없을 것 같은데 뉴럴 네트워크를 쓰잖아요.
그럼 항상 항상 항상 어떻게 나냐면 이게 여러분이 미리 얘기해도 상관없으려나 항상 두 분으로 나눠져요.
보통 리럴 네트워크 자체가 맨 처음 입력받아가지고 약간 좀 추상화하는 부분도 있고 그리고 나중에 이제 실제로 출력을 내놓는 부분이 있어요.

참석자 1 12:26
출력을 내놓게 약간 뭔가 이 계층이 깊은 건데 이 일이 안 보여서 좀 미안하긴 한데 그래도 들은 가다가 있으면 나중에 더 잘 알아들으니까 그래가지고 어쨌든 전이 학습이 크게 두 가지가 있어요.
트랜스포 러닝에 하나는 그냥 원래 있는 모델을 그대로 제로 샷 러닝이라고 그래서 한 번 거의 이제 트레이닝 안 시키고 바로 원래 모델 그대로 갖다 쓰는 거예요.
원래 모델을 하나도 건드리지 않고 원래 머리를 건드리지 않고 그 사람이 뭐라고 얘기했으면은 그거 다음에 약간 이제 그걸 가지고 해석해가지고 이제 분류하는 거지 예를 들어서 전의 학습을 구체적인 예를 들면은 여러분 뭘로 할 수 있냐면은 원래 이미지 넷이라고 이제 10천 가지 모델이 천 가지 이미지를 구분할 수 있는 게 있어요.
예를 들어서 천 가지 이미지를 구분할 수 있는데 천 가지밖에 안 되니까 낙타는 구분 못하는 거지 이해돼요.

참석자 1 13:19
여러분 낙타랑 말 품종 같은 거 구분 못한다고 근데 우리가 말의 품종을 구분하고 이러려고 그러면은 약간 더 학습을 시켜야 될 거 아니에요 그렇죠 근데 전이 학습할 때 아까 제일 두 가지 방법 중에 한 가지는 원래 이제 원래 이미지 넷이 일단 구분을 해 그냥 이미지 그대로 놔두고 구분한 다음에 그다음에 얘가 예측한 거 보고 얘는 뭐에 가까울 것인지 아까 말 품종 중에서 말 품종이나 낙타인지 이런 게 구분하는 거를 하는 것만 이제 새로운 웨이트만 새로 이제 학습시켜가지고 원래 원래 웨이트는 하나도 건드리지 않고 그렇게 학습시키는 방법이 있고 그다음 나머지 하나는 원래 이제 학습시켰던 이미지 넷 있잖아요.
이미지 넷 같은 원래 뉴럴 네트워크를 약간 거기도 웨이트를 바꿔버리는 거지 그게 파일 튜닝이에요.

참석자 1 14:09
그러니까 원래 있는 원래 있는 머리 있죠 원래 있는 뉴럴 네트워크 이 메이터 받아온 거를 약 다 학습을 시켜버리면은 파일 튜닝이고 그걸 그대로 두지 않고 뒷부분만 이렇게 바꿔가지고 학습시키는 게 다른 또 그냥 제로s 러닝이고 제로샷이라 이라고 안 하고 그걸 뭐라고 그러냐 지금 내가 이름을 까먹었는데 그것도 어쨌든 그 방법도 있어요.
이름이 없어 없어 사실은 나도 정해야 될 것 같아요.
두 가지가 있어요. 파이트윙 하는 것과 파이트윙 안 하는 것과 그래요.
보통 전이 학습이 두 가지가 있어요. 파이트 하는 거 파이트윙 안 하는 거 파인 튜닝을 하는 거는 어쨌든 원래 모델 원래 웨이트 건드리는 거 파인 튜닝 안 하는 거는 원래 모델 안 건드리고 그냥 뒤에 부분만 그냥 건드리 붙여가지고 하는 거 이렇게.
근데 두 가지 다 유용하거든요. 아무래도 파일 튜닝이 더 좋겠지.
그쵸 그래서 사실 여러분은 파이 튜닝을 잘해야 되고 이 책에도 파일 튜닝이 나와요.

참석자 1 15:02
파이 튜닝이 우리나라 말로 뭐냐 미세 조정 미세 조정이죠.
미세 조정 미세 조정 학습 그쵸 그게 다 8.3절이 나오는데 우리 교과서에서는 알겠죠.
근데 이게 제가 재미있는 게 이 교과서 말고 이게 지금 1판이 1판이 한 2018년쯤 나왔다가 우리 이게 펜스 플로우가 너무 바뀌었잖아요.
아까 테라스로 2019년 9월에 근데 이게 지금 2021년 2년인가 그때쯤 나왔는데 이 판으로 완전히 75% 바꿨다고 재밌는 게 이 책에 맨 뒤에 보면은 아닌가 안 적혀 있네.
여기 있어 안 적혀 있구나 여기 있다 여기 있다 다 있다.
여기 밑에 뒷장에 여기 보면 여기 있잖아요. 일판 대비 75% 변경이라고 적혀 있죠.
이런 책이 다 있나 있죠 여러분 일판 대비 75%를 변경하는 책이 어디 있어요?
그쵸? 대단하죠. 여러분 그래요. 그리고 이 책 뒤에 또 뭐가 나왔냐면은 이 책 같은 출판사인데 여기는 지금 딥러닝 위드 파이썬이잖아요.

참석자 1 16:10
딥러닝 그도 자바스크립트라는 책이 나왔거든요.
그것도 구글 딥마인드 사람들이 만든 거예요. 이분 있잖아요.
이 저자 저자가 누구냐 프랑스와 숄레 적혀 있죠. 이분이 어느 나라 사람 같아요 여러분 프랑스 사람이에요.
프랑스 와 왔는데 프랑스 가는데 진짜로 이 사람이 지금 딥마인드에 있어요 딥마이드가 뭔지 모르세요?
여러분 혹시 구글에 구글 인수 합병한 사실 구글이에요.
그러니까 원래 알파고 하다가 구글한테 인수 합병되고 계속 구글에 있지 그냥 지금도 특히 구글 사람들이 구글 딥마인드 팀이라고 부르죠.
그래서 이제 회사가 아니라 팀이 됐으니까. 근데 그 사람이고 여기 구글 딥마인드 팀에서 캐라시도로 파이썬으로 하는 사람들도 있고 자바스크립트를 하는 사람들도 있는 거예요.
자바스크립트를 하는 사람들이 나중에 책을 또 썼거든요.
그 책이 제가 지금 저번에 아직 못 보여드렸는데 기톱으로 제가 공개한 것 중에 자바스크립트 있잖아요.
그쵸?

참석자 1 17:00
그렇죠 거기에 책이 나왔는데 그 책은 근데 이 책에 있고 일부 뺏기고 막 약간 그랬더라고요.
막 겹치는 게 있어요. 근데 전의 학습이 3장에 나와 되게 빨리 빨리 엄청나게 중요하다는 얘기지 한마디로 이 책은 일판 등기 변경을 어마어마한 75%가 했는데도 내용만 바꿨지 그렇게 순서는 안 바꿨거든요.
근데 요즘 나오는 책이 전이 학습이 되게 앞부분에 나온다고 뭔 얘기인지 알겠어요 여러분 전의 학습이 되게 중요하다 그러니까 진도를 앞에 빨리 나가야 돼.
그쵸 그래야 중요한 거 할 거 아니야 그쵸 근데 제가 자바스크립트 책으로 참여할 수는 없죠.
거기 또 뒤에 내용이 또 너무 이상해. 그냥 자바 스크립터로는 자바스크립트는 별로 어쨌든 주류가 아니잖아요.
파이썬이 주류잖아요. 그러니까 어쩔 수 없이 자연어 처리 이쪽은 거의 저자가 되게 많아요.
저자가 많은 책은 약간 의심이 되지 어떤 부분 되게 좋고 어떤 부분 되게 나빠요.
거기 앞부분은 되게 좋은데 뒷부분은 되게 이상해.

참석자 1 17:52
진짜로 그래서 교육 가설은 제가 그냥 참고만 앞부분은 너무 좋아요.
앞부분은 전야스 나오고 이런 부분은 너무 좋아요.
이 책보다 더 좋아요. 거기는 완전히 힘을 엄청 잔뜩 줬죠.
그러잖아요. 그래서 앞부분 보고 이렇게 좋은 책에다가 뒷부분 보고 이렇지 그러니까 그런 거죠.
저장 하도 많으니까 그런 거죠. 어쨌든 그런 상황이고 지금 8.3절이 전약기고 거기 파이프닝도 나오고 여기 보면은 여기 그러네.
그냥 피처 익스트렉션이라고 부르는구나 미안해요.
그 용어가 트랜스폼 러닝에 크게 두 가지가 있는데 여기 다 적혀 있네.
83.1절 83.2절 적혀 있잖아요. 보이죠 여러분 보여요.
여러분 지금 미리 알아둬요. 여러분 지금 저도 확실히 정리하니까 여러분 시험에 낼게요.
나중에 8.3절에 8.31절은 마지막에 물로 끝나요.
여러분 특성 추출로 끝나죠 그쵸? 8.32절은 미세 조정하게 끝나죠.

참석자 1 18:47
여러분 이해됐어요 봤죠? 지금 방금 봤죠 미세 전정막이가 영어로 뭐라고요?
파일 2니 그다음에 특수 추출이 피처 익스트랙션 피처 알죠?
여러분 피처 FEA 그쵸 그쵸 익스트랙션 특성 추출이잖아요.
그쵸 전이 학습이 크게 두 가지가 있는 거예요. 특성 추출 또는 파일 뷰닉 특수 추출은 그냥 거기서 걔를 건드리지 않는다고 웨이트를 다시 웨이트 원래 있는 오픈 오픈 웨이트 받은 거 있잖아요.
걔를 건드리지 않고 그 뒷부분만 내가 학습시켜가지고 이해돼요.
여러분 실제 출력 부분 쪽만 약간 감은 오죠 여러분 그렇죠 되게 조금만 학습시키는 거고 미세 조정은 원래 가져온 그 웨이트를 건드리는 거야.
알겠어요? 여러분 무슨 그다음에 프리트레인을 타고가 아니라 어서 갖고 오는 거 있어 프린트레인은 어디서 돼 있는 걸 내가 갖고 온다고 생각하면 돼요.

참석자 1 19:43
사실은 이제 로드를 하는 거지 어디 세이브 된 거를 누가 세이브 해간 거를 로드를 해놓은 거지 내가 해놓은 걸 수도 있지만 보통은 이제 이런 거는 이미 유명한 프라블럼들에 대해서 풀어놓은 것들이 많이 있어요.
무슨 경진대회 이런 게 있어요? 딥러닝 경진대회 이런 것들 유명한 문제들이 아주 일반적인 문제들이지 그거를 가지고 와서 내가 하는 거라고요.
그리고 이게 지금 제가 처음에 맨 처음에 시작할 때 허깅 베이스라는 거 제가 얘기했었잖아요.
허깅 베이스 허기 페이스가 트랜스포머 라이브러리를 잔뜩 모아놓고 온갖 거 하는 거라 그랬잖아요.
근데 그 허기 페이스의 트랜스포머는 전부 다 거의 언어 모델들이거든요.
비전 쪽도 있지만 거기에 온갖 모델들이 있는데 걔네들을 파악을 하고 갖다 쓰는 게 굉장히 중요하겠죠.
그러니까 그거는 이 수업에서 다 할 수는 없는데 여러분이 알아서 하시라는 거지 내가 자꾸 소개해 주겠다고 알겠죠.

참석자 1 20:31
나도 모르고 계속 올라올 텐데 뭐 거기 그렇죠 거기 그래서 허기 케이스를 쓴다.
이 얘기는 또 허기스 파이스를 쓴다는 거는 이제 여러 가지 측면이 있는데 그중에서 이제 오픈 소스 트랜스포머 라이브러리를 가져오겠다 이걸 하면 그다음에 중요한 게 오픈소스 모델 오픈 웨이트 모델을 가지고 온다는 거지.
웨이트 그래서 거기에 있는 온갖 라이브러리들 중에서 라이브러리 온갖 모델 중에서 머리가 있는 웨이트가 있는 모델 중에서 적당한 걸 가지고 와서 내가 피처 익스트렉션만 하든지 파인 튜닝만 하든지 이런 식으로 해가지고 여러분이 되게 대단한 일을 한 것처럼 보일 수 있는 거예요.
졸업 논문에도 그것만 해도 그냥 내 아버지 사실은 움직이신 거야.
사실은 회사에서도 그것마저도 대단하네 이렇게 된다고 하세요.
왜냐하면 회사에서도 사실은 별 사람이 다 있으니까 사실 그렇죠 되게 욱한 사람들이 태반이지 미안해요.
여러분 여러분이 생각보다 똑똑해요.

참석자 1 21:29
그냥 학생이구나 이래요. 나는 지금 기대하는 사람이 있어.
직원분이 오시나 그래요. 왜

참석자 3 21:37
용어로 전이라

참석자 1 21:38
트랜스퍼 트랜스퍼가 전달받아서 쓰는 거니까 저희가 여러분 전달해 주는 거잖아.
지식을 전달받아서 하는 느낌이 들지 않아요. 그 좋은 이유 한번 생각해 보면 굉장히 좋아요.
왜 전이냐고 그쵸 뭔가 전달받아서 하는 거잖아요.
누가 많이 잘해놓은 거를 가지고 내가 활용하는 거잖아요.
지금 제가 전이하고 있죠 여러분 그쵸 제가 전에 밖에 사무실

참석자 1 22:11
예 네 오고 있는 중인 거예요. 지금 그렇죠 습니다.
그걸 어떻게 알았지 그래요 어떻게 거기서 보이나 보지 아니요.
아까 그래 고마워요. 어쨌든 오고 계시대요.

참석자 2 22:32
그러면 그 뭐지 파인트닝이랑 피처 익스트레션 쓰는 경우를 어떻게 나누나요?

참석자 1 22:38
일단은 일단 시간 없으면 피처 익스트리션 먼저 해보고 그냥 제일 심플하게 그리고 좀 여유가 되면 파인투이 가는 거지 여유가 되면 트레셋이 보통 잘 되면 그냥 끝이잖아.
사실은 그게 좋잖아요. 파이프닝 어쨌든 학습을 하는 거 트레이닝 시키는 거는 지금 사실 좀 예를 들어서 피처 섹션이 얼마나 좋냐면은 지금 아까 허깅 페이스 인 페이스 허깅 페이스 모델들 갖고 왔잖아요.
그거에다가 그냥 내가 붙여가지고 하는 거니까 내가 조금만 뉴럴 네트워크 붙여가지고 웨이트 몇 개 없는 걸로 학습시켜도 되는 거잖아요.
이해돼요. 여러분 내가 뉴럴 네트워크 여러분 진짜 머신러닝 정도로 굉장히 사실 이 머신러닝에서는 거의 곱하기 더하기 끝이잖아요.
머신러닝 곱하기 더하기 끝이야. 근데 이쪽에서 이제 우리 뉴럴 네트워크 액티베이션 통해 통과하는 것 정도 뭔지 모르지만 아직 배울 거예요.
이제 궁금해하고 있어 봐요.

참석자 1 23:30
그런데 허기 페이스에서 이렇게 쪼아 붙여가지고 학습시키는 게 굉장히 쉬운 일인데 5차 변파를 거기까지 5차 나중에 이제 웨이트 파라미터 조정한다 그랬잖아요.
걔를 내가 만들어 놓고 조그만 뉴라토프 하면 되잖아요.
근데 파일 터닝 하기 시작하잖아요. 파인 튜닝이라는 거는 그 빌리언 이런 거를 내가 지금 학습시켜야 되는 거잖아요.
근데 거기서 어디까지 시킬지 내가 정해야 되잖아요.
그러니까 일단 그걸 일단은 이제 백프라프로케이션을 하면서 백프로케이션 미세 조정하려고 그러면 파라미터 일단 로딩을 했다가 오차 값을 전파를 해야 되거든요.
우리가 어느 정도 터졌는지를 다 웨이트에다가 곱하고 더하고 해야 되잖아요.
빼기 해야 된다고 이제는 근데 그러려고 그러면 계산량이 어마어마해지잖아요.
보통 컴퓨터는 잘 안 되기 시작하지 근데 피처 스트리션은 잘 되지 이해돼요.

참석자 1 24:19
그러니까 여러분이 이 노트북이 40 70이면은 파인 튜닝은 너무너무 잘 되는데 알파인 튜닝이 아니라 진짜 익셉션은 4090이 아니면 이제 파이 튜닝이 안 되는 거야.
파이 튜닝이 좀 컴퓨터가 되게 좋아야 된다고 메모리가 어마어마하게 필요한 거죠.
이해돼요. 그래가지고 그것 때문에 그렇게 너무너무 이제 원래 웨이트를 건드리는 게 너무 약간 파이틀링이 쉽지 않은 일이라고 솔직히 이제 엄청나게 웨이트가 큰 것들은 여러분 GPT 같은 거는 여러분 우리 학교 아무리 갖다 줘도 소스 갖다 줘도 웨이트 갖다 줘도 돌리지도 못해 그쵸 어마어마하게 매몰이 많이 들어가니까 그거는 이제 심지어 이제 돌리지도 못하는 거고 파인트닝 하려고 그러면은 더 필요하다고 메모리가 더 사실 이제 그냥 전에 제가 얘기했잖아요.
그냥 추구하는 게 있고 학습하는 게 있다고 그랬잖아요.
추론하는 건 이 방향인데 그렇죠 학습하는 건 이 방향이잖아요.
여러분 거꾸로 그 알아서 보세요.

참석자 1 25:16
알겠죠 그쵸 근데 그거 하기 위해서는 계산량이 더 필요하니까 그쵸 근데 파이 튜닝은 사실 그래서 그거를 나 상당량을 메모리에 올리고 해야 되기 때문에 안 될 수가 있다는 컴퓨터가 나쁘면 돈이 많이 드는 일이라고 알겠죠 그래요.
그리고 미리 한 마디 더 하면 사실 지금 유행하는 온디바이스 AI 쪽에서는 아니면 또 그쪽도 트랜스포머 쪽은 워낙에 웨이트가 양이 많으니까 그냥 파이 튜닝도 그냥 그렇게 원래 웨이트를 건드리는 식으로 안 하고 로라라고 그래서 로우 레이크 어레이라고 그래가지고 들어봤어요.
여러분 안 들어갔지 아무도 그래요 한지 2년 됐는데 그것도 그러니까 옆에다가 별도의 매트리스를 만들어 가지고 별도의 RA 만들어가지고 나중에 해줄게 해가 아니고 너무 지금은 거의 로라로 변하고 있어.
로라를 거의 다 쓰고 있으니까 로라라는 게 원래 파이트닝을 하더라도 원래 베이트를 건드리지 않고 내가 아까 전에 지금 보통 피스 섹션은 뒷부분에다가 왜 이럴레트 붙여서 하는 거 있잖아요.

참석자 1 26:19
학습을 근데 이제 학습을 어쨌든 웨이트 전파를 다 뭔가 중간중간 많은 수많은 웨이트들을 다 메모리 로딩하는 거 너무 힘드니까 옆에다가 별도의 어레이 만들어 가지고 걔만 학습시켜서 뭔가 협조 짬뽕한 결과가 학습된 결과가 나오게 됐어요.
혹시 리모컨 리모컨 문제인 것 같아 잠깐 오시면 안 돼요.
전화로만 얘기하시는 거예요. 고마워요. 패스트 리모컨 리모컨으로 그럼 어떻게 제가 여기는 왜 안 나와요?
근데 큰절이 선생님

참석자 3 26:53
지금 네 리모컨 가지고 컴퓨터 화면도 안 나오거든요.
지금 네 이거 사진 하니까 이거 화면 아예 자체가 안 틀어져 있는데 안 그 본체는 본체는 틀어야 이 좀 해봐야겠다.
진짜 네 이거 화면 30분 나왔는데

참석자 3 27:19
컴퓨터를 껐다 샀다.

참석자 1 27:20
잠깐만요. 자금액 안 껐죠 안 되잖아

참석자 1 27:31
그럼 절대로 안 오시네. 컴퓨터 모를 그래서 어쨌든 수업을 알차게 보내야 되니까.
그래서 여러분 질문 많이 하니까 좋네. 그래서 뭐 내가 뭐 얘기했지 로라라는 거 있다고 근데 지금 이렇게 얘기하면 참 오테니까 나중에 슬라이드 만들어서 보여줄게요.
여러분 네네. 네가 슬라이드 만들어 보여줄게요.
그거는 거의 지금 그게 그게 대세거든 놀라쓰는 근데 이제 교과서가 못 따라오지 이쪽은 워낙 빨리 발전하니까 어쩔 수 없죠.
그렇죠. 그래서 새로 나오는 교과서들을 보면 새로 나오는 책을 보면서 거기서 어떻게 발전하고 있는지를 볼 필요가 있죠.
제가 그래요. 그래서 여러분은 어쨌든 알겠죠. 무슨 얘기인지 지금은 전혀 학습이 되게 중요 중요해 현장 산들이 엄청나게 중요하다는 거야.
알겠죠 그리고 질문 잘해야 되는데 피처 익스트레스 나는 확실하게 이제 그 용어가 빨리 스트레스라고 빨리 진행해.
알겠죠 좀 늦어요. 그리고 계속 하면은 제가 다시 보여드릴까요?
오시면 안 됩니다.

참석자 1 28:26
그다음에 9장 9장은 지금 로딩 중에 있어요. 그다음에 하나는 네 지금은 떠요 떴어 어떻게 떴어요?
네 그리고 스는 그다음에 h 10장이 12월이고 11장이 텍스트로 돼 있죠 그쵸 텍스트 11장 11장이 텍스트인데 텍스트 하다가 11.4절에서 여기 11.4절에 통수가 없어가지고 7.4절에서 뭐가 나와요?
트랜스포머라고 나오죠. 여러분 그쵸 트랜스포머 지금 이게 허기 페이스가 트랜스포머 라이브라고 했잖아요.
그쵸 트랜스포머 그러면 그걸 배우는 거예요. 중요 재미있는 게 이 책은 트랜스포머를 짰어요.
진짜 코드를 다 줘요. 그러니까 트랜스포머가 어마어마하게 큰 건데 이 사람은 정말 훌륭한 인사이트로 정말 이 사람은 다 짰어.
트랜스포머를 그냥 우리가 소스를 보고 다 이해할 수 있게 해놨어요.
그래서 진짜 인사이트를 줘요. 봅시다. 여러분 그리고 나올 여기 트랜스포머 아키텍처 안에 보면은 17.4.1에 447쪽이라고 적혀 있는데 어쨌든 셀프 어텐션이라고 적혀 있잖아.

참석자 1 29:36
어텐션 어텐션 어텐션에 대해서 이해하는 게 되게 중요해요.
여러분 트랜스포머를 안 쓰더라도 어텐션 자체를 이해하는 게 더 필요하다고 그게 이제 많은 인사이트를 주기 때문에 알겠죠 봅시다.
나중에 그다음에 12장이 생성 모델이죠. 생성 모델 있죠?
생성 생성 모델이 이제 제너러티브 i잖아요. 그렇죠 아까 GPT의 첫 번째 키워드 제너러티브 그쵸 사실 생성 모델은 생성을 하는 것뿐이지 사실은 원래 다른 학습에서 뭔가 변형된 거라고 볼 수 있어요.
여러분 그러니까 이거는 이것도 이제 생성형 AI를 위한 아주 특별한 뭐가 있다고 생각할 수도 있지만 사실 특별한 뭐가 있긴 있는 것도 있지만 앞에 걸 다 기반으로 한 거라서 이걸로 바로 하는 건 바람직하지는 않아요.
알겠죠 이게 뒷부분에 있는 게 다 이유가 있는 거죠.
그쵸 그래 어쨌든 생활 AI는 최대한 여러분 많이 활용해야 되고 그런데 이제 원래 앞에 내용을 다 차곡차곡 쌓아가면서 머신러닝을 모르면 안 되는 것처럼 그렇게 공부를 합시다.

참석자 1 30:41
여러분 그래서 이제 어쩔 수 없이 교과서로 그냥 바로 들어가서 1장부터 볼까요?
1장 교과서 종류가 많으니까 1장 1장에 가면은 28쪽 그래 28쪽 28쪽 28쪽 보세요.
여러분 28쪽 28쪽에 그림이 바로 탁 나오죠 그쵸 맨 아예 그쵸 28쪽에 뭐라고 나와요?
여러분 인공지능 머신러닝 딥러닝 단계를 보여주고 있어요.
제 그림에도 있어요. 똑같이 저는 이거를 이런 교과서에 아무것도 안 나올 때 맨 처음에 그렸는데 그거를 어쨌든 알겠죠.
근데 이게 되게 중요한 그림이야 그쵸 머릿속에 넣어놓으세요 여러분 이걸 뭘 보여줘요?
모든 딥러닝은 머신 러닝이야 그쵸 모든 머신러닝은 인공지능이에요.
그쵸 여러분 그쵸 근데 아닌 것들이 존재한다는 게 중요하죠.
구분하는 게 그렇죠 그러면은 딥러닝은 가치 있는 거고 딥러닝이 아닌 머신러닝이나 AI는 다 가치가 없는 거냐 아니죠 다 기반으로 하는 거예요.

참석자 1 31:41
그 기능들이 원래 내용들 그리고 가벼운 거는 머신러닝으로 그냥 끝내도 되는 게 바람직하지 딥러닝 아닌 걸로 알겠죠 그래요.
그래서 그리고 원래 원리는 자체는 그대로 가는 거기 때문에 그리고 이거는 뉴럴 네트워크에 특화된 거고 이건 뉴럴 네트워크가 아닌 거야는 것도 구분할 수 있어야 되고 그래요.
계속 갑시다. 그래서 인공지능이 뭐냐 이렇게 얘기하는 건 제가 열심히 저번에도 얘기했으니까 넘어가고 31쪽 가볼래요.
31쪽 30조 31쪽 여기 이제 머신러닝 먼저 설명하죠.
당연히 그렇죠 머신러닝 그래서 여기 31쪽 맨 위에 그림 보면은 그림 1 2에 전통적인 거랑 머신러닝 구분해 놨어요.
그쵸 그 전통적인 거랑 머신러닝 근데 여기 지금 머신 러닝에서는 해답을 주는 걸로 적어놨죠.
그쵸 여러분 그렇잖아요. 근데 이거는 제가 제가 이 그림이 동의하지 않아요 난 이거 아니야 이거 이 사람이 틀렸다고 생각해요 여러분 테레을 주는 건 뭐예요?

참석자 1 32:33
여러분 원래 제가 지난 시간에 대충 했는데 원래 머신러닝을 원래 머신러닝을 학습을 크게 세 가지로 사람들이 구분하고 있잖아요.
지도 비지도 일단 구분하는 게 맞고 그쵸 슈퍼바이즈든 언슈퍼 바이즈든 그리고 그거 말고 이제 이인포스먼트 러닝 이렇게 한다고 그랬잖아요.
사실은 슈퍼바이즈 슈퍼바이즈로 끝나지만 이름 용어 자체가 그쵸 어쨌든 그렇게 할 수 있잖아요.
그렇죠 그래서 지금 슈퍼바이지드 러닝에서는 레이블이 필요하고 정답이 필요한데 다른 데는 그렇지 않아요.
지금 이 그림은 뭘 보여주고 있어요? 그래서 지금 이 머신러닝이라기보다는 슈퍼바이즈 듯 머신러닝을 보여주고 있는 거지 이해돼요.
여러분 그냥 머신러닝이 다 이렇지 않다고요. 그 이름이 틀렸다고 리젝트 만약에 전화로 논문이 왔으면 내가 리뷰 했으면 이렇게 하면 안 되지 그쵸 이해되죠 그래서 많은 정보들이 틀려요.
여러분 그렇기 때문에 여러분 채집 생성형 AI를 믿을 수가 없지 이해돼요.

참석자 1 33:30
여러분 머신러닝 이거 틀린 그림이야 진짜로 슈퍼 바이젠드 머신러닝은 이렇다고요?
알겠죠? 그래요. 어쨌든 dh도 학습 같은 거는 정답 값 안 주잖아요.
해답 값도 안 주고 이 강아지도 그래요. 여러분 사장 값이라는 거 없어요.
보상 감수만 주지 어떻게 할지 안 알려주고 니가 잘해 봐 정수가 느끼면 돼 이러는 거잖아요.
그러는 거죠. 여러분 그래요. 그래서 어쨌든 이 교과서를 다 맹시하지 마세요.
여러분 그리고 모든 교수님들 수업 마찬가지지만 저도 저만의 뭔가 나름의 시어리가 있잖아요.
여러분 그래서 그래서 이제 교과서는 내가 여러분 공부 잘하라고 하는 것뿐이지 교과서에서 틀린 거를 제가 이렇게 얘기해 뒀는데 시험에서 교과서에 이렇게 나왔는데요.
하면은 미리 얘기해야 돼. 그래서 나랑 디베이트 해가지고 오케이 했으면 상관없지만 내가 분명히 아니라고 그랬는데 그거를 교과서에 나왔다고 그렇게 시험 봤다고 봐달라고 하는 말도 안 되는 소리.

참석자 1 34:19
그렇죠 원래 이 사상사가 그런 거지 그렇죠 우리 앞에 그럼 왜 배우는데 그렇죠 어쨌든 알겠죠.
여러분 그래요. 그래서 아직도 안 되는군요. 그래요.
그다음에 계속하면은 32쪽으로 넘어가면은 데이터에서 표현 학습하기 이렇게 돼 있는데 그쵸 이게 리프레젠테이션 러닝이라고 그래가지고 그쵸 표현이 여러분 영어로 리프레젠테이션이에요.
리프레젠테이션 영어로 다 뭐라고 그러는지 되게 중요하고요.
그리고 여러분 생성 AI를 이용할 때도 그냥 우리나라 말로 물어보면 대답 이상하게 해요.
많이 왜냐하면 학습된 데이터가 적잖아요. 그쵸 영어가 훨씬 많으니까 그래서 영어로 웬만하면 다 알고 있어야 되고 중요한 건 이제 디플이나 아니면은 여러분 번역기 이런 거 돌리면은 걔네들이 맥락을 잘 모르니까 번역 이상하게 한다고 그래서 여러분이 정확한 용어를 알아야 돼요.
알겠죠. 다시 그래서 강조하지만 이거는 영어로 효율 학습하기는 리프리젠테이션 러닝이에요.
알겠죠 표현 학습이에요.

참석자 1 35:14
이게 중요한 부분인데 어쨌든 그래서 이게 원래 데이터는 전에도 얘기했지만 데이터는 사실 우리가 뭔가 의미를 부여해야 되고 그쵸 그래서 정보가 되고 그렇죠 마찬가지로 지금 딥러닝을 주로 쓰는 게 이제 뭔가 새로운 지식 창출 이런 건데 레이블을 새로 붙이는 것도 있고 그러기 위해서는 개의 뭔가 데이터를 뭔가 추상화시켜야 돼요.
지금 사실 여러분 지금 내가 말하는 것도 다 추상적인 거잖아.
그쵸 뭔가 이렇게 여러분 다 알아듣는 거잖아요. 그쵸 그래서 뭔가 좀 인공지능적인 걸 하려고 그러면 전부 다 표현을 약간 다 뭔가 추상화시키는 게 필요한 거예요.
그렇죠. 그래서 이게 데이터 로데이터는 엄청나게 많지만 그거를 리프리젠테이션 러닝한다는 거는 뭔가 중요한 특징들만 추출해가지고 뭔가 표현을 바꾼다는 거지 이해돼요.

참석자 1 35:57
여러분 그래서 딥러닝도 사실은 그렇게 해가지고 나중에 뭔가 일이 큰일을 하는 거고 여러분도 지금 제가 쏟아붓고 있는 어마어마한 이제 많은 것들에서 뭔가 표현을 내부적으로 바꿔가지고 정장하고 있는 거지 그래요.
그리고 일단 지금 33쪽에 그림을 보면은 이게 데이터가 일단 형태가 여러 가지가 있을 수 있는데 지금 이 데이터는 생긴 게 여러분 일단 여러분 일단 이거는 카티시안 이거 뭐 데카르트 자표겠죠 그쵸 좌표기잖아 그냥 2차원 좌표기잖아요.
여러분 2차원 좌표기 볼 줄은 다 알잖아. 근데 이거 유치원생은 몰라.
그쵸 뭔지 알잖아요. 여러분 이건 뭐예요? 사실은 x y x장 y라는 좌표 값이 있어요.
그쵸 그래서 지금 각 데이터는 동그라미인데 각 동그라미는 사실은 어떤 데이터로 표현되고 있냐면은 x 좌표가 y 좌표가 두 가지예요.
그쵸 그쵸 원래 이렇게 돼 있는 거죠.

참석자 1 36:49
그거는 원래 로 데이터고 그쵸 그다음에 지금 여기 정보가 하나 더 있어요.
여러분 뭐가 더 있어요? x y 값으로 끝났나 이게 지금 데이터가 뭐가 있어요?
또 뭐가 있어요? 색깔이 표시돼 있다. 그쵸 색깔 색깔은 사실 여기 2차원으로 표현되는 게 아니잖아요.
사실 이건 뭐예요? 그러니까 이게 3차원이야 그쵸 3 자표기가 있고 제트좌표기에서 1 아니면 0 이런 거지 사실은 빨간색을 1로 보고 흰색을 0으로 볼 수 있잖아요.
이해돼요. 여러분 이거 사실 3차원이야 그쵸 빨간 색깔 표시하는 순간 3차원이에요.
그쵸 이해됐어요.

참석자 1 37:21
여러분 됐죠 그래서 지금 여기는 예시 데이터에서 이거에서 여기 보통 이렇게 표현하는 거는 이 사람의 의도는 지금 원래 로 데이터 자체가 XY로만 주어지는데 그걸 가지고 제 값을 뽑아내는 거지 제값 이해돼요 제트 값이 그래서 빨간색이 흰색인지 그쵸 이 빨간색이 있으면 1 흰색이면 0 이렇게 뭔가 내놓으라는 거지 그쵸 근데 이게 그냥 x y 값만 봐도 사실 우리가 지금 쓱 보이죠.
대충 대충 대충 어떻게 보여요? 여러분 그럼 이렇게 이런 선 있죠 여러분 제가 거꾸로 다 이렇게 뭔 얘기지 이런 선으로 딱 끓으면은 이쪽은 빨간색 이쪽은 흰색인 거 보이잖아요.
그쵸 오른쪽 위는 빨간색 왼쪽 아래는 흰색인 거 보이죠.
그러면 이거 이렇게 학습시키면 되게 편할 거 아니에요?
바로 x 와이프만 주어지면 이게 빨간색인지 흰색인지 알 수 있잖아요.
그쵸 그거 근데 이거 이 데이터는 보니까 이게 선이 자르는 선이 선형이면 되겠다.

참석자 1 38:19
그쵸 여기 지금 그림 보면은 여기 보게 34페이지 아래쪽에 보면 2 4 보면은 원본 데이터가 맨 처음에 나와 있고 그렇죠 그다음에 좌표 변환한 거가 지금 있고 3번에 더 나은 표현이라고 돼 있잖아요.
그쵸 더 나은 표현은 어떻게 돼 있어요? 완전히 그냥 빨간색 흰색이 다 구분이 돼버렸고 도표 변환한 것도 빨간색 색 구분시키긴 했는데 그래 이렇게 도표가 약간 오르 튀어 있죠 그쵸 뭔 얘기하는지 알겠어요 여러분 이렇게 좌표를 변환시켜서 학습하는 방법이 또 머신러닝에 있겠죠.
근데 사실 이거는 여러분 리니어 리그레션이라고 해서 리니어 리그레션이라기보다 어쨌든 이게 보면은 선형적으로 뭔가 딱 구분이 되는 게 보이죠.
여러분 선 자체가 선원 하나만 있으면은 구분이 되잖아 그쵸 그래서 그런 되게 심플한 거고 이런 거를 이제 학습을 시켜서 자동으로 하는 게 좋겠다는 생각이 들잖아요.

참석자 1 39:18
그쵸 이거를 맨날 어떤 이미지 표 값이 나와도 이건 빨간색이겠지 흰색이지 한번 이거 보면 알 수 있잖아요.
그쵸 그렇죠 여러분 그렇죠 이거 보면 우리가 그래요.
근데 왜 그분은 왜 안 오신대요? 안 오신대요 몇 번이에요?
몇 시야 이지 4355 0 3 1, 3 5 5 4 1, 3 5 0 3 6 6기 화면이 안 돼 아니 이거 안 나오는 건 없는데 저것만 나올 수도 있어요.
이게 지금 이렇게 하나 나오거든 그게 나와요. 그러면 할 말이 없네 번 해주면 누가 알아 누 아무도 안 했네 이쁘네요.
그러면 그게 안 이걸로 구분 자력만이라고 돼 있네요.
이 나쁜 사람 그 말 하지 복제 됐어요 이러니까 안 올라갑니다.
됐네 됐어요. 이러니까 안 올라가시네요. 이해가 됐어요.
네 감사합니다. 됐네. 안 오면 안 오는 게 이유가 있겠지.
그 그분도 학습이 돼가지고 여기서 맨날 부르는 거는 이런 일이겠지 하고 안 오는 거예요.
진짜 되게 썰렁하네. 그래요.

참석자 1 40:35
그래서 내가 지금 뭐 떠들고 있었냐 그래서 뭘 하고 있었지 중요하다고 지금 자꾸 머릿속에서 신호를 줘가지고 이게 자꾸 중요하다고 지금 제가 그래서 33페이지 했어요.
그쵸 33페이지에서 데이터가 어쨌든 리프리젠테이션 러닝에서 표현에 대해서 그렇죠.
학습하는 거에 대해서 했는데 표현을 이제 바꾸는 거를 여기서는 이제 XY 축 이거 변하는 거 그런 얘기를 했는데 이거는 이제 머신러닝에서 주로 하는 짓이고 딥러닝 쪽에서 딥러닝이 별로 안 필요한 데이터잖아요.
사실 이거는 왜냐면 데이터도 선행적으로 구분이 되잖아요.
그쵸 그런 거였고요. 그래서 지금 4분 남았는데 우리 쉬는 시간까지 그래도 이거를 계속 보는 것보다 내 슬라이드가 나은 것 같아요.
슬라이드 다 키 분 제 슬라이드라고 보는 것 같아요.
슬라이드 본 다음에 읽어보면 더 이해가 잘 돼서 제 슬라이드로 할게요.
저도 이제 책이 100% 마음에 드는 건 아니라서 제가 이 책 쓰는 거 너무 이 책이 너무 고맙긴 한데 오늘 책이 나오지

참석자 1 41:53
어

참석자 1 41:59
그래서 여러분 이거 제가 했던 거 여기서 다시 여러분 이거 다 있잖아요.
그쵸 다 있어요. 여러분 교과서 말고 이걸로 하다가 다시 교과서 넘어올게요.
그리고 이 내용 보면은 저도 이렇게 열심히 막 국어과 갔다 왔고 하다 보니까 학습이 돼서 나중에 전화하시면 시간이 없더라고요.
그래서 최대한 빨리빨리 하려고 하는 거죠. 그렇죠 지금 여기 보면은 제가 이거 강의 자료 올려놓은 거 있잖아요.
맨 처음에 올려놓은 거 그거 다시 올렸거든요. 사실은 이것도 추가해가지고 이런 거 그냥 새로 다운로드 받으면 돼요.
여러분 별거 지난번에 사실은 추가 시 변경 기는 별로 나간 것도 없고 해서 그냥 새로 올렸어요.
그래서 여기 지난 시간에 얘기했던 설명할 때 좀 이렇게 약간 보충해 놨어요.

참석자 1 42:46
그렇죠 그다음에 여기 이거 방금 얘기했듯이 지도 학습 기지도 학습 그쵸 지도 학습에서는 레이블이 있는 거 정답이 있는 거고 강화랑 비지도 이런 거 처음에 지난 시간에 좀 했죠.
그쵸 비지도 좀 약간 다 가지고 교과서에 있는 것도 보여주면서 좀 했었어요.
그렇죠 말아 먹으라고 그랬었고 이제 여기 처음 하는 거죠.
여기 이슬라이드부터 그렇죠 그래서 머신러닝에 세 가지가 적혀 있는데 이거는 지금 딥러닝이랑 아무 상관없이 얘기하고 있는 거예요.
그쵸 딥러닝에 근데 다 적용이 돼요 안 돼요. 이게 여기 머신러닝 얘기지만 이게 딥러닝이 적용이 되는 거예요.
안 되는 거예요. 머신러닝에서 얘기하는 모든 것에 딥러닝이 적용이 되는 거예요.
안 되는 거예요. 되는 거예요. 무조건 여러분 나중에 우리 자바 배웠죠 하이 클래스의 모든 특성은 하이 클래스가 받아요 안 받아요 갖고 있어요 없어요.
갖고 있어야 돼. 머신러닝이랑 지금 딥러닝이랑 어느 게 상위 플래스예요?
머신러닝이야 그쵸?

참석자 1 43:51
알겠죠? 이 그래프를 이렇게 그리는 거에서 밖에 있는 게 또 상이 클래스예요.
알겠죠 머신러닝에서 나오는 거 하나하나 다 중요하다 안 중요하다.
엄청 중요하지. 딥러닝에도 다 똑같이 적용되는 거라고요.
알겠죠? 여러분 슈퍼 바이즈 러닝 어슈퍼 바이즈 러닝 이런 거 있잖아요.
딥러닝도 똑같아요. 그냥 머신러닝 딥 뉴럴 네트워크 안 쓰고 그냥 머신러닝으로 할 수도 있고 이렇게 쓸 수도 있고 이해되죠 여러분 그런 식이에요.
그러니까 되게 중요하다고 알겠죠. 그래서 딥러닝 리얼 네트워크 하는데 이게 뭔지 모르면은 이제 또 하나도 모르니까 제가 이 복습해 주는 거야.
알겠죠? 그래서 여기 지금 세 가지 이거 나오는 거에 제가 예를 들어 놓은 거예요.
이것도 여러 가지가 있는 방법이 있는 건데 근데 왜 나눠져 있냐면 기본적으로 보면은 프라블럼이 자체가 달라요.
보면은 여기 제가 영어로 내가 귀찮아서 영어로 적어놨어요.

참석자 1 44:43
너무 우리나라 말로 너무 애매해서 컨티뉴어스 밸리 프리딕션 디스크립 마이더리 프레시피케이션 이런 거 적어놨죠.
여러분 그다음에 디스크릿 멀티 프레스 프레시피케이션 적어놨죠.
이게 이게 뭐냐면 하는 일이 다른 거지 이해돼요. 여러분 와닿아야 돼.
이거 모르겠으면 질문하셔야 돼요. 여러분 창피할 거 없어요.
여기서 창피하는 게 낫지 나중에 들어서 듣고 나서 모르는 게 낫지 시험 망치는 게 더 창피한 거야.
알겠죠? 여기 커팅스 밸리 플리스는 연속적인 값을 예측한다는 거예요.
그쵸? 연속적인 값이라는 게 뭐예요? 여러분 예를 들어서 키 있으면 몸무게 예측하고 이러는 거 그쵸 사실 정확히 맞지는 않지만 키랑 그럼 체지방률 한번 보물 예측 가능하잖아요.
그렇죠 이런 거 그렇죠 그러면 이게 몸무게 같은 거는 굉장히 퍼티어스 값이잖아요.
몸무게 48kg 49kg 48.2kg 이런 식으로 그렇죠 여러 가지 있잖아요.

참석자 1 45:35
그쵸 이해되죠 여러분 무슨 말인지 100kg 이런 거 그렇죠 100.1kg 다 있잖아.
그게 커트러스 리지 그래요. 그다음에 그런 문제에 대해서는 이런 이런 방법을 쓰고 그쵸.
그다음에 디스크립 바이너리 클리시피케이션 요거는 무슨 뜻이냐면은 여기 일단은 클래시피케이션 클래스피케이션 적혀 있죠 그쵸 분류 우리나라 말로 분류 우리나라 말로 다 알아야 돼요.
여러분 그쵸 분류 분류 분류를 하는데 바이너리 분류 멀티플레스 분류 돼 있죠 그쵸 바이너리 분류는 뭐예요?
여러분 예스 노 분류하는 거 또는 영일 분류하는 거 이해되죠 여러분 멀티클래스는 종류가 많은 거 그쵸 저 첫 번째 문제는 이제 개냐 고양이냐 개냐 개가 아니냐 이런 거 구분하는 거고 두 번째는 개냐 고양이냐 사람이나 이런 게 구분하는 거 이해되죠 여러분 그런 문제들 그다음에 디스크릿은 뜻이 뭐냐 클래스피케이션 자체는 다 디스크릿 하지 왜냐하면은 이 중에서 뭐냐 이런 거니까 다 디스크 타잖아요.
떨어져 있는 것들이잖아요.

참석자 1 46:34
이상 그쵸 커티니스 하지 않지 아까 몸무게 같은 것들은 가격 값이 예측하는 값이 굉장히 연속적인 값인데 얘는 연속적인 게 아니라 0 아니면 1이다 아니면 0 1 2 3 4 5 6 중에 하나다 이런 식의 디스크릿이죠.
그쵸 그런 거에 따라서 기법이 달라지는 거예요. 그렇죠 그래요.
그리고 보면은 여기 지금 이 용어들이 다 중요한 용어인데 이거는 제가 수업에서 아니 이거 알고 있어야 돼요.
여러분이 이게 진짜 이거는 지금 여기 적어놓은 것들을 제가 딥러닝 아닌 것만 다 적어놨어요.
여기서 여기 적어놓은 건 지금 기본적으로 리뉴얼 리그레션, 라지스트 리그렉션, 소프트리스 리그레션 다 채운 거 있죠.
그리고 서포트 벡트 머신 디시전 트리 랜덤 포리스트 있죠 이런 거 다 뉴럴 네트워크를 안 쓰고 하는 방법들이에요.
알겠죠 기본적으로 그리고 근데 문제는 뉴럴 네트워크에서는 이거를 사라지는 게 아니라 이거를 기반으로 해서 뭐 더 하는 거예요.

참석자 1 47:26
그러니까 이거를 알아야지 제대로 이해하지 그쵸 그래요.
그리고 제 수업이 아니라 이제 3학년 1학기 수업 한진희 교수님 수업에서 열심히 했었겠지 아니면 지금 동시에 듣고 있는 친구도 있을 거고 동시에 들더라도 동시에 두들어도 괜찮아.
어쨌든 열심히 좀 하세요. 여러분 알겠죠 그래서 이거 어 용어 자체가 뭔지 알아야 되는데 이게 그래서 이 문제 자체가 리뉴얼 리그레션 라지스트 리그레션 소프트웨어스 리그레션 이렇게 돼 있잖아요.
그쵸 리그레션이라는 말 자체가 따라가기 헬기 하기 뭐 이런 뜻이거든요.
우리나라 말로 그래서 리뉴얼을 리그레션 하겠다는 거는 내가 뭔가 아까 기본적으로 이제 뭔가 정답 값이 나오게 하기 위해서 역시 슈퍼바이즈 러닝이니까 내가 뭔가 함수를 매핑 함수를 만들어야 되는데 함수라는 거 항상 그런 거는 뭔가 입력값을 수록 특별 값 내놓는 건데 그게 리니어 선형 함수가 나온다는 거야.
선형 함수 선형 함수 별거 아니고요.

참석자 1 48:17
그냥 더 x 원래 입력 값에다가 뭘 곱해 그다음 바이러스 값 주고 이 정도예요.
그쵸 그렇죠 여러분 입력 값에다가 뭘 곱해? 입력 특성 값에 데이터에다가 뭘 곱해가지고 그리고 거기다가 뭔가 선이 여러분 1차 함수가 이렇게 생겼잖아요 그쵸 선이 그렇죠 아까 봤던 거 그런 거 그쵸 그게 리니어 함수예요.
그쵸 별거 아니고 리니 함수가 뭔지 정확히 알아야 돼요.
여러분 이거는 어디서 배웠어? 초등학교 때 배웠지 리니어 함수 아니에요 미니어 펑션이 뭔지 알겠죠 여러분 비선형은 뭐냐 그거 아닌 거 다 알겠어요 여러분 이 선이 아닌 건 다 비선형이에요.
알겠어요 선형 비선형 정확히 이해하죠 일단 대충 선형은 선 비선형은 선이 아닌 거 약간 좀 뭔가 다 변환이 되는 거 그렇죠 230도는 선형이 아니야 그쵸 이해됐어요.
다른 거 다 그래요. 그래서 여기 리뉴 리릭션을 그냥 원래 특성 값에다 곱하기만 해가지고 모든 해결하겠다는 거야.
알겠죠? 이게 바이어스를 더하잖아요. 보통 몰랐으면 지금 알았어.

참석자 1 49:18
바이어스를 더하고 원래 여러분 as 피처가 하나면은 특성 값이 하나면은 y는 AX 더하기 b잖아.
a가 곱하는 값이고 b가 뭐예요? 바이어스지 우연히도 a하고 b 했는데 b가 바이어스가 좋아요.
그렇죠 바이러스를 약간 더 올릴 수도 있는 거죠. 선이 항상 항상 원점 지나는 게 아니잖아요.
그쵸 그렇게 하는 거지 그쵸 지금 제가 하는 거라 못 알아들었다 질문해도 좋아요.
여러분 나 창피할 거하나도 없어. 지금 시점에서는 그렇죠 나중에도 분화 지난 다음에도 이거 물어보는 거 창피할 거 없어요.
여러분 학생이니까 다 못해 알겠죠? 막 물어봐요.
알겠죠? 나이프로 잘하면 되지 그쵸 그쵸 그래서 어쨌든 리니어 함수로 하는 거고 그다음에 라지스틱 그립션은 라지스틱 함수라는 게 있어요.
여러분 라지스틱 펑션이라는 게 라지스틱 펑션은 모든 세상의 모든 자연수 값을 0하고 1 사이로 매핑하는 놈이에요.
0하고 1 사이로 그런 함수가 있어요. 여러분 아직 우리나라 다른 말로 시그모이드라고 불러요.

참석자 1 50:21
시그모이드 시구 모이드 라지스틱 같은 말이에요.
그러니까 시구 모이드 리그이랑 똑같은 말인데 미리 들어놨다가 넣으면 나중에 또 모르겠으면 질문하세요.
여러분 라지스틱이 리글리 시노비도 같은 말이고 라지스틱 뜻이 모든 세상의 모든 값을 실수 값을 영하 14일 매핑하는 거 영하 11이 뭔데요?
영어 1 사이의 값이 뭔데요? 여러분 커플이잖아 확률을 매핑하면 데이터 하나도 아 그렇죠 확률로 그러니까 모든 세상이 모든 누가 뭔가 훈련을 시켰는데 뭔가 더 이상한 값이 나왔는데 무조건 확률로 바꿔버리는 거예요.
그러면 1에 가까우면은 그냥 이거는 예스다 여유 합법은 노다 이렇게 하면 편하잖아요.
그쵸 그래서 우리가 뭔가 원래 값에서 원래 나온 값에다가 뭘 곱해가지고 곱하고 더해서 어쨌든 무조건 0하고 의사를 시키겠다는 거지 그래서 구분하겠다는 거지 왜냐하면 이익증 분류니까 이해되잖아요.

참석자 1 51:13
여러분 당연히 여러분이 그냥 원시시대로 돌아가서도 이제 또 살다 보면 이렇게 이게 나올 수밖에 없어요.
그렇죠 여러분 그러니까 은근히 세상에 있는 많은 것들이 당연해 그렇죠 그렇죠 그래요.
그다음에 소프트 넥스는 소프트맥스라는 것들은 여러 개의 출력 값이 여러 개의 값들이 나오는데 하나가 아니라 출력값이 걔네들이 전부 다 더해가지고 1이 되게 만드는 놈이에요.
원래 이제 아무리 여러 가지 이제 출력 값들이 나와서 전부 다 확률로 만들고 싶은 거지.
그러니까 예를 들어서 소프트맥스 함수라는 거는 그렇게 나중에 보는 게 더 빠를 것 같아요.
어쨌든 소프트맥스는 멀티플렉스 쪽에 쓰는 거고 어쨌든 뭔가 결과 출력 값이 나온 것들이 전부 저희가 일로 만드는 놈이에요.
알겠죠 별 거 아니고 그래요. 그래서 이 정도만 알고 있고 그리고 저거는 자세한 거는 제가 교과서에서도 나올 거 나중에 필요하면 보충해 줄게요.

참석자 1 52:10
그리고 지금 슈퍼바이저 러닝에서 되게 열심해지겠는데 무슨 육군이 지금 막 하고 있으면 미치다 그렇죠 돼가지고 선출했는데 여러분 이렇게 하면 안 되고 쉬는 시간을 보장해 주세요.
3분밖에 안 남았지만 여러분 11시 5분에 오세요.
11시 5분에 내가 이제 알았죠 11시 5분에 쉬는 시간 가졌다가 왜냐하면 쉬는 시간 맞춰져야 되는 시간 다른 수업이라서 미안해요.
여러분 미안해요. 11시 5분에 와요. 11시 5분.


clovanote.naver.com