- GPT(Generative pre-trained transformer)
- **Transfer learning**(전이 학습)
- Pre-training (사전 학습)
- Fine-tuning (파인 튜닝)
[[Pre-training & Fine-tuning의 차이점]]
- VAE(Variational Auto Encoder)

- convolutional neural network(합성곱 신경망)
* __Loss == Error == Cost
* Derivative (function)  
  == 도함수
  == Gradient
  == **변화율**
  == 기울기
  == 경사

* Stochastic == Random
* Learning rate (학습률)
    == Step == Step size == 보폭

 * Data == Train data + Test data   (훈련, 시험)
    Training data == True training data + Validation data (검증)
 * DNN parameters: weights and bias of neurons  (targets for training)
 * DNN hyper parameters: learning rate, # of neurons, # of layers, ratio of validation/test data

__DFS(Depth-First Search)(깊이 우선 탐색)(큰 그림: 숲)__ : 루트 노드(혹은 다른 임의의 노드)에서 시작해서 다음 분기(branch)로 넘어가기 전에 해당 분기를 완벽하게 탐색하는 방법
__BFS(Bread-First Search)(너비 우선 탐색)(작은 그림: 나무)__ : 인접한 노드를 먼저 탐색

- 강의자료
Testing(시험) == Inference(추론) == prediction(예측)
앙상블 == 집단지성 == 여러개가 모여있는 것
transfer function == activation 함수 == 활성 함수

- 1장
역전파(backpropagation)
옵티마이저(optimizer)
앙상블
특성 공학(feature engineering)
활성 함수(activation function)
가중치 초기화(weight initalization)
배치 정규화(batch normalization)
residual connection(잔차 연결)
depthwise separable convolution(깊이별 분리 합성곱)

- 2장
훈련 세트(training set)
테스트 세트(test set)
소프트맥스(softmax)
옵티마이저(optimizer): 성능 향상시키기 위해 입력된 데이터를 기반으로 모델을 업데이트 하는 메커니즘
손실 함수(loss function): 훈련 데이터에서 모델의 성능을 측정하는 방법으로 모델이 옳은 방향으로 학습 될 수 있도록 도와준다.
성능지표(accuracy): 정확도를 고려해준다.
*텐서 == 데이터를 위한 컨테이너
텐서에서 차원(dimension) == 축(axis)
-> [ ]의 갯수가 차원의 수*

샘플축(sample axis) 
	== 샘플 차원(sample dimension)
	== 배치 축
	== 배치 차원
	== 데이터 갯수
	== 첫번째 축(0번 축)

BLAS(Basic Linear Algebra Subprogram)
	-> 고도로 병렬화된 효율적인 저수준의 텐서 조작 루틴이다

- 4장
oov (out of vocabulary) : 사전에 없는 단어는 뺌
mse(mean squared error) : 평균 제곱 오차
mae(mean absolute error) : 평균 절대 오차
K-겹 교차 검증(K-fold cross-validation)

0 : padding
1 : start of the sentence
2 : oov(out of vocabulary)

5장
- 일반화(generalization) == preventing overfitting
- 최적화(optimization)
- 보간 (interpolation)
- 특성공학(feature enginering)
- 규제(regularization)

6장
- 개념 이동(concept draft)
- oov (out of vocabulary) : 어려운 단어는 뺌
- 가중치 가지치기 (weight puning)
- 가중치 양자화 (weight quantization)