
- 13.2.1 혼합 정밀도로 GPU에서 훈련 속도 높이기

훈련속도를 3배 늘리는 방법?? -> 혼합 정밀도 훈련(mixed-precision training)

__정밀도는 숫자의 해상도에 해당__

00000000 : 0
11111111      : 255

숫자를 16비트에 저장하는 __반정밀도(half precision),        float16, 1e - 3__
숫자를 32비트에 저장하는 __단정밀도(single precision),   float32, 1e - 7__
숫자를 64비트에 저장하는 __배정밀도(double precision), float64, 1e - 16__

단정밀도에서, 일반적인 learning rate는 1e-3, weight update는 1e-6(즉 learning rate가 1e-3이니

gradient가 1e-3이란 얘기) 크기가 일반적

1e-5나 1e-6 정도의 작은 gradient로 weight update하려면, 단정밀도로는 불가능하고 float64를 써야 함

