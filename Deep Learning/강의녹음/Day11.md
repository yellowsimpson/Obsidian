딥러닝 day11
2025.04.14 월 오전 10:02 ・ 48분 24초
심승환


참석자 1 00:00
이거를 그래서 교과서에 170쪽이지 170쪽

참석자 1 00:10
그래요. 그래서 어쨌든 교과서에 그래서 지금 이 예로 여기 회기가 이제 리그레션이라고 돼 있는데 사실은 원래 리그렉션 리뉴얼 리그렉션도 있고 라이트 스트리그렉션도 있고 두 가지 있잖아요.
그쵸 여기는 당연히 근데 보통 회기라 그러면 그냥 리뉴얼 리액션 얘기하는 거죠.
그쵸 근데 여기도 리뉴얼 하는 건 아니야 그쵸 커티스 밸리플레이션 하는 거지 그쵸 그래서 오해의 여지가 있어요.
여러분 그렇죠 용어가 좀 그래 그렇죠 알아먹어야 돼.
근데 이해해요. 여러분 들거수 치료 시작한다는 말이 나와요.
그냥 획이라고 그러면 사실은 라지 스티그레이션 리뉴얼 리그레션 여러 가지 있잖아요.
그쵸 그리고 라디스틱 액션은 분명히 확률 바이리플레시케이션 하는 문제예요.
그쵸 여기서 지금 바이어리플레시케 하는 건 아니에요.
그쵸 그래서 여기서 회계라고 쓰는 거는 여기 영어로 다 직격했는데 사실은 컨트스 메뉴를 프리딕션 하는 문제를 회계라고 그랬어요.
디렉션이라고.

참석자 1 01:14
근데 되게 이상하잖아. 이상해도 알아먹어야 된다는 거야.
알겠죠 근데 분명히 명확하게 리그렉션이라고 그러면 보통 컨트롤 리그레션을 의미해요.
알겠어요. 그러면서 됐어요. 리뉴얼 리그레션은 아니야.
근데 그쵸 리뉴얼 아니잖아. 이게 선형으로 만들지는 않잖아요.
이게 우리 그 신경만 쓰는데 무슨 선형이에요? 그렇죠 됐어요.
헷갈릴 수 있는데 여러분 문제는 이제 알아먹어야 되니까 시험에 나와요.
이런 것 있어요. 나올 수 있어요. 아직 안 했죠 알겠어요 여러분 알아보고 이 디그 시라 그러면 여러분 뭐냐 값을 코트에서 값을 코트에서 밸리로 표시하는 문제를 말해요.
알겠죠 그래서 지금 여기 교과서에 나오는 예제들을 약간 좀 기억할 필요가 있는데 문제가 어떤 문제였냐 그쵸 되게 대표적인 예가 있었죠.
바이리플리시케이션에서 세트 마트 엘리시스로 감정이 커지티브냐 negative냐 딱 그렇죠 그렇죠 그렇죠 여러분 시드모이드로 나왔죠 거기가 라이스트 리게이션이죠.

참석자 1 02:11
오히려 그쵸 마지막 라디스 티그레이션 하지 그쵸 사실 여기도 주택 가격 예측 문제도 신경 쓰잖아요.
중간에 라 리니어 측을 막 넣는데 막판에는 항상 리니어지 막판에 리니어예요.
저번에 시간에 제가 보여줬으니까 신경과 생긴 거 여러분 172쪽에 있잖아요.
172쪽 미리 미리 그냥 하셔야지 처음 들어가는 것도 아니고 72쪽에 마지막에 요거 빌드 모델에서 모델 만들어 놓은 거 보면 레이스 s하고 일 드 있죠 여러분 일 그쵸 액티베이션 펑션이 없어요.
그쵸 액티베이션 펑션이 없는 게 리뉴얼 리베이션이에요.
그쵸 알겠어요 여러분 액티지 펑션이 시그 모이드는 라지스틱 리액션이고 그렇죠 시그모이드 라지스틱 같은 말인 거 알아야 돼요.
그렇죠 여러분 외워야 돼 이런 거 이제 외워야 돼요.
용어를 모르면 그거 모르는 거야 알겠죠? 됐죠 그래요.

참석자 1 03:11
그래서 이 문제는 지금 다시 170쪽에 보면은 문제가 고스트 주택 가격 예측하는 거고 예측하는 거는 주택 가격인데 어쨌든 여기 보면 리포트 보스팅 하우징 이렇게 해서 하는 거고 보면은 데이터가 트레인 데이터가 404개, 테스트 데이터가 1002개 이렇게 있어요.
그쵸 그리고 쉐입이 이제 13개씩 있죠 그쵸 필처가 13개라는 얘기지 그쵸 필처가 13개 있다는 뜻이에요.
그쵸 여러분 여러분 세프티모터리스는 여기 되게 여기 데이터가 안 나왔던 게 이제 어레이가 이 크기가 달라가지고 그쵸 안 나왔고 그쵸 패티 레이어가 달랐잖아요 그렇죠 여기 숫자가 보통 여러분 리스트 앱 리스트는 7만 개 이랬잖아요.
그쵸 7만 개에서 6만 개 6만 개 만 개 이렇게 했나 보통 그렇게 했는데 이건 되게 지금 되게 작죠.

참석자 1 04:10
이것도 이제 대표적으로 데이터가 되게 작은 빅데이터가 아닌 대표적인 예예요.
보스턴은 주택 가격이 별로 많이 못 모았어. 근데 여러분이 실제로 실제로 여러분이 데이터 모아서 할 때 이런 경우가 굉장히 많아요.
그러니까 보통 1만 개 안 되면은 데이터가 크다고 안 해요.
1만 개가 넘어가야 데이터가 크다. 그래요. 보통 뒤에 나와 있던 어쨌든 얘는 지금 굉장히 데이터가 작고 그쵸 그래도 딥러닝 못하냐 하지 하긴 하는데 작기 때문에 이제 뭔가 이걸 이걸 통해서 뒤에 보면은 173쪽에 미리 보면은 케기 검증이라는 것도 나오잖아요.
그쵸 이게 k기업 검증이 너무 데이터가 작으면 이 짓을 많이 해요.
미리 데이터가 작다는 것도 미리 보여주면서 얘기하는 거야.
알겠죠 데이터가 무지 작다. 그쵸 그렇지 그쵸 그다음에 13개의 피처가 있는 거 피처가 13개면 아까 전에 NDC 같은 경우에는 28 28 이렇게 있었죠 그렇죠 되게 작아요.

참석자 1 05:07
이것도 그렇죠 이미지는 아림이지만 13개면 피처로서는 많다고 볼 수도 있지만 어쨌든 13개가 있고 여기 보통 여기 특성들이 다 일부러 안 보여주는 게 이제 1인당 범죄율 주택 주택 평균 방 개수 이런 게 있잖아요.
그쵸 숫자들 보면은 이렇게 교과서에 나오듯이 스케일이 막 달라요.
어떤 데 이 15.2 40점 2.3 50 이렇게 있는데 이게 무슨 레인지가 레인지가 다 다르다는 거지 이게 타겟이네 이거 미안해요.
여기 실제 숫자는 안 보여주네. 숫자 찍는 거는 어쨌든 어떤 건 0점 얼마로 나오고 어떤 거는 막 30 얼마로 나오고 막 되게 엄창이야 스케일이 이 대조업은 그래요.
그게 되게 중요하고 그리고 여기 이제 일부러 안 보여주는 원인 중에 하나는 여기 막 흑인 하는 비율도 있고 막 그래요.
좀 그렇잖아 그러니까 차마 못 보여주는 것도 있고 막 그게 좀 문제가 있어요.
알겠죠 여러분 흑인이 얼마나 많이 사냐 집값이 떨어지는 게 있고 막 그랬어요.

참석자 1 06:08
진짜로 그래요 여러분 지금도 그래 심지어 어쨌든 그래서 그런 것 때문에 교과서에 이 보스팀 채택하기 위해서 맨날 데이터셋을 안 보여주는 경향이 있어요.
그렇지만 또 귀한 자료니까 또 쓰고 있고 그래요. 별로 중요하지 않지 어쨌든 갑시다 여러분 그래서 됐지 가격은 이렇게 나왔고 가격이 이거는 옛날 가격이라서 그렇고 70년대 가격이라서 그다음에 여기 지금 4.3.2절이 또 되게 중요한데 3.3.2절 172쪽 아래에 있는 거 보면은 171쪽 거기 4.13.2절 아래 맨 마지막 문장에 특성별로 세 번째 문장에 특성별로 정규화라는 말 적혀 있죠 그쵸 뭐예요?
여러분 4.3.2 문단의 세 번째 문장에 특성별로 정규화 적혀 있는 거 보여요.
여러분 다 봤어요 요 요거 줄 있죠? 그쵸? 특선별 피처 와이즈 피처 와이즈라고 표현 특선별이 피처 와이즈 그렇죠 우리나라 영어로는 피처 와이즈 정규화라고 이제 교과서에 교과서에 노멀라이제이션이라고 나와 있거든요.

참석자 1 07:21
원래 영어 책에 노멀라이제이션이 근데 이제 노발레이제이션 번역을 정규화 해야 되는 게 맞는데 밑에 보면은 주석에 23번 주석 보실래요?
여러분 몇 줄 역주는 정규화는 다른 의미로 사용되기 때문에 오해가 쉽다고 그랬잖아요.
그래서 뭐가 좋다고 돼 있어요 스탠다레이션이라 적혀 있어 표준화 그래서 이거는 또 저 원래 오리지널 저자가 좀 별로 잘못 쓴 거예요.
사실은 노멀라이제이션 하면은 보통 정규화가 진짜 정규화라서 표준 편차를 1로 만들고 평균을 0으로 만드는 걸 의미하거든요.
그걸 이 사람이 좀 이 프랑스가 볼래 이 사람이 수학을 잘 되게 싫어하고 잘 못하는 것 같아 진짜로 그래서 이런 용어를 막 썼어요.
근데 사실 번역을 했는데 지역을 사실은 안 맞다는 거지 너무 오해의 여지가 크잖아요.
로바메션하면 다 정규화 의미하잖아. 정교화 근데 아니거든 표준 편차 1로 만들어진 게 정교화지 그게 너무 유명하잖아요.

참석자 1 08:17
이 사람이 수학을 잘 못해 그 수학 수식이 거의 안 나와 이 책이 그래서 잘 팔리죠.
우리가 또 이해하기 쉬워서 그런 면이 있어요. 다른 사람들은 수식이 너무 쉬워서 수식 투적이거든요.
정말 딴 책이 이에 수식이 거의 없잖아요. 그래서 이해하기 쉽지 그래서 이 사람 성공했지 어쨌든 참 전화 유혹이야.
그렇죠 어쨌든 이해 정규야 이거 아니야 그쵸? 격주가 맞아야 돼.
표준화라 그래야 돼. 이거는 표준화 알겠어요? 여러분 제가 이렇게 가르쳤으면 시험에서는 어떻게 어떻게 해야 되는 거냐 표준화가 맞다고 제가 교과서 틀렸다고 했으면 교과서가 아니에요.
알겠어요 여러분 표준화가 맞아요. 교과서가 틀리기도 하고 옆으로 틀리기도 하고 막 어쩔 수 없어요.
그렇죠 나한테 이상한 거 있으면 미리미리 물어놔요.
시험에서 교과서에서 이랬어요 하고 얘기해도 소용없어요.
알겠죠 인터넷에서 이랬어요.

참석자 1 09:04
진짜 말도 안 되지 그쵸 알겠죠? 여러분 미리미리 나한테 물어봐요.
이상한 거 있으면 어쨌든 정규화 아니고 이거 표준화예요.
표준화는 뭐냐? 표준화에 이제 정규화도 있고 리맥스 노 리맥스 표준화도 있고 그런 거예요.
여러분 지금 여기 코드 4.4 24 맨 밑에 있는 거 보면은 이거는 지금 이거는 정말 정교했네.
이 사람도 정교했구먼 맞네. 미안해요. 여기 정규화를 했네.
리미스 표준화 안 하고 정교화해버렸어요. 진짜로 미안해요.
여러분 내가 또 착각해서 정규화했네. 이 사람은 진짜 정교화인 거 맞아요.
맞는 거 보여요. 여러분 여기는 표준편차 1로 만들고 미안해요.
여러분 내가 또 한참 더 해봐가지고 여기 표준 정교화했네.
진짜 꼭 정교화해야 되는 건 아니고 원래 미니스트 팀이라 해도 되는데 정교화했어요.
아니 예측해라. 알겠죠? 여러분 여기 정교화 핸드 이거 맞아 이 사람이 정교화 맞아요.
원래는 정규화를 했어요. 이게 정규화인지 알겠죠?

참석자 1 10:06
여러분 평균을 빼고 편차를 나누면 정교화하는 거 맞잖아 평균 0 빼고 자 1 됐어요.
맞네 진짜 그래서 여기 이렇게 이런 식으로 해요. 여러분 이제 이거는 따라 할 수 있어야 돼요.
여러분 그거 코드 보고 따라 오픈북으로 할 수 있어야 돼요.
여러분 알겠죠? 액시스를 0으로 하면 여러분 뭐예요?
이거 배치별로 하는 거죠 그쵸 배치별로 평균 내고 그러는 거예요.
액시스를 0으로 하면 됐어요. 그리고 근데 테스트 데이터도 정교화할 때 트레인 데이터에서 사용된 그래 그게 되게 중요해요.
이 교과서에 뒤에 나와 있는데 뒤 페이지에 172쪽 볼래요?
172쪽 설명이 172쪽이 되게 중요해요. 이 내용이 이거 시험에 나와요.
여러분 내 거예요. 까먹지 않고 제가 뭐냐면은 정규화할 때 훈련 데이터에서 계산한 값을 무조건 해요.
그래가지고 봐봐요. 다시 코드 볼까요?

참석자 1 11:05
코드 코드 보면은 여기 평균이랑 표준 편차를 트렌드 데하고 했죠 그쵸 그쵸 여러분 그런데 트렌드 데이터를 이렇게 많이 하는 건 당연히 이해가 되는데 이렇게 하는 것도 테스트 데이터도 지금 미니랑 스탠다드네이션을 여기 트렌드 데이터 한번 한 걸 했죠.
그쵸 왜냐면은 테스트 데이터는 우리가 앞으로 영원히 볼 수 원래 절대로 훈련할 때 훈련할 때 볼 수 없는 거여야 되잖아요.
결국은 훌륭한 거 갖고만 나중에 다 평가를 할 거 아니에요 그러니까 실제로 이 우리가 이제 데이터를 나중에 뽑아 테스트 데이터 주입할 때도 이제 정규화시켜서 정규화나 표준화시켜서 구입해야 되는데 트레 데이터의 것만 갖고 해야지 진짜 나중에 모든 새로운 데이터를 봐도 항상 그럴 거 아니에요 새로운 데이터의 평균 표준 패턴을 우리가 어떻게 알아 모르잖아요.
항상 우리 트랜 데이터 갖고만 할 수 있는 거잖아. 그래서 트렌 데이터 갖고만 해야 되는 거예요.

참석자 1 12:01
이해되죠 이거를 아니 실제 세상이 앞으로 어떻게 될지 모르지 사실은 평균하고 표준화가 계속 이동해요.
실제 데이터에 대해서는 그렇지만 우리 학습하는 거 우리는 철저하게 트레인 데이터 갖고만 할 수 있잖아.
트랜 데이터의 정보만 사용해야 되는 게 중요한 거예요.
이해됐어요. 여러분 그게 핵심이에요. 테스트 데이터는 우리가 아무것도 몰라야 되는 거야.
그래서 지금 이 테스트 데이터를 정규화하는 이유는 왜 하느냐 나중에 우리가 이밸류에션 하려고 하는 거잖아요.
이밸류에이션 검증하려고 성능 평가하려고 우리 예측기가 얼마나 수련이 잘 됐나.
근데 그거를 트레인 데이터 갖고만 해야 트레인 데이터 정보만 갖고 해야 된다고 이해 안 되면 질문하세요.
말이 안 돼. 테스트 이트가서 한다는 건 모르는 건데 문에 몰라야 되는 건데 그렇죠 그래요.
알겠죠? 그래요. 그다음에 그게 중요한 거예요.
중요한 거 이거 시험에 나면 이거를 제가 여기다가 일부러 코드 막 냈대.

참석자 1 13:01
테스트 데이터가 민도 비슷한 자료 다 구해놓고 뭘 해야 되느냐고 그러면 여러분 대부분의 학생들이 테스트 데이터 파워 낸다고 그럼 틀린 거지 알겠어 그래요.
테스트 데이터 거 가지고 여기 하면 안 되는 인터넷 트인 데이터 거 해야지.
나중에 이제 새로운 데이터가 나타났어. 그럼 걔를 정교화해야 될 거 아니야 근데 새로운 데이터 앞으로 이제 앞으로 나타난 데이터에 표준 편차 계산을 어떻게 알아요?
우리가 표준 편차 평균이나 이런 거를 모른다고요.
그래요. 그다음에 모델 만드는 건 이렇게 간단하게 했었고 그래도 나름 딥러닝이죠.
그쵸 헤드 레이어가 두 개니까 그쵸? 그래요. 그럼 64개로 꽤 많이 만들었죠 꽤 많이 했어요.
64개 정도를 그쵸 2개로 했고 그리고 여기에 이제 RMS 프라토 코 노스를 MSA 쓰는데 매트릭을 MA로 보여달라고 그랬어요.

참석자 1 14:08
배에 값으로 보는 게 기가 좋으니까 가격 이게 이제 예를 들어서 전에도 얘기했지만 이제 이런 식으로 나올 텐데 29.1 15.2 이 가격 이렇게 나오는데 만약에 민 에트로트 에러가 한 5다 그러면은 여기서 한 5달러 정도는 다 예측한 값에서 왔다 갔다 할 수 있다는 걸 보여주는 거니까 그쵸 그런 거죠.
그다음에 이거 하자 4.5절에서 나오는 게 k기업 검증이라고 적혀 있는데 이거 영어로 알아야 될 필요가 있어요.
케이 폴즈 크로스 밸리데이션이라고 이게 진하게 k기업 부채 연금 옆에 적혀 있죠.
케격 교차 검증이라고 케이 폴드 크로스 밸리데이션이라는 말이 나오죠.
그래요. 이게 어쨌든 지금 이제 4.요 4장 들어오면서 우리가 밸리데이션 데이터를 따로 쓰고 있잖아요.
홀드 밸리데이션 그쵸 그러니까 트렌 데이터를 또 그대로 쓰는 게 아니라 거기서 또 떼가지고 검증할 때 쓰려고 하잖아요.
그래서 얼리 스타킹도 좀 해보려고 그러고 이런 거 있잖아요.
그런데 너무 데이터가 작잖아요.

참석자 1 15:15
이거 데이터가 너무 작아요. 너무 작으니까 거기서 혼자 써버리면은 이게 우리가 또 받은 데이터가 걔가 거기에 너무 좌우되잖아요.
사실 검증 자체가 그래서 믿을 수가 없는 거예요. 그쵸.
너무 데이터가 작으니까 검증 데이터 자체도 이제 그것만 잘한다고 잘할 수 있다고 믿을 수가 없으니까 이게 보면은 지금 그림 보실래요?
여러분 이 그림 이 그림처럼 아예 여러 검증 데이터 이 부분 데이터 3개를 분사해가지고 여기를 써보고 여기를 써보고 여기를 써보고 해보고 다 이걸 뭔가 평면적으로 봐야지 뭔가 믿을 만하다는 느낌이 드는 거죠.
훈련 훈련한 결과가 그러니까 이게 원래 훈련을 어디까지 할지가 검색 데이터를 쓰는 이유가 우리가 훈련을 어디까지 할까의 문제잖아요.
너무 바로 적합 안 되게 멈추려고 그러는 거잖아요.
그쵸 오버 피팅 안 되게 멈추기 위해서 우리 검정 기사 쓰는 거잖아요.

참석자 1 16:09
트린데이 타임이 너무 막 치우치지 않게 근데 보통 이제 우리가 이렇게 하고 끝내잖아요.
이렇게 한 것만 하고 우리 데이터 빼가지고 앞에 거 하나 이렇게 하거나 아니면 이렇게 해서 끝내잖아요.
이러면 얘 너무 얘만 얘 잘라 얘 최적화 해서 끝내버릴 거 아니에요 훈련이 그래서 겁나니까 이렇게도 해보고 이렇게도 해보고 이렇게도 해봐서 어느 정도에서 우리가 점수 여기 검증 점수를 3개를 평균 내가지고 적당하기 좋은 점수에서 끝내려고 하는 거야.
훈련을 또 훈련을 우리가 이렇게도 하고 이렇게도 하고 이렇게도 해야 되잖아요.
여러분 모델이 3개나 필요해요. 그쵸? 그러니까 이거 훈련한 거를 또 또 데리고도 훈련하고 훈련하고 그럴 수는 없어요.
여러분 왜냐하면 검색 데이터를 다 버렸잖아. 후련 데이터 뭐냐면 무슨 얘기냐면은 다시 거꾸로 얘기했어.

참석자 1 16:54
어 다시 여러분 조심할 게 데이터가 아깝다고 해서 이걸 훈련한 다음에 이렇게 훈련한 다음에 이걸 데리고 그대로 다시 이렇게 또 이걸 방도 데이터를 써서 훈련하잖아요.
그럼 무슨 일이 생기겠어요? 여러분 훈련에 사용한 데이터로 검증을 쓰는 거잖아요.
그러면 이거는 답을 알려주고 하는 거잖아요. 이거 절대로 안 되는 거 알아요.
여러분 여러분 근데 여러분 선배들이 맨날 학원 공부가 막 이렇게 하는 경우도 있고 막 그래 좀 잘 된 줄 알아 내가 훈련에 사용한 데이터로 검증을 한다고 그럼 여러분 같이 놀면 안 되는 거예요.
그쵸? 큰일 나 그쵸? 이해돼요. 여러분 훈련에 사용된 데이터를 검증해 사용하면 안 돼 알겠죠 한 번 높은 문제를 풀어야 돼.
절대적으로 풀 때는 알겠어요. 그래서 이거는 이게 모델을 3개 만들어가지고 그래서 여기 보면 앞에 172쪽에 굳이 이렇게 여기를 함수로 만들었잖아요.
빌드 모델 이거 옛날에 그냥 했는데 여기 빌드 모델이라는 거 만들었죠.

참석자 1 17:54
왜 이러냐면 모델 여러 번 만들어 쓰느라고 그랬어요.
PF 여러 번 만들어 쓰려고 함수 리드로 만들었어요.
아직 또 리턴 모델 해놨잖아요. 그쵸 함수도 만들고 또 만들고 만들고 해야 되고 여러분 조심할 게 와델 피하잖아요.
그리고 와자 점 피트 또 불러 그러면 옛날에 학습했던 거 웨이트에다가 다시 또 그냥 더 추가로 학습하는 거지 이해돼요.
여러분 저렇게 마델을 컴파일하고 이렇게 새로 정의해야지만 웨이트가 초기화가 돼요.
알겠어요 여러분 그래서 k 코드 밸리데이션 하는 거 코드가 여기 있나 있지 코드를 보면은 지금 일단 케이프 홀드니까 k를 여기서는 지금 그림에서는 아까 3이었는데 3개로 나눴는데 여기서는 4개로 나누기로 했어요.
검증 데이터를 네번 쓰는 거지 이해되죠? 여러분 네 군데 쪼개내서 3개로 쪼개기에는 너무 트인 데이터 작은 거야.
그래서 4개로 해야지 4분의 3을 쓸 수 있으니까 데이터를 트인 데이터를 이해되시죠?

참석자 1 18:49
여러분 그래가지고 이제 해본 건데 그래서 홀드 k 번 도는 거죠.
케번 돌아서 아까 틀린 데이터를 아까처럼 뽑아내고 밸리데이션 데이터 밸리데이션 데이터를 트레 데이터 일부를 뽑아내고 그다음에 트레인 데이터 트레인 데이터 나머지를 이렇게 뽑아내고 그쵸 여러분 파이썬이에요.
그냥 지금 여기 어디 하고 있는지 알겠죠? 여러분 173쪽 하고 있어요.
됐어요 하고 있어요. 괜찮아요. 그리고 모델은 빌드 모델 해가지고 노네스 피하고 그다음에 이밸류에이트 해서 이밸류에이트는 밸류에이션 데이터 갖고 했어요.
그냥 해가지고 업에 그냥 마지막에 한번 여기서 피 탈 때 굳이 밸리데이션 매번 하지 말고 다 훈련시킨 다음에 마지막에 밸리데이션 시키고 디벨리웨이트로 그 점수를 어펜드시켜서 그래요.
어패드 시켜서 여기 여러분 이밸류에이트 하면 이렇게 이렇게 이거 받을 수 있다는 거 보이죠 여러분 이게 뭘 리턴하냐면은 여기는 로스 값 여기는 매트릭 값을 리턴해 줘야겠죠.

참석자 1 20:02
받아가지고 걔네들 여기서 지금 MA 값을 미 애솔루트 에로를 어벤드 시켜가지고 계속 업데이트 받은 다음 이게 지금 받은 다음에 평균을 내는 거를 점수를 봤죠.
점수 점수를 봤어요. 그랬더니 이렇게 이게 엑소 루트에서 이렇게 나왔잖아요.
밸리데이션 이게 지금 몇 쪽에 있는 거냐면은 여기 바로 114쪽에 중간에 있는 거죠.
저거를 액폭을 배분해서 출력을 시켰더니 이렇게 다섯 번의 폴드에 대해서 MA가 이렇게 나왔어요.
그러면 이제 평균적으로 2.56 정도 된다고 이렇게 본다는 거죠.
이렇게 봤어요. 그다음에 그냥 이 정도 된다고 보고 그다음에 또 케이 홀드로 해가지고 이번에는 이제 아까는 100번을 훈련시켰는데 이번에는 얼마나 훈련시켰냐면은 500번 했다 그랬죠 500번 500번 4그룹 그다음 줄에서 여기 넘 4 500 아까는 100으로 했는데 그럼 100으로 했죠.
500으로 해가지고 또 훈련을 시켰어요.

참석자 1 21:11
훈련을 시켜서 이번에는 아까는 바로바로 이밸류에이션 했는데 이제 이밸류에이션 하지 않고 이번에는 또 어떻게 또 어떻게 바꿨냐면은 히스토리 여기 변수에다가 써가지고 히스토리 히스토리에서 요거 뽑아낼 수가 있어요.
이 MA라고 나온 게 이게 이것도 여러분 당 여러분 좀 헷갈릴 수 있는데 이게 정해져 있어요.
이게 이름이 밸리데이션 이름이 내가 줬나 이가 이거네.
소메일 할 때 컴파이러스 컴파일 할 때 우리가 매트릭을 MA라고 줬죠.
그쵸 리리케이션 MA라는 이름이 잠깐만요.

참석자 1 22:10
히스토리에 밸리데이션 MA라는 게 이것도 나온 거는 미안해요.
여러분 아까 갔다 밸리데이션 데이터라고 줬죠. 이번에는 또 그렇죠 여러분 아까는 안 줬는데 아까는 줬는데 안 줬는데 이번에 줬죠.
밸리데이션 데이터를 줬잖아요. 그쵸 줬을 때 매일 매매일 이런 게 생겨요.
여러분 변수가 히스토리에 쌓여요. 내가 뭐 말하는지 여러분 알려나 원래 MA 원래 테스트 데이터에 이제 트레 데이터에 대해서는 mae 이런 게 생길 텐데 이제 요 밸리데이션 데이터를 줘가지고 밸리 벨 언더바 MA라는 이름이 이렇게 테스터 플로우에서 정해 놓은 거예요.
여러분 그래요. 그래서 걔를 여기다 붙여가지고 쌓아서 봤어요.
그리고 여기 별거 아니죠 버버스는 영어로 하면은 이렇게 나오는 그런 거 안 나와요.
여러분 별거 아니고 버버스가 영어로 안 하면 막 나왔잖아.
밑에 원래 업 하고 나오잖아 그런 게 안 나온다는 거예요.
별거 아니고 페이스북으로 안 보여줘도 되겠죠. 뭔 얘기인지 알죠 여러분 그래요.

참석자 1 23:20
이렇게 해서 MA의 평균을 그려봤고 그리고 그래서 지금 이게 이게 사실 우리 그림을 그려보면은 이렇게 보이면은 사실 여러분 500이나 했으니까 이것도 교과서 헷갈리는데 이렇게 하면 여기 잘 안 보이잖아 비슷해 보이죠.
여러분 그쵸 비슷해 보여서 사실 별로 변화가 없어 보이는 100가지만 그려본 게 교과서에 이제 이렇게 또 있어요.
처음에 10개 포인트 이렇게 안 했구나 훌륭하다 이렇게 하는 건데 이 사람 꿈이야 내가 내가 틀렸지 여기 이거 보면 여기 여기 때문에 너무 값이 커 보이니까 여기를 잘라버렸어 뒤에만 그려본 거예요.
뚱뚱하네. 그래 이렇게 해야지 이렇게 그려봤어요.
그랬더니 이게 잘 보이잖아. 앞에를 잘라버리니까 처음에 10개 데이터를 보일 때 제외하니까 잘 보이잖아요.
그쵸 사실은 이거는 나중에 배우겠지만 이제 어쨌든 이게 숫자를 봐서 이제 제일 작은 걸로 하는 건데 이쯤에서 되게 작다는 게 보이잖아요.

참석자 1 24:25
100 전에 그쵸 그래서 결국은 이거를 어디서 아까 검증 데이터 아까 이 검증 MA 자체가 어떻게 나온 거냐면은 평균으로 해서 나온 거예요.
평균에서 맞지 이 MA 히스토리 oma 히스토리 여기 에버리지 MA 히스토리로 아까 평균 낸 거 파이썬으로 몇 페이지에 있는 거냐면 175페이지에 평균 낸 거로 지금 구한 거였거든요.
그래서 이게 이제 평균 점수로 실제 제대로 된 적당한 f을 찾아내서 이거예요.
그거 얼마까지 했냐면 그래서 한 130이라는 걸 알아내서 130을 알아내서 130까지 다시 픽스 시키고 이번에는 트렌 데이터 전부 다 써버렸어요.
그쵸 아깝지 않게 밸리데이션 데이터 다 날려버렸어요.
그쵸 훈련시켜서 했더니 나중에 이벨류에이터가 25 정도 2.4 6 정도로 나왔어요.
그래서 이제 통과된 건가 원래 아까는 2.5가 넘었었거든요.
근데 2.46으로 좀 줄어들었어요. 그래요.

참석자 1 25:43
한 100달러 정도는 향상됐다 이렇게 되고 어쨌든 그렇게 데이터가 작을 때 발악을 하는 약간 그런 내용이에요.
여러분 알겠죠? 그래요. 우리 새로운 데이터에 대해서 테스트 데이터 갖고 한번 해보면 테스트 데이터 갖고 넣어서 하면 프레딕션 하면 이게 여러 개가 여러분 테스트 데이터가 이게 몇 개예요?
여러분 아까 대충 있었지만 여러 개 있었잖아요. 그쵸 그러면 그중에서 이제 한 개 뽑아내려면 이렇게 뽑아내면 되겠죠 그쵸 0번 1번 이런 식으로 그쵸 쳐봤어요.
그래서 1만 달러로 예상되고 실제 값을 또 보려고 그러면 볼 수 있겠지 그렇게 끝난 거고 그래요.

참석자 1 26:23
그래서 어쨌든 여기 4.3절 내용이 여러 가지 담고 있는데 교과서에서 뭔가 좀 요약을 하면 요약을 하면 지금 데이터가 굉장히 작을 때 케이 폴드 크로스 밸리데이션을 써가지고 그냥 검증 데이터를 한 검증 데이터에 쓰는 건 좀 그러니까 평균 내가지고 사용해 보면서 그렇죠 뭔가 우리가 어디까지 오버 어디까지 피팅 훈련해대이 차야 되고 나중에는 그 찾아낸 네트워크 숫자 갖고 전체 데이터 다 훈련해버렸어요.
그쵸 보통 그러면 잘 되더라. 이게 케이폴드 크로스 밸리데이션을 엄청 좋아하세요.
이분이 옛날 1판에서도 거의 앞부분 나오고 그랬었어요.
그랬어요. 여러분 알겠죠? 또 나왔죠 뒤에 가면 너무 안 그래도 책 두꺼운데 또 나와요.
굳이 되게 좋아하셔가지고 그래요. 그다음에 그러면 이제 드디어 5장으로 넘어갑시다.
여러분

참석자 1 27:24
5장은 5장은 제가 5장 6장 금방 할 수 있다고 그랬잖아요.
그쵸 5장이 왜냐하면 제가 많이 했던 거니까 앞에서 교과서의 5장이 5장 제목을 볼까 여기 5장 여기 읽어 보셨죠?
여러분 여기 의미 합시다. 이거 의미미 이거 보세요.
5.21은 일반화라고 했지 일반화 그렇죠 일반화 지금 사실 4장에서도 약간 그런 걸 열심히 한 거예요.
사장에서 계속 밸리데이션 데이터 쓰고 페이 폴드 프로스트 밸리데이션 써가지고 했던 게 이제 어디까지 훈련시켜야 되느냐의 문제잖아요.
그게 이제 일반화라고 적혀 있잖아요. 일반화 머신러닝 목표는 일반화인데 일반화는 뭐냐 훈련한 데이터가 아니라 이미 보지 못했던 새로운 문제에 대해서 잘 푸는 게 일반화예요.
알겠어요 여러분 일반적으로 일반화가 여러분 나중에 소프트 영화 배우면 이제 추상화 이런 거랑 비슷해 뭔가 되게 어떤 구체적인 것만 잘 푸는 게 아니라 스토리를 잘 만드는 거죠.

참석자 1 28:26
한마디로 우리가 좀 일반적으로 생각할 수 있는 능력 수상 이론을 배우는 건 이론 그렇죠 여러분 이론 이론을 배우면 여러분 5만 가지를 다 알 수 있는 거잖아요.
그쵸 뭔가 깨우침을 얻는 거지 원리를 깨닫는 거 일반화 그런 거예요.
여러분 그래서 여기 일반화를 다른 말로 하면은 여기 일반화라는 거 외우세요.
일반화 제너널라이제이션 일반화가 다른 말로 뭐냐 프리벤팅 오오 피팅이라고 할 수 있어요.
프리벤팅 오피팅 오오 피팅을 방지하는 거 알겠죠?
여러분 그래요. 그다음에 머신러닝 모델을 어떻게 평가하냐 그다음에 훈련 성능 어떻게 향상하냐 일반화 성능 향상하냐 이런 걸로 되어 있는데 여기 보면은 이제 이 머신러닝 모델 평가하는 건 이제 평가 평가를 할 때 우리가 조심해야 될 거 그런 거에 대한 용이 나오는데 나중에 보겠지만 여기서 제일 핵심적인 것 중에 하나가 이제 제일 바보같이 했을 때가 베이스 라인이잖아요.
이게 베이스라인 베이스라인이라는 걸 다 정해야 돼요.

참석자 1 29:29
그쵸 전에 얘기했듯이 거의 데이터 실제 세상에 대해 존재하는 거의 비가 안 온다 온다 이런 거 있잖아요.
비가 거의 안 오잖아. 근데 안 온다고 하면 90% 맞잖아요.
근데 그러면 제대로 하는 게 아니잖아요. 사실 그렇죠 그러니까 그런 거에 대한 베이스 라인이 얼마냐 그쵸 그런 거에 대한 걸 정하는 거에 대한 내용이 나오고 제대로 된 평가를 하기 위해서 왜냐면 우리가 오해하거든.
그래서 그다음에 5조 3절 내용은 훈련 설명 하시는 건데 훈련이 잘 안 될 때 어떻게 해야 되느냐의 문제예요.
훈련 성능을 향상하는 거에 대해서 여기 대표적으로 이제 사실 여러분이 러닝 레이트에 대해서 많이 배웠잖아요.
그쵸 러닝 레이트 러닝 레이트가 너무 크면은 아예 훈련이 안 될 수가 있지.

참석자 1 30:10
그렇죠 너무 작으면 너무 오래 걸리고 그렇죠 그 내용도 나오고 그다음에 사실 우리가 또 훈련을 빨리 하기 위해서 배치 장거 사용하는 거 기억나잖아요.
여러분들 그쵸 배치 데이터 사이즈 어떻게 하냐 이런 내용이 주로 나와요.
알겠죠 그다음에 마지막에 일반화 성능 향상하는 거 요거는 오피팅 방지하는 거라고 했잖아요.
여러분 사실 여기에 온갖 규제를 하기 시작해 규제 레글러 라이제이션 전에 저한테 배웠지만 여러분한테 제가 이렇게 하는 것도 지금 여러분이 일반화를 잘 하려고 너무 구체적인 내용만 아는 게 아니라 전체적으로 잘 알려고 하는 건데 제가 강의한 내용 중에 트레이닝의 맨 마지막에 여기 보면은 이거 있었잖아요.
그쵸 항상 모델이 너무 복잡하면은 일반화가 떨어지죠.
그쵸 모델이 여기 여기 없는 여기 오프팅이죠. 그쵸 이런 거 보시죠?
그렇죠 여러분 다른 그림이지만 이게 요 그림도 기억하세요.
여러분 어쨌든 그래서 모델을 복잡하게 만들면 안 되는 거야.

참석자 1 31:14
은혜를 너무 복잡하게 만들지 않는 거에 대한 내용들이 이제 사실 레귤러 라이제이션이라고 그래서 규제라고 그러거든요.
규제 모델 모델뿐만 아니라 그래 사실 세 가지 규제라고 내가 정리가 됐어.
어쨌든 규제를 하는 거에 대한 내용이 나올 거예요.
에글로레젠이션 그래요. 그래서 저도 점점점 일반화를 잘 시켜가고 있는 중이고 갑시다.
여러분 전에는 막 다 따로따로 보이던 게 점점점 이렇게 합쳐지고 있다 했죠.
계속 갈게요. 일반화는 그래서 머신러닝 목표로 여기 요 그림부터 요 그림 이 그림 전에도 보여줬죠.
그치 너무 좋다고 이 그림 그쵸 이 그림 요거 요거 영어로 다 알려고 그랬죠.
여러분 여기 이쪽 x축이 이게 훈련 반복이 여러분 에폭이죠.
에퍼 에폭이죠. 영어로는 에폭이 폭 그쵸 이쪽 알죠?

참석자 1 32:11
여러분 여기 여기 여기 루스죠 루스 그쵸 딴 데 1시 많이 나오죠 그쵸 그래서 여기 루스가 이제 여기 트렌 데이터에 대한 거 여기 밸리이션 데이터에 대한 거 그쵸 쟤 옛날에 얼리 스타킹 그림에서도 제가 있었죠.
이 그림이 이 그림이랑 같은 거예요. 여러분 교과서에 나오지만 여기 얼리 스타킹 있지 않았나 요거 있잖아요.
요거 요거 요 그림으로 이게 다른 책이 다르게 나오지만 이게 f이 있고 rmsa가 로스잖아요.
여러분 그쵸 이게 트레인 데이터에 대한 밸리데이 데이터에 대한 트레인 데이터 항상 줄어들지만 밸리 데이터 언젠가는 늘어나고 이러잖아요.
그래서 여기 베스트 모델은 여기다. 그쵸. 지금 사실 앞에서도 그런 거 계속 한 거예요.
화장에서도 그렇죠. 화장에서 우리 케이 플루 플러스 밸리데이션 왜 했는데 이거 이렇게 될까 봐 그런 거잖아요.
그쵸. 근데 벨리즈 데이터 못 믿겠으니까 케이 홀드나 한 거지 그쵸 그런 거 이해하시는 게 여러분이 되게 중요해요.

참석자 1 33:10
실제 여러분 딥러닝 시킬 때 여러분 이제 안 하고 사는 사람 별로 없을걸 제대로 취업하면 여러분 거기 하고 살 것 같아요.
알겠죠 그래요. 그래서 그래서 뭐냐 다시 얘기하면 이 그림이랑 저 그림이랑 다르게 그렸지만 같은 거라는 거 알겠어요.
여러분 그리슨 데이터 검증이 걸리는 데이터일 거고 이게 트레인 데이터 거라 가 있어요.
이 원리 스타 비우셔야 된다고 그렇죠 그래프는 약간 생긴 방이 다를 수 있어도 같은 얘기예요.
그렇죠 됐어요. 그리고 이거를 이제 훈련 반복에 대해서 그럴 수도 있지만 모델 컴플리스트에 대해서도 그리 적 제가 드렸잖아요.
다른 거죠. 그것도 그렇죠 오피팅이 다른 관점 이거는 여기는 시간 훈련에 대한 거고 제가 여기 마지막에 이거 이 그림은 또 모델 복잡도에 따라서 그린 건데 이 에러가 결국은 모르스 뭐 그렇죠 에러랑 오스랑 같은 말인 거 여러분 알죠?
그래요.

참석자 1 34:14
그다음에 그래서 과제 적합이 되는 거는 여기 교과서에 여기 보면은 자동 섞인 호연 데이터라고 182쪽에 진한 색으로 나오죠.
그렇죠 여러분 그 위에 적혀 있는 거 여기 보면은 과대 적합은 바로 윗줄에 과대 적합은 요도 문제가 나오죠.
데이터에 잡음이 있거나 불확실성이 존재하거나 드문 특성이 포함되어 있을 때 특히 발생하는 변수가 적혀 있죠.
그렇죠 약간 좀 성견 같아 약간 맞는 말이에요. 감자가 왜 생기냐 잡음이 있거나 불확실성이 존재하거나 근육투성이 포함되어 있을 때 저 성경 같아 좋은 말이에요.
181쪽에 1번 자궁이 섞인 훈련 이게 적혀 있죠 잡음이 여러분 영어로 뭐예요?

참석자 1 35:05
노이즈 노이즈 여러분 테스트 플로우 플레이 그라운드에 거기 노이즈 넣을 수 있는 거 있었는데 아나 이거 왜 그랬냐면은 실제로 데이터가 대부분 다 그렇거든 데이터가 거의 깨끗하지가 않고 자분 섞인 데이터 여러분 뭔지 느껴 보세요 여러분 182쪽 너무 잘 찾았어 이거 확실해 참 이상한 엔지스트리 느낌 이런 이상한 거 있잖아요.
여러분 공부하는데 문제가 더러워 그쵸 그런 거 그쵸 그 문제 잘 풀어야 되나 아니지 그 문제 잘 풀려고 수련을 한다 아니지 그렇죠 여러분 그래 이걸 내가 이게 무슨 숫자인지 알아보려고 노력할 필요가 있냐 아니지 걸러야지 그쵸 정승진 선생이 말씀하신 게 좋은 것 같아요.
그렇죠 이런 더러운 분들은 그렇죠 욕하면서 안 해야 돼.
그렇죠 이런 걸 잘 쓰려고 훈련을 해 봐. 이상해진다고 그렇죠 그래요.
그다음에 가보면 이런 것도 있어요. 여러분 레이블을 잘못 붙였었어.
정답이 틀렸어. 그쵸 정답이 틀린 거를 여러분 열심히 공부했다.

참석자 1 36:04
이상해지지 사람이 그렇죠 여러분 이상한 선생님 만나면은 정신 이상해져요.
진짜 알겠죠 여러분 조심해야 돼요. 그렇죠 그래서 실제로 다음이라는 이런 거 예를 들어서 이게 이상치라는 건데 사실 이상치 아웃라이어라고 하기도 하고 이게 데이터가 사실 이쪽 대충 이렇게 골라야 되는데 이 이상 치들이지 그쵸 교과서 있잖아요.
이거 넣죠 이렇게 훈련 이거 이렇게 훈련할 거 아니야 그럼 이렇게 되잖아요.
이렇게 그렇죠 이해돼요. 여러분 교과서에 나오는 그림 너무 좋잖아.
그쵸 저거는 무시해야 돼. 이런 것들은 그렇죠 그렇죠 여러분 그래 이런 것들을 열심히 하려고 노력을 하면 이게 여기 모델 모델 복잡도들을 보면은 이게 모델 복잡도가 얘랑 왼쪽이랑 오른쪽이랑 어떻게 복잡해 보여요?
모델이 모델이 이거잖아요. 여기 얘는 이런 거잖아.
똑같은 얘기 비슷한 얘기 알겠죠 여러 모델이 훨씬 복잡하잖아.
그쵸. 아니 이게 아니라고 그렇죠 그렇게 하면 안 된다는 거지.
이거는 자금 때문이야.

참석자 1 37:08
그쵸 노이즈 때문에 노이즈라는 거는 라벨이 잘못된 것도 있고 이 자체가 이상하게 생겨먹어서 도저히 분리할 수 없는 거 알겠죠 여러분 이거 기억을 하세요.
이거 되게 좋은 책이야. 진짜 아니 왜 나는 인사이트를 줘요 여러분 실제로 그렇잖아요.
일상생활 하러 갈 때도 여러분 출연해야 되는데 저런 수련을 시키나 하면 안 해야 알겠죠.
여러분 그러니까 이상한 수혈을 시켜 알겠죠 그래요.
그다음에 나도 진짜 옛날에 진짜 옛날에 고등학교 중학교 선생님 중에 진짜 이상한 문제를 내는 거야.
가사 선생인지도 너무 태명 선생님이 문제가 너무 더러워 맞아 주지.
우리가 하는데 진짜 그렇게 살면 안 되는 거지 문제를 그렇게 내 이해되죠?
여러분 그래요. 그다음에 과대 여기 보면 요거 불확실한 특성 불확실한 특성이 이거는 여러분 이게 원래 이런 건 확실하게 여기는 딱 구분할 수 있는데 여기 막 섞여 있는 놈들이 가끔 있을 수 있는 거예요.
실제 세상에도 회색지대.

참석자 1 38:10
근데 여기를 억지로 하려고 하면은 되게 이상해진다고 그 모델이 그쵸 원래 속성 자체가 불확실한 놈이 있는데 우리는 얘랑 얘만 잘하면 되지 여기까지 하려고 그러면 이 이상해진다.
원래 근데 이거는 잡은건 아닌 거지. 원래 데이터가 진짜로 진정으로 이런 거지.
이거는 잘못된 놈이야. 여러분 이해돼요. 얘는 잘못된 게 아니라 원래 그런 거야.
그쵸 모호한 영역이 있을 수 있는 거지. 세상에. 근데 이거를 억지로 분류하려고 그러면 더 이상해진다는 거지.
이건 인정하고 여기는 어떻게 될지 모르는 놈이라고 하는 게 좋다는 거죠.
알겠죠? 됐어요. 그래 특성 공간에 원래 모호한 유형이 있을 수도 있다는 거지.
그래서 이거는 이렇게 이쪽 이쪽에서 끌어내는 게 안전한 거예요.
알겠죠? 이거를 막 옷으로 이렇게 하는 게 위험하다는 거지.
그래요. 그리고 그다음에 여기 여기겠어 내 마지막이 여러분 번호 매기세요.

참석자 1 39:07
여러분 181쪽에 1번 자분석 클라미타 1번 매겨놓고 183쪽에 브라이스 특성에 2번 매겨놓고 부부 수성 가치 상관관계 상 더 매겨놓고 그쵸 세 가지를 약간 좀 설명처럼 약간 되게 잘 해놨어요.
이분이 그렇죠 그게 지금 다 이게 뭐냐면 어

참석자 1 39:30
과대 적합을 일으키는 놈들이라는 거지 알겠죠 모피팅 그렇죠 알겠죠 여러분 그래요.
그래가지고 여기 뭐 대구 투자 가세 상관관계는

참석자 1 39:46
금수성은 굉장히 이상한 데이터가 가끔 섞여 있다는 거죠.
특이한 놈 이거는 약간 아웃라이어랑은 다르고 얘는 잘못된 거고 얘는 또 모호한 건데 얘는 굉장히 드문 놈이 가끔 있는 거죠.
그런 거에 대해서 또 풀려고 그러면 그러니까 여러분 수능에서 맨 마지막 문제 제기는 게 낫다 이거죠.
그런 거죠. 여러분 그거 괜히 그거 풀려고 그러다가 또 이상해질 수 있으니까 그 문제 푸는 데는 뭐 어쨌든 그래서 감성 분류 작업하려 할 때도 되게 어려운 단어 있잖아요.
그걸 너무 열심히 하면 또 곤란한 거지 그래서 아예 제껴버리는 게 낫다는 거지 잘 안 나타나는 거예요.

참석자 1 40:29
그리고 여러분들이 편견을 가지는 거지 사람이 편견을 가지게 되는 것도 공지서 때문에 집에 가게 이상한 걸로 하나 봐가지고 그 때문에 막 우리가 다 그냥 그렇다고 그렇죠.
머리가 흰 사람 만났는데 그 사람이 성격이 되게 더러웠어.
머리가 하얀 사람은 성격이 다 더럽다고 젊은 애인데 머리가 하얗게 염색했는데 걔가 성격이 되게 이상했거든요.
그러면 이제 머리가 하얗게 드물잖아. 샘플이 딱 하나잖아요.
한 사람 봐놓고 그걸로 다 일반화시켜버리면 곤란하잖아요.
여러분 근데 이해되죠 그런 거예요. 됐죠 그래서 가짜 상관관계 가짜 상관계도 많지 상관관계가 실제로 없는 거지 때 드물 때 많이 나타나죠.
그쵸. 오히려 여기 되게 좋은 얘기다. 이거 이거 이거 봅시다.
이거 이 단어가 항상 부정 레이블이 우연히 있었어요.
여러분 실제로 그 데이터 데이터에서 트레이 데이터에서는 우연히 그랬어요.
여러분 이런 거야 같은 생각이 뭐냐면은 어떤 애가 자기 가족에서는 여자는 무조건 힘이 센 거야.

참석자 1 41:28
그 가족에서는 그랬어요. 그래서 여자 남자가 훨씬 힘이 세다고 계속 평생을 그렇게 살고 나타나는 세상에 나타나면 되게 위험하잖아요.
같은 생각이잖아 우연히 그런 걸 뭔 얘기인지 알겠어요 여러분 그 트렌드 이터에서만 우연히 그랬는데 전혀 상관계가 없는 거잖아.
힘이 여자가 세다는 부담은 없잖아요. 사실은 사람이 중요한 거지 오히려 풀렸잖아.
그렇죠 근데 그럴 수 있지 내가 데이터에서 그러면 그렇죠 그런 거죠.
여자의 힘이 세고 남자의 힘이 약하다 이렇게 하는 건 위험하잖아.
사실은 아닐 수 있잖아요. 여러분 그래요. 그런 거 같은 상관관계라는 분노투성 따로 해놨네.
좋은데 분노투성으로 하는 게 아니라 자체 상관관계 같지 그렇지 알겠죠?
그래 그런 거 트렌드 데이터가 너무 작을 때부터 발생하지 알겠죠?
그래요. 그래서 여기 나오는 내용들 하지 맙시다.

참석자 1 42:19
그냥 귀찮아서 다 이해를 넘어가고 그것만 여러분 기억하시면 될 것 같고 그다음에 노이즈 넣었을 때 이 내용 하는 것 중에 제가 말로 한 거 다 세워도 될 것 같아요.
갑시다. 그래서 그다음에 5.2.2조 가면은 186조라고 해요.

참석자 1 42:37
일반화의 본질이라는 거에 대해서 얘기하는데 교과서 틀린 말 다 바로 다 봤어요.
187쪽에 187쪽에 여기 입력의 가짓수가 여기 보면은 108 매니폴드 가설이라고 적혀 있잖아요.
그쵸 매니폴드 가설에 랩 리스트 분류기가 28 곱하기 28이 정수 배열이고 이게 0하고 해서 255 값을 가지잖아요.
그쵸 28 곱하기 28이 784거든요. 그러면은 이게 가능한 가짓수는 256 784승이잖아요.
256까지가 가능하고 그다음에 또 256까지 가능하고 256까지 가능하니까 256 곱하기 2250 곱하기 이래야지 계속 그쵸 이해돼요.
여러분 이해돼요. 이렇잖아요. 근데 저자분이 거꾸로 적어놨죠.
그렇죠 74 1 56승으로 적었잖아요. 왜 이렇게 시죠?
번역을 잘못하셨어 영어를 알겠죠? 여러분 영어 먼저는 명확하게 돼 있어요.
알겠죠 원자는 이렇게 숫자를 안 하고 말로 적혀 있는데 번역은 거꾸로 하셨어 알겠죠?
여러분 됐죠?

참석자 1 43:49
이런 거 틀리면 여러분 되게 위험해요. 알겠죠? 됐죠 그다음에 어쨌든 굉장히 숫자가 경우의 수가 엄청 많아요.
이거 이거 여러분 TF 14 2566 7 8 4에 256승이랑 얘랑 어느 게 더 어느 게 더 큰 것 같아요.
여러분 이거랑 이거랑 이게 더 커요. 784 무조건 지수 중이 높은 게 지수가 어마어마 지수가 어마어마해요.
알겠죠? 그래요. 근데 애매하면 여러분 다 로그 치에서 비교하면 되는 거 알지 그래요.
그래요. 그다음에 그다음에 그래서 이것도 그림 57은 이게 이제 사실 데이터가 3에서 6으로 변하는 모습, 8에서 5로 변하는 모습, 2에서 6으로 변하고 6에서 0으로 변하고 이런 거 보이죠.
여러분 6에서 0으로 변하고 이런 거 보이죠.

참석자 1 44:41
교과서에 있는 거 이게 전부 다 데이터에 뭔가 명확한 상관계가 있어서 사실은 뭔가 실제 우리가 임의 숫자가 임의의 형태로 존재할 수 있는 게 아니라 이렇게 모호한 영역이 존재하고 뭔가 구체성이 있다는 거지 그래서 이런 것 때문에 여러분 우리가 생성 AI가 가능한 거예요.
사실은 그렇죠 나중에 나오지만 나중에 해 봅시다.
여러분 그러면 이런 거 이런 특성 때문에 숫자 공간이 이제 다차원 매니폴드라는 게 여러분 여기 매니폴드라는 게 매니폴드 공간을 가지고 있다는 게 사실은 숨겨져 있는 뭔가 확률 분포가 있다는 거지 확률 분포 확률 분포가 존재한다는 거지 아무 데나 존재하는 게 아니에요.
그쵸 숫자 중에 이렇게 여기 숫자가 이렇게 이만큼 자리가 있으면 여기에 존재하는 여기 숫자가 거의 안 나올 거 아니에요 그쵸 여기 여기 안 나와 무조건 이 여기서 이제 좀 약간 여기다 여기 나타나고 약간 약간 정해져 있어.
그렇죠 아기 숫자 뭔가 정해져 있어.

참석자 1 45:41
그렇죠 6하고 약간 뭔가 더 약간 뭔가 우리가 다 숫자라는 거는 확률적으로 고해하는 공간이 이거 말고 다른 게 또 사실 나오는 거 보면 재미있는 게 자동차를 만들려고 그러면은 어쨌든 바퀴가 달려 있고 지붕이 보통 있잖아요.
그렇죠 거기서 변하는 거지 갑자기 바퀴가 위에 달리거나 그러진 않잖아요.
그쵸 그래요 뭔가 확률 우표가 더 명확히 했다는 거지 알겠죠?
그래요. 그다음에 여기 한 189쪽에 189쪽에 일반화의 원천인 보관이 교관이 여러분 인터폴레이션 인터폴레이션인데 안 적혀 있네.
보관이 인터폴레이션인데 인터폴레이션은 샘플 뭔가 뭔가 비어 있는 부분을 채우는 건데 평면포를 통해서 채우는 거예요.
항상 그래서 그리고 재미있는 게 이게 2하고 0을 매니폴드 보관에 이제 매니폴드 보관이랑 확률 포에 의해서 확률적으로 존재하는 걸로만 우리가 이거를 평균 내면은 이렇게 되는데 확률적으로 존재하는 구간에 대해서만 얘를 그냥 선형 평균 내면 다 섞어버리잖아요.

참석자 1 46:54
그쵸 확률적으로 여기는 잘 존재하지 않는 거야. 이해돼요 여러분 여기는 존재를 많이 하고 그럼 평균 내면 이렇게 된다고요 확률적 확률 분포가 있다고 숫자에는 그냥 평균 내면은 그냥 다 쏟아버리면 이렇게 막 못 알아보는 글씨가 나오지만 매니폴드 구가하는 확률 평균 확률 분포를 가지고 채우는 거예요.
알겠죠? 평균적으로 여기 존재 하면 여기 존재를 하면 다 채우면 이렇게 된다고 알겠죠 그래요.
그게 중요하죠. 환경소를 찾아내는 게 중요해요.
그래서 학습지 학용소를 찾아내요. 우리가 나중에 잠재 공간이라고 그래 레이턴트 스페이스라고 그래서 안 좋겠죠.
여기는 나중에 할 거예요. 그래서 등등 일반화 여러분 진짜 여러분 지브리 이미지 만들어내는 거 있잖아요.
확률 표가 너무 명확해서 그런 거야. 그쵸 지브리 여러분 어떻게든 눈 비슷한 게 있잖아.
눈은 다 눈이 약간 가동이 있던지 없던지 뭔가 동글동글하고 있잖아.
흥유포가 명확하잖아요.

참석자 1 47:51
그러니까 그렇게 지우리 같다고 느끼지 우리가 다 심슨이면 스 같다고 느끼지.
그렇죠 우리 지금 스테트 피티가 이미지 만들어낸 거 있잖아요.
그쵸 성명표가 우리가 명확하게 우리가 인지하고 있지 그거를 학습하는 거야.
걔네들은 그게 일반화라고 그래요. 그래서 딥러닝이 됐다고 하는 이유로 50분 여기까지 해야겠네.
그래요. 여기까지 하고 다음 시간에 이어서.


clovanote.naver.com