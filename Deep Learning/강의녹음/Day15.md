딥러닝 day15_1
2025.05.07 수 오전 10:01 ・ 49분 7초
심승환


참석자 1 00:08
이거 있었던 사람 이거 쓰면 안 돼

참석자 1 00:30
저기 지난번에 CNN 들어간다고 그랬는데 타이에 들어갈 때 7장에서 사실은 제가 좀 안 한 게 몇 가지 있는데 결국은 사실 보니까 다 문제가 되긴 하더라고요.
나중에 나오고 나오. 그래서 일단 7장 그냥 빨리 나가기보다는 7장 다 나가는 것보다 나중에 이제 8장 9장 하고 나서 숙제를 내줘야 돼서 마지막 첫 프라이트 하다가 아직까지 간단하게 어쨌든 한 번 해봐야 되잖아요.
이 코딩을 계속 제대로 한 번도 안 했으니까 그래서 고대 그 8자 구장을 나가야지 할 수 있기 때문에 진도를 빨리 나가긴 해야 돼서 어쨌든 마질 서플래싱을 하긴 해야 되는데 그건 나중에 하고요.
파이토치랑 비교하는 것도 마을 서플래싱을 해야지 비교가 제대로 돼서 그것도 나중에 하고 일단 그래서 지금 강의 자료에 제가 새로 올린 것 중에 그 여기에 여기 페이션스 밸류라는 거 있잖아요.
이거를 제가 안 했더라고요. 그래서 얼리 스타핑 7장에 나오잖아요.
그러니까 콜백 함수 정의하는 거 있었죠.

참석자 1 01:42
첫 장에 얼리스타핑이랑 마대 체크 포인트 이게 몇 쪽에 있냐면은

참석자 1 01:55
내장된 플레로파 평가 루프 쓰는 거 원래 원래 이거 했고 폴리 사용하겠죠.
폴릿 사용하기 7.3절이네. 7.3절이

참석자 1 02:11
3절이 10점 3절이 260쪽인데 여기서 7.3절 2절 소류 사용하는 거 그거죠 3 26 미안해 7.3.2절이고 263쪽 여기에 콜백 사용하는 거에서 제가 책 포인트랑 얼리 스타킹 두 가지 가 중요해서 그걸 얘기해 줬었고 이거 여기에 대한 내용을 사실 대충 했는데 여기에 파라미터에서 조금 약간 헷갈리는 게 있어서 그거는 정리를 해 주려고 그래요.
그래서 여기 보면은 265쪽에 265쪽에 265쪽에 있죠.
265쪽에 265쪽에 265쪽에 지금 코드 7 19가 어쨌든 이게 여러분 한 번에 보이죠.
여기 슬라이드는 이렇게 나눠져 있지만 다시 보면은 원래 이제 피트 함수 부를 때 여러분이 맨날 여기 이렇게 트레인 하는 그 데이터 그쵸 그다음에 네이버 정답 값 주고 그다음에 북 주고 가끔 밸리데이션 데이터도 주고 그래요.
이렇게 끝났는데 여기 콜백스라는 거 처음 들어왔었어요.

참석자 1 03:38
그쵸 여기 그 콜백스 콜벳 미스트 적혀 있는데 변수 적으세요 여기 지금 변수 변수인데 여기 보면은 앞에 이렇게 변수가 이렇게 익혀 있잖아요.
그쵸 보이죠. 여러분 뭐 하는지 알겠어요 지금 제가 여러분 이거 지금 코드 7 19 보고 있는 거예요.
265쪽에 265쪽에 코드 7 19를 봐요. 여러분 그래서 피 함수에 여기 보면 이 콜백스 는 하고 이렇게 줄 수 있어요.
그쵸 변수로 줬는데 변수를 안 주고 직접 여기서 줄 수도 있겠죠 여러분 리스트를 이해돼요.
당연히 당연히 직접 쓰는 경우도 많아요. 이렇게 변수로 안 하고 이해되죠?
봐요. 바로 이렇게 보면 예를 들어서 매트리스 하는데 여기 에큐리스 적혀 있잖아요.
여러분 근데 여기 여기 이 리스트로 레트릭스 돼 있는 게 이게 변수로 할 수도 있잖아 그쵸 변수로 하고 변수를 부를 수도 있잖아요.

참석자 1 04:31
그쵸 여러분 선배들이 하도 옛날에 시험 보는데 기말고사에서 제가 이걸 못 알아보길래 지금 여러분도 제가 여러분 여기 보면은 요거 예를 들어서 이렇게 이렇게 했잖아요.
요거 요거 여기 그냥 바로 직접 썼잖아요. 이거를 여기 앞에다가 이 사이에다가 a는 하고 이거 이렇게 변수로 해놓고 여기다 a 적을 수도 있잖아.
당연히 그 사람들이 이렇게 여기 변수로 해서 할 수도 있고 이렇게 여기도 지금 변수 여기 변수로 돼 있잖아요.
당연히 근데 이거 여기 앞에 있는 거 여기 여기서부터 교과서는 여기 같이 있지 이렇게 요거를 그냥 여기 여기 요거 요거 요거 요거 이거 직접 쓸 수도 있을 거 아니야 그쵸 리스트로 해가지고 그렇죠 이해되지 그쵸 이해되죠 무슨 말인지 알겠죠 여러분 당연히 변수로 항상해야 되는 건 아니고 그냥 다 변수는 원래 다 그냥 대체 가능한 거잖아요.

참석자 1 05:24
알겠죠 그래 그러고 다시 그러면은 콜백에 이제 콜백도 리스트를 주는데 여러 개 줄 수 있으니까 여러 개를 줄 수 있는 거니까 여기 보면은 지금 여기 두 개가 적혀 있는데 콤마로 돼 있어서 얼리 스타킹 하나랑 나대실 포인트가 있는 거죠.
그쵸 알겠죠 그리고 오픈북으로 볼 때는 여러분이 다 채울 수 있어야 돼.
무슨 의미인지 알고 알겠죠. 시험 볼 때 이거 뭔지도 모르고 못 찾고 이러면 여러분도 별로 식빵이 알겠죠.
있는 줄 알고 있으라고 찾아서 쓸 수 있어야 돼. 알겠죠 기말고사에 낼 가능성이 높아요.
알겠죠 그럼 차라리 쓰라고 제가 이제 여러분 기말고사 낸다 이거는 여러분 안 까먹길 바라는 거죠.
여러분 이거 배웠는데 이거 모르고 못 찾았으면은 좀 별로죠.
그쵸 그래서 이렇게 강조하는 거예요. 시험이 나온다는 거는 시험이 중요한 게 아니라 여러분이 좀 남는 게 있어야지.
그쵸 할 수 있어야 된다고 알겠죠. 그래서 여기 파일 테스트 모니터 셀 메스톤 이렇게 적혀 있잖아요.

참석자 1 06:24
그쵸 이 의미가 뭔지 설명을 좀 자세하게 해줄게요.
여러분 하이패스는 이제 체크 포인트 같은 경우에는 이게 이게 뭐 하락인 건지 여러분 알잖아요.
저장은 세이브 중간중간 하는 거죠. 그쵸 그래서 이 파일에다 저장하라는 거지.
이 파일에다가 하이패스 하이패스가 여기 지금 그냥 파일 이름만 적혀 있잖아요.
현재 디렉토리에 저장하는 거겠지 그쵸 이걸 절대 경로로 줄 수도 있고 상대 경로로 줄 수도 있을 거예요.
그쵸 그냥 예를 들어서 여기 안에 a 슬래시 이렇게 하고 적혀 있으면 현재 디렉토리에다가 디렉토리 a 만들고 저장을 하는 거지.
그쵸 근데 제가 해보니까 죽더라고요. ad2를 만들어 놔야지만 되지 안 만들어 놓으면 디렉터리 없다고 그러면 죽어요.
알겠죠 아니 근데 그것도 또 하기 나름이지 만들기 나름이잖아 이 사람들이 새로 만들고 a 디렉토리 만들고 난 다음에 저장할 수도 있을 것이고 그것도 하기 나름인데 그러니까 그런 걸 외울 필요는 없겠지.

참석자 1 07:14
그쵸 사실은 내 말은 여기 이제 파일 피스라는 건 여러분 파일이 들어간 파일 경로가 들어간다는 건 알고 있어야지.
그쵸 알겠죠 그래요. 그다음에 모니터 여기 모니터 세이브 베스톤이 이렇게 적혀 있는 거 두 개가 같이 쓰이는 건데 교과서에도 분명히 두 개 같이 적혀 있는 거 보이죠.
여러분 보면은 이렇게 두 개가 쌍으로 여기 이렇게 설명돼 있잖아요.
그쵸 여기 지금 굳이 세일 베스트 온이라는 게 적혀 있잖아요.
네 그러면 이게 적혀 있으면은 베스트라는 거가 언제 베스트라는 건 뭐가 최고로 좋다는 건데 언제가 최고로 좋은지에 대한 지표가 있어야 될 거 아니에요?
그쵸 그 지표로서 여기 모니터 이거 이거를 모니터는 이걸 보겠다는 거잖아요.
모니터 본다는 뜻이죠. 여러분 감시하는 게 모니터링이라고 그러잖아요.
여러분 그쵸 밸리데이션 로스 요 값이 적혀 있죠 그쵸 벨로스 벨 언더바 로스 값을 모니터링하면서 이 값이 제일 좋은 것만 저장하겠다는 거지.

참석자 1 08:15
그쵸 만약에 이제 밸리데이션 로스 값을 보다가 이게 커지면 저장 안 하고 작아지면 저장하고 계속 지금 저장한 것보다 이해되죠.
여러분 그때마다 저장하겠다는 거예요. 이해되죠 이걸 안 하면은 계속 저장하거든요.
그 저장하면 시간이 많이 걸리고 버벅거리고 오래 걸리거든요.
그래서 이 파일 시스템 쓸 때마다 시간이 많이 걸리니까 베스트 오니 하는 게 좋죠.
여러분 그렇죠. 그리고 이거를 밸리데이션 로스를 썼는데 벨 로스 이렇게 하는 거 이건 스트링으로 돼 있잖아요.
그럼 이 규칙이 있는 거지 로스트 말고 또 여러분 원래 지표로도 많이 쓰는 게 또 뭐가 있어요?
에큐로시도 있고 그렇잖아요. 여러분 다른 것도 할 수 있잖아요.
지표 매트릭스 여러 개 주면은 여기 지금 사실은 매트릭에 액트로시 줬잖아요.
그쵸 큐시도 있고 로스도 있고 원래 또 그렇죠. 항상 로스는 항상 있고 그리고 여기다가 벨 말고 뭐가 그냥 벨 말고 그냥 로스랑 그냥 에트로시도 있거든요.

참석자 1 09:05
여러분 그거는 트레인 하는 로스가 트레이트로시를 말하고 벨 언더가 붙어 있는 거는 이제 밸리데이션 데이터를 줬을 때 얘네들에 대한 로스와 에트로스를 의미하는 거예요.
그렇겠지 그쵸 여러분 달달 외우지 않아도 이렇게 보면 알잖아.
이거 눈치로 있잖아요. 여러분 그렇죠 항상 이걸 코드는 코딩하는 건 여기 항상 따라하는 거잖아요.
이걸 달달 외우는 건 아니고 이렇게 한 번 보면 여러분 따라 할 수 있잖아요.
그쵸 만약에 에큐리시를 보려고 그러면 l하고 언더하고 에큐리 쓰면 되겠다.
그쵸 이해되죠? 그래요. 로스 값이 최소 최소화 될 때 저장하고 싶은 거예요.
여기는 근데 여러분 로스 값이 항상 최소가 되는 게 항상 좋지 않을 수도 있어요.
액트로시가 더 중요할 수도 있어. 그 때에 따라 다르다고요 문제의 종류에 따라서 그쵸 알겠어요.
여러분 그래서 이거는 본인이 정하는 거라고 알았어요.
여러분 됐죠?

참석자 1 09:58
그다음에 마르체크 포인트는 이렇게 여기 얼리 스타핑 얼리 스타핑에서는 얼리 스타핑은 여러분 뭐 하는 거냐면은 이제 계속 에프이 원래 에프이 여기 지금 10으로 줬는데 10번은 지금 한번 데이터를 계속 했잖아요.
그쵸 배치 사이즈는 여기 빼먹었네. 배치 사이즈를 빼먹었네.
배치 사이즈가 디폴트가 32이거 그거 외울 필요 없는데 디폴트 매치 사이즈로 하겠지 그쵸 그러면 이해되죠 그런데 에포을 10번까지 하면 할 때 여기 얼리 스텝핑이 들어가면은 10번보다 더 빨리 끝날 수도 있는 거예요.
그쵸 언제 여기 저거 주는 거지 모니터가 또 페이션스가 적혀 있는데 모니터가 있어야겠죠 언제 얼리 스타킹 할 거냐?
벨 에큐러시가 더 이상 에큐로시는 여러분 어떻게 되겠어요?
커지는 게 좋아요. 작아지는 게 좋아요. 커지는 게 좋잖아요.

참석자 1 10:50
로스트는 작아지는 게 좋고 또 그렇죠 이것도 다 이건 다 이미 그냥 암묵적으로 되어 있는 거지 이런 거는 로스트가 커지는 거를 좋아하는 사람은 없으니까 그런 건 또 케라스가 친절해가지고 또 다 케어스가 이제 여기 펜스 플로우가 그렇게 정해져 있는 거고 여기는 액트루시 해놓으면 이제 액트루시가 작아야지 그래서 더 커지지 않을 때를 의미하는 거죠.
그쵸 근데 이거를 페이션스 값을 줬어요. 페이션스 페이션스라는 건 여러분 디폴트는 0이에요.
안 안 참는 거 근데 이제 이 되어 있다는 걸 한 번도 참고 두 번 참아서 두 번까지 참아보자 혹시나 더 이렇게 되는 경우도 있잖아요.
여러분 이렇게 플럽체이션 그래프가 액트리스가 이렇게 하다가 이렇게 되면은 한 번은 참았으면 더 좋아질 수도 있잖아 이해돼요.
여러분 그러니까 두 번은 참아보자 이렇게 할 수 있는 거죠.
이해돼요.

참석자 1 11:40
여러분 그냥 계속 이렇게 이렇게 이렇게 하고 있으면 이렇게 이렇게 하시면 이거 두 번은 참아야지 두 번 참아야지 좋아지잖아요.
그래서 페이션스를 줄 수 있다는 거죠. 배치 사이즈가 좀 작거나 데이터가 충분히 많지 않을 경우에는 페이션스를 두는 게 좋지 왜냐하면 진짜 의동칠 수 있으니까 이해돼요.
여러분 또 페이션스를 좀 많이 수도 있고 여기 불을 줬는데 10 줄 수도 있고 그러면은 10 준다는 건 최소한 이제 에프 개수보다는 더 많아야 되는 거지 이게 에퍼업별로 하는 거거든요.
페이션스도 이해되죠 여러분 그래서 이거에 대해서 정확하게 이해하기 위해서 제가 이거 아니구나 제가 여기다가 이게 여기 강의 자료에다가 제가 여기 시플 시지 프런 펜션스 엘리지 얼스타킹이라고 올려놨거든요.
돌려가지고 제가 올려놓은 거예요. 여러분 이건 어떻게 올리게 됐냐면 여러분 선배님들 중에 훌륭한 선배가 있었던 거지 이거 지금해요.

참석자 1 12:39
그래서 이렇게 올리게 된 거야 알겠죠 어쨌든 디폴트 지금 교과서에서는 지금 페이션스가 2가 돼 있는데 만약에 페이션스를 안 줘 얼리스타킹에서 그러면 0이 돼 디폴트로 알겠죠 안 참는 거지 그러면은 만약에 이제 이렇게 지금 20번으로 준 거죠.
만약에 예를 들어서 20번으로 내포을 했는데 줬는데 PC에서 준 거죠.
여러분 이해되죠? 여러분 그래서 1 2 이렇게 돌아가잖아요.
여러분 그렇죠 근데 그리고 벨 여기 제가 이거 반드시 적어줘야 돼.
벨 에큐로시가 모니터 하는 거죠. 뭐에 대한 모니터링인지 봐야지 그치 여기 보면은 실제로 여기 애플마다 그냥 로스 그냥 에큐로시 벨루스 벨 에큐로시 네 가지가 나오잖아요.
밸리데이션 데이터 주면 밸리딩 데이터 안 주면 이 두 가지밖에 안 나오고 그쵸 여러분 이거 내가 별로 많이 가르쳐주려고 좀 욕심을 내가지고 실습을 거의 안 시키잖아요.
여러분 알아서 하셔 알겠죠 알아서 하세요.

참석자 1 13:36
여러분 내가 이거 맨날 시키면 진도 거의 못 나갈 거 아니야 그쵸 그리고 친절하게 촉진해 주고 검사하고 그런 것도 안 하고 있죠 4학년인데 알아서 하면 내가 지금 조교도 사업 요원 쓰기 힘들고 알아서 하세요.
알겠죠 알아 먹어야 알겠죠 벨 로스 이거 원래 로스 에큐로시가 원래 있다가 트레인 할 때는 그다음에 벨로스 벨 에큐로시 이거는 밸리데이션 있다가 좀 생기는 거야 지 그래서 지금 모니터는 벨 에큐로시를 했을 경우에 알겠죠 그러면은 얘는 무시하고 얘만 신경 쓰면서 이제 페이션스를 하겠는 거지 그쵸 첫 번째는 이랬어요.
두 번째는 좋아졌지 세 번째 퍼 더 좋아졌네. 네 번째 거 좋아졌는데 계속 좋아지면 계속 가는 거예요.
그렇죠 신경 안 쓰이고 그러다가 보면은 계속 좋아졌지 그럼 여기 봐봐요.
여기서 9774 좋아졌네 여기는 좋아졌어요.

참석자 1 14:27
좋아졌네 계속 좋아졌는데 여기는 안 좋아졌죠 안 좋아지는 순간 안 좋아졌네 하고 그냥 끝나 여기서 끝나버리는 거예요.
이러면서 끝나버려요. 한 번도 안 한 번만 감소하면 그냥 이제 그만합시다.
이러는 거죠. 페이셔서 0이면 이해되죠 그래요.
그다음에 일로 해요. 1 1로 하면 어떻게 하겠어요?
여기 계속 증가하다가 증가했는데 여기 감소를 했나?
다 줬다고 감소 안 했는데 이거 뭐야 이거 틀렸어 9794 감소하지 않았는데 이게 뭐야 왜 이래?
실수가 증가했잖아. 그쵸? 여기서 봐주는 게 아니고 다른 데서 봐주는 잠깐 잠깐 봅시다.
이거 내가 실수한가 본데 9 5 5 9 9 6 97 97 9 7 6 7 9 7 7 1 97 92 계속 증가했는데 봐주긴 뭘 봐줘?
여기서 감소했잖아요 그쵸? 이상하네. 그러나 뭐가 이게 잘못된 것 같은데 미안해요.
여러분 이것도 실수했네. 이거 뭔가 잘못됐어요.

참석자 1 15:46
여러분 이거 틀렸네 틀렸어 그렇죠 분명히 여기서 여기서 안 봐주는 건 이해되죠.
여러분 그렇죠 여기서 어디서 했어? 한번 나중에 다시 볼게요.
이거 고쳐야겠다. 그다음에 어쨌든 이 돌려서 나온 건데 뭔가 실수 되는 것 같은데 다시 볼게요.
왜 그다음에 여기는 두 개면은 여기 개선되지 않았는데 참고 개선되지 않았는데 참고 여기 두 개일 때 프레셔스가 이임으로 더 이상 여기서 여기서 설명해 놨어요.
여러분 알겠죠? 이거 이거 이상한데 저거 이상한 건 내가 알았으니까 다시 또 붙여볼게요.
여러분 이상하네. 왜 이렇게 이상하지? 아니 내가 이거 안 적어놓으면 까먹어서 그리고 적어놓는 거예요.
지금 까먹었다. 셀 oc 이거 이상하네. 어쨌든 거기 말고 이게 다 까요?
3이면은 삼미녀는 여기는 왜 뭐냐 그냥 계속 끝까지 갔다 오 이런 거 같은데 15 이거는 제가 부채라서 접자 말하는 건가 세 번은 어쨌든 참았을 거예요.
그리고 여기 지금 여기 15에서 멈췄네. 그쵸?

참석자 1 17:06
그래요 어쨌든 이런 식으로 여러분 이해하셔야 알겠죠.

참석자 2 17:09
그래요. 교수님 그러면 그 연속 개수가 아니라 그냥 토탈 개수로 따지는 건가요?
감소하는 횟수를

참석자 1 17:19
연속 개수가 아니고 토탈 연속 개수더라고요. 연속 개수 연속 개수였어요.
왜냐면은 이거 한번 이건 다 준 건 그냥 넘 봐준 거는 그냥 잊어버려요.
그 연속으로 연속으로 그래야 되나 그렇더라고요.
그게 맞지 옛날에 있었던 역사는 중요하지 않아 개선되고 있으면 계속 자라는 거잖아요.
여러분 합리적인 게 뭔가 생각해 보세요. 알겠죠?
옛날에 몇 번 나빠졌던 분이 지금도 손대고 있으면은 그거는 뭐 중요하지 않잖아요.
옛날에 있었던 일이 그렇잖아요. 그쵸 아니 여러분 생각해 보라고 여러분이 만약에 그게 아닌 것 같으면은 새로운 API가 필요하겠죠 그쵸?
아니면 여러분이 만들 수도 있어요. 여러분 이런 거는 이런 거는 히스토리 카운트 해가지고 여러분이 중간에 멈출 수도 있을 거 아니야 그런 것도 컴백을 만들 수가 있어요.
알겠죠? 그런 거 안 가르쳐줬지만 제가 트레인 스텝 같은 거 해서 오버라이딩해서 할 수 있고요.

참석자 1 18:10
파이프 치 보시면 비교해 주면 여러분이 더 잘할 수 있는데 그거는 진도 숙제 내준 다음에 나중에 할게요.
여러분 좀 많이 나간 다음에 숙제를 내기 위해서 뭘 알아야지 숙제를 내거든요.
여러분 여러분이 지금까지 안 한 걸로 재미있는 숙제를 할 수가 없어서 좀 진도를 나가고 재미있는 숙제를 시켜주고 싶어요.
알겠죠? 그래요. 그래서 미리 미리 숙제를 공지해 놓을까 미리 여러분 지금 사실 이거 아직 바지를 구경만 시켜줘 이거 실제 아직 콘플레이트로 하고 싶어 거든요.
왜냐하면 혼자 하면 너무 재미가 없어서 재미가 없는 이유는 비교할 수가 없어서 혼자 다 하려고 너무 힘들거든요.
남이 한 거 보면서 하는데 남이 누가 안 한 거에 대해서는 전혀 패널티가 없어요.
알겠어요. 제가 저도 그냥 거의 강제로 짜려고 해요.
알겠죠? 아니 반대로 짜는 건 아니고 만약에 서로 같이 떼는 사람이 있으면 같이 하고 아니면은 그냥 안 온 사람이 있어.
사람 있으면 그냥 같이 하는데 보여주기 할게요.

참석자 1 19:02
여러분 제가 이거 오늘이 언제야? 5월 7일 5월 7일 근데 마감일은 마감일은 한 6월 6월 3일쯤 하고 싶어요.
이 시험 전 전 주 이 정도로 90점이 되는 근데 이거를 팀장만 제출하는 게 아니라 모두 제출하고 개별 숙제예요.
사실은 이게 개인별 리포트고 개인별로 하는 건데 다른 사람 거를 참고해서 뭔가 비교해 보라는 거예요.
여러분 여러 가지를 시도해 보고 비교해 보는데 내가 다 하려고 하면 귀찮잖아요.
그리고 만약에 이 사람이 안 했어 그럼 할 수 없는 거지 뭐 그렇죠 그런 식으로 한다는 거야.
알겠죠? 여러분이 재미있게 살자고 하는 거지 내가 굳이 이거 팀워크를 이렇게 중시하는 건 아니에요.
알겠죠? 전혀 팀워크가 아니고 일을 나눠서 하는 게 좋은 거예요.
여러분 항상 하는 게 여보는 저번에 그때 진짜 나중에 치면 나중에 할게요.
여러분 이거 미리 좀 같이 할 사람 찾아보든지 이거 보고 생각하고 있어 봐야죠.
여기도 여러분이 이걸 보면 내가 적어놓은 거 보면 모르겠어.

참석자 1 20:17
여기는 뭐 서로 일을 다른 종류로 나눠서 하는 게 아니라 같은 일을 하기 때문에 원래 팀워크는 여러분 잘하는 거 하는 거잖아요.
이건 그런 게 아니고 그냥 다 잘해야 되는 거야. 알겠죠?
달라요. 목적이야 알겠죠? 그냥 순전히 그냥 일을 나눠서 하기 위한 것뿐이에요.
알겠죠? 그리고 보면 여기 보면 테스트 북 8.2.5 9.4.5 이렇게 써야 되잖아요.
제가 여러분 그래서 제가 8장 9장을 나가야지 이걸 숫자를 낼 수가 있는 거예요.
알겠죠? 그래요. 이거 나가자마자 숙제 내주겠다 이거지 알겠죠?
트랜스퍼 러닝도 하고 싶거든 트랜스퍼 러닝 체스프 러닝이 되게 중요하거든요.
그래서 어떤 교과서는 체스프 러닝이 거의 앞에 나와요.
요즘에는 워낙 전이 학습이나 파이튜니 이런 게 중요해서 모델이 워낙 오픈소스로 많이 나와 있으니까 레이트가 있는 게 그래요.

참석자 1 21:06
어쨌든 뭔가 남는 게 있어야 돼서 너무 고생을 하지 않으면서 이렇게 됐고 그다음에 이제 강의 자료에 여러분 다시 강의 자료에 제가 얼리 스타킹 방금 했고 어 스터핑에 혹시 여러분 내가 나도 어디 적어놓을게요 스케이셔 이 예지 붙여야지 또 거기다가 아까 그랬지

참석자 1 21:41
수정 되죠 이 앞에다가 적어야겠다 이러면 나도 아깝겠지 그래요.
됐고 그리고 지금 요거 요거 하는 거 요거 요거 그다음에 이거 이렇게 되죠.
CNN의 강의 자료를 제가 여기 올려놨죠. 요거 요거예요.
이게 교과서에 좀 참신하게 설명하신다고 너무 그냥 말로만 때우는 게 많아가지고 이해하기 힘들어서 이거 보고 듣고 넘어가려고 그래요.
알겠죠? CNN은 그냥 다른 사람들이 설명하는 게 너무 좋은 게 많아서 그래요.
그래가지고 여기 보면은 교과서 제가 이거 지금 강의 자료에 있는 거 보세요.
여러분 컴퓨터 앞에 올릴 수 있어요. 컴퓨터 안 가져온 사람들은 보세요.
그래서 여기 CLN이라는 거는 기본적으로 이게 이름 자체는 이름 자체는 컨볼루셔널 뉴럴 네트워크이라고 적혀 있죠.
옛날에 그러면은 네트워크이 뉴럴 네트워크 자체가 우리가 배운 거는 뭐였냐면은 덴슬리 커넥티드 또는 풀리 커넥티드 뉴럴 네트워크이었어요.
계속 걔랑 대조되는 거예요. 여러분 알겠어요.

참석자 1 22:59
여러분 옛날 함수 코드 짤 때 그냥 교과서를 잠깐 보여줄 필요가 있어.
교과서 저것은 여러분이야 이 교과서 한번 보여주는 게 낫겠다.
미리 교과서 8장 시작하면은 아예 그냥 이렇게 나는 코드를 바로 보여드릴게요.
살짝 8장에 8장에 283쪽 먼저 보여주시다. 강호 기능이 있습니다.

참석자 1 23:25
8장에 283쪽. 여기 보면 이게 합성으로 신경만 소개하면서 이게 283쪽에 코드 8 1에 옛날에는 여기 댄스 맨날 이 레이어즈 전 댄스 썼잖아요 그쵸 그렇죠 그쵸 여기 보면 이제 레이어즈하고 컴브투디라는 게 새로 나오잖아요.
그쵸 그쵸 보이죠. 여러분 넥스트 플링 투디라는 게 나오고 새로운 걸 배우는 거야.
레이어 중에 베스만 배웠는데 여러분이 댄스 말고 컴브 2D 레스플링 2D 이런 걸 배우는 거지 알겠죠 그리고 2D라고 되어 이제 2D 그럼 2D 말고 1d도 있고 3D도 있고 그렇겠지 맞아요.
진짜로 있어요. 원디도 있고 3D도 있어요. 근데 컨볼루션이 제일 잘 먹히는 데가 2D예요.
2D는 2차원이지 2차원 이미지 가로세로 이미지 가로세로 정보가 있는 거를 잘 살리면서 하는 게 핵심인 거예요.
그 유명한 알파고 있잖아요. 알파고 바둑판 갖고 공부하거든요.
거의 걔도 2D 썼어요. 콤보 2D 이거 똑같이 썼어요.
여러분 진짜 이렇게 된다니까 알파고 2 알겠죠? 그래요.

참석자 1 24:35
그다음에 매스 플링도 컴플 쓰면은 매스 플링이라는 것도 같이 쓰고 이런 식으로 해가지고 결국 마지막에는 댄스로 끝나죠.
그렇죠 결국 근데 콤볼루션 뉴럴 네트워크이라고 해도 댄스 네트워크를 안 쓰는 거 아니에요?
댄스 네트워크 플리커넥트 네트워크 같은 거 그쵸 알죠?
여러분 댄스 리커넥티드 댄스 네트워크 플리 커넥티브 다 같은 말이에요.
그쵸 걔네들은 일단 이름 자체가 벤스트리 컬렉티드 프리커렉티드라고 얘기하는 게 뭐였냐면은 원래 이제 계층이 이렇게 있을 때 여러분 원래 텐서플로우 플레이 브랜드에서 봤듯이 레이어에 뉴런들이 쓴 뉴런들이 전부 다 연결되고 그쵸 벤슬리하게 폴리 연결되고.
그쵸 영어로 공부하면 되게 편하다. 그쵸 폴리컬렉스 돼 있잖아 죠 거기에 다 웨이트가 있었죠 그쵸 클릭 하트 그러면은 굳이 이름을 컴브 2D 이렇게 붙이는 이유를 보면 댄스가 아닌가 보네.
그렇죠 얘는 스파스인 거지. 스파스 사실은 아예 연결도 안 하고 그냥 학습하는 놈이 따로 존재해요.

참석자 1 25:32
그거를 여기 보면은 이 필터라고 적혀 있지. 필터 필터라고 적혀 있죠 여러분 지금 이렇게 이렇게 해봅시다.
한번 설명 필터라는 거가 적혀 있잖아요. 그쵸 필터 필터 그를 32개 쓴다 그랬죠 필터라는 거에만 웨이트가 있는 거예요.
필터가 뭐 거르는 거잖아요. 여러분 뜻이 필터링한다는 정보를 거르는 거죠.
정보를 걸으면 어떻게 되는데 여러분 정보가 줄어요?
늘어요 줄어 그쵸 여러분 저기 제가 중간고사에도 나왔지만 여러분 우리가 딥러닝 머신러닝이 먹히는 이유는 매니폴드 과정을 하고 있다고 그러고 그쵸.
기본적으로 세상에 존재하는 것보다 우리가 뭔가 문제를 풀 때 필요한 정보는 더 많다고 생각해요.
적다고 생각해요. 필요한 정보가 적은 거지. 여러분 지금 내가 이렇게 수업을 하고 하는 이유도 뭐겠어요?
지들이 말로 떼어도 하는 거라고 생각하는 거지.

참석자 1 26:26
사실 정말 세상의 온갖 종류를 다 공부하는 게 아니라 이렇게 내가 추상화시켜서 이론화시켜서 해도 여러분이 더 잘할 거라고 보고 그러는 거 아니야 그쵸 정보가 적은 거잖아요.
여러분 확실히 그렇죠 이게 필터링 하는 것도 여러분 뭐 하는 거예요?
다 추상화시키는 거야 그렇죠. 정보를 줄이는 거예요.
추상화는 여러분 정보를 줄이는 거예요. 그쵸 사과 배보다 여러분 과일 음식 정보가 적지.
사과 사과의 정보는 엄청 많지만 과일 음식 적잖아.
그쵸 과일보다는 식물의 정보가 적지. 근데 왜 그런 걸 자꾸 하는데 카메라 알아서 5만 가지를 다 하려고 하는 거잖아요.
그쵸 필터링한다는 건 뭐예요? 추상화시키려는 거예요.
그렇죠 32가지 관점에서 이거는 32가지 관점에서 필터링을 해서 정보를 추상화시키겠다는 거야.
32가지 관점으로 하겠다는 거지. 그쵸? 이해돼요 여러분 그리고 학습을 하는 건 이 필터밖에 없어요.

참석자 1 27:18
덱스 필터 옛날에는 이 다음 레이어로 넘어갈 때 다음 레이어가 지금 렉스플링 툴이라고 적혀 있는데 여기에 만약에 댄스가 들어있었으면은 여기 정보가 여기 여기 10개 적혀 있는데 이 10개 적혀 있는 거예요.
앞에 있는 거의 피처랑 다 연결돼 가지고 다 웨이트가 있었잖아요.
그쵸? 웨이트 게시 계산하고 가르쳐줬잖아요. 제가 그쵸 여기는 그런 게 아니라 필터에만 웨이트가 있다.
32개의 필터에만 웨이트가 있어요. 근데 이 이 필터의 사이즈를 정하는 게 필요할 거 아니에요 그쵸?
추상화시킬 때 몇 개나 우리가 몇 가지 웨이트를 쓸까 그거를 커널 사이즈 하는 걸로 해요.
커널 사이즈가 적혀 있죠. 필터의 필터 여러분 기본적으로 지금 2D라고 적혀 있으니까 입력이 2D로 원래 입력 데이터가 2D라는 걸 가정하고 있어요.
2D 정보 이미지 사실은 이미지 이미지 아니더라도 뭐든지 2D로 표현된 정보를 가져가고 있어요.

참석자 1 28:18
여기 이 댄스는 입력으로 들어오는 게 몇 가지 몇 디맨전이었어요.
원디였어요 2D였어요. 제로디였어요. 제로디는 스칼라 원디는 벡터 2D는 매트릭스.
그쵸 3D부터 그냥 텐스라고 부르면서 그렇죠 그러고 있죠.
여기 댄스는 여러분 입력이 뭐였어요? 제로 d 1 d 2D 3D 뭐였어요?
배치 빼고 배치 빼고 배치 디멘전 빼고 댄스의 입력은 몇 디멘전이었어요.
너무 빨랐어요. 여러분 천천히 댄스의 입력으로 들어오는 건 여러분 인풋시에입이 어떻게 생겨 먹었나 인풋시에입 할 때 여러분 숫자 몇 개 썼어요?
한 개 여러분 한 개 주입식으로 또 합시다. 그래 해줘.
빨리 가야 저기 예를 들어서 m 리스트 데이터였어 m 리스트 있잖아요.
m 리스트 이미지 그게 20평 곱하기 28이었잖아요.
근데 여기 인풋 쉐임을 댄스였으면은 만약에 이게 바로 첫 번째 레이어가 댄스였어요.
인풋 레이어 빼고 그러면은 이 댄스 인풋 쉐입은 딱 숫자 하나만 썼잖아요.
28 곱하기 28 숫자를 하나라도 만들었었죠.

참석자 1 29:34
원디였어 원디 벤시드는 항상 원디로 들어왔잖아.
헬스 플로우 플레이 그라드도 그렇게 생겼잖아. 원디로 들어오잖아요.
원디로 무조건 굳이 이미지인데 원지로 만들었어.
플래틴 시켜가지고 사실은 플레틴이라는 말은 안 썼지만 우리가 리쉐이 시켜가지고 항상 하나로 만들었어요.
그쵸 벡터로 만들었어요. 그쵸 뭔 말인지 모르면 복습하세요.
여러분 알겠어요. 근데 여기서부터는 이제 이 합성모 신경망은 사실 제목이 이게 8장 제목이 비전이라고 돼 있잖아요.
여러분 비전 기본적으로 우리가 세상을 3D로 바라보고 있는 것 같이 보이지만 사실은 은근히 2D로 보고 있어.
이 그림만 봐도 우리 다 느낌이 오잖아. 원근법이 나와서 막 이랬던 이랬던 거고 동양화는 원근법이 별로 안 돼 있고 그렇죠 무슨 얘긴지 알아요 여러분 사진만 봐도 우리는 되게 느낌이 오잖아.
사실은 우리가 충격 보고 있어.

참석자 1 30:28
사실은 거기 잠자리 같은 애는 막 눈이 많이 달려가지고 주위를 보지만 우리는 딱 한 자리만 보고 있다고 그렇잖아요.
그러면 계속 돌면서 막 이렇게 봐야 돼. 뒤에는 뒤통수 치면 진짜 모르잖아.
그렇죠 여러분 뭔 얘기인지 알아요 2D로 보고 있다고 우리 비전은 우리 2D야 3b가 아니야.
사실은 하늘로 날지도 못하고 그렇죠 여러분 잘 안 돼.
3b는 진짜 x y축밖에 없어요. 우리 맨날 그래프 여러분 x축 y축만 그리는 게 편하잖아요.
우리 3 3차원 그래프 그리면 좀 불편해. 진짜 우리는 여러분 크기가 좋아.
이 그림 그리는 3차원 그림 별로 안 좋아하고요. 그냥 2차원 그림이 좋아.
진짜로 여러분 알겠죠? 지금 별로 동감을 안 하는 것 같아서 동감하지 비전은 2D예요.
알겠죠 그래서 숫자 이미지도 2D지 세트 다는 사실은 다 2D잖아.
그쵸 그래서 비전이라는 건 2D를 기본적으로 의미해야겠죠.

참석자 1 31:20
2D 그래서 여기 여기 이 댄스 네트웍은 원디 데이터를 위한 거고 기본적으로 이 컴블 2D는 2D 데이터를 위한 거예요.
알겠어요? 여러분 이미지 이미지는 기본적으로 2D지 컬러가 들어가면 3D가 되지 하지만 그렇죠 어쨌든 2D야 알겠죠 그려 2D를 위한 거고 댄스는 여기 지금 이게 지금 이게 뉴런의 개수인데 유런의 개수가 이제 10개에다가 입력 개수에 들어온 거에다가 is 1 해가지고 그쵸 곱하기 10개가 다 웨이트가 되는 건데 그쵸 그랬어요.
그렇죠 만약에 입력이 3개였으면 웨이트가 이렇게 생기냐면은 4 곱하기 10이 생기지.
그쵸 향수가 들어오는 걸로 보고 해서 그렇죠 마이너스가 됐으니까 그쵸 그쵸 그랬는데 여러분 중간고사 나왔던 내용이 기말고사에 다 들어가요.
아니 왜 중간고사 모르면 이거 데스 안 쓰는 게 아니야 계속 써요.
여러분 알겠죠? 그래요. 근데 여기 컴프투디 같은 경우에는 이제 필터라는 게 있는데 여기만 웨이트가 있다고 여러분 알겠어요?

참석자 1 32:32
필터가 32개 32개가 나올 것이고 그리고 커널 사이즈가 3위로 돼 있잖아요.
커널이 필터는 사실 이제 필터가 어쨌든 32가지를 우리가 뭔가 만들어 본다는 거잖아요.
정보를 32가지로 뭔가 32개지의 추상화를 시키는 거예요.
근데 터널 사이즈라는 거는 이게 이제 여기서 웨이트의 크기를 정하는 건데 한 필터당 승인 모양이 2D로 가로가 가로 세로 똑같이 3을 쓰겠다는 거예요.
3 곱하기 3짜리 웨이트만 쓰겠다는 거야. 성 곱하기 3짜리 웨이트나 그래서 그거 성 곱하기 3짜리 웨이트를 요 입력에다가 대고 32가지를 쓰겠다는 거지 기본적으로 알겠어요 여러분

참석자 2 33:34
좀 헷갈려서 그런데 그러면 콘스트디의 필터라는 게 댄스에서의 뉴런 같은 역할인

참석자 1 33:40
맞아요. 정확해요. 뉴런이 필터예요. 여기서는 맞아요.
근데 커널이라고 붙이는 거는 그냥 2D에서의 모양을 얘기할 때를 커널이라고 불러요.

참석자 2 33:53
그럼 저 컴퓨트기를 플랫 시키면 댄스로 쓸 수 있는가요?

참석자 1 33:58
컴퓨터 d를 플래팅시키면은 댄스로 쓰는 거냐고

참석자 2 34:02
1차원으로 바꾸면 또 댄스로도 쓸 수 있는

참석자 1 34:05
아니요. 그렇진 않아요. 아예 하는 방식이 달라서 어쨌든 잘 계속 질문하면 좋겠어요.
되게 지금 사실 내가 이거 여기서 알려주고 싶은 거는 그냥 어쨌든 웨이트가 적다라는 걸 알려주고 싶은 거예요.
스파스라고 웨이트가 여기는 그냥 다 달리잖아요.
여기에 연결되는 게 입력이 들어오는 거라 여기는 어쨌든 필터에만 웨이트가 있어요.
알겠죠? 필터 32개 필터의 사이즈를 이렇게 정해버리는 거지 입력 크기랑 아무 상관없어 잘 모르지만 여러분들 근데 이거를 가시적으로 표현하는 교과서에 잘 안 나와요.
거기 보면은 어쨌든 생긴 게 이게 나오기 시작하는데 이것도 너무 이상해 잘못 그려져 있고 해가지고 뭐가 틀렸는지 알려줄게.
나중에 어쨌든 이 틀렸어요. 여기 다 맞을 수 있어 어 그래서 그래가지고 이걸로 할게요.
여러분 CNN은 여러분 CNN이 나오고 나서 사실 획기적으로 좋아진 거예요.
그러니까 CNN이 있기 전에는 리얼리티가 별로 성공적이지 않았어요.

참석자 1 34:56
근데 알파고도 그렇고 옛날에 아타리 게임 하는 거 벽돌 깨기 봤죠 여러분 그것도 되게 신선했잖아요.
전부 다 CNS 인 거예요. CNN이 그만큼 중요하다 알겠죠 거의 비전 쪽에서는 CNN을 계속 써요.
지금도 뭐 아무리 새로운 라파스도 예를 들어서 트랜스포머가 그렇게 유명한데 트랜스포머도 CNN을 써요.
비전에 대해서는 알겠죠. 왜냐면은 왜 그런지 여러분이 이제 느껴야지.
그렇죠 그래요. 갑시다. 그래서 이 교과서 제가 이제 그래서 여기 보면은 여기 보면은 CNN 오버에서 커널 필터 막 적혀 있잖아요.
그쵸 대충 설명했는데 어쨌든 필터가 메이트라고 그쵸 보면은 원래 이미지가 이런 게 있는데 여기 보아요.
여기 왼쪽 이미지가 있어요. 그쵸? 흑백 이미지인데 흑백 이미지를 쓰면 좋은 게 여러분 일단 원디잖아.

참석자 1 35:45
아니 원디가 아니라 뎁스가 없으니까 그냥 이거 완전히 그냥 2이죠.
그렇죠 이거는 여기 색깔이 들어가기 시작하면 3D잖아.
그렇죠 지금 일단 이해하기 쉬워서 흑백 이미지로 한 거예요.
여러분 알겠죠? 얘를 추상화를 이렇게 시킬 수도 있잖아요.
여러분 정보가 많이 사라졌죠 이거 어떻게 돼요? 엣지만 사라져 있죠 그쵸?
엣지만 엣지 여러 엣지 그냥 테두리만 보이잖아. 그렇죠 여러분 근데 이거 여러분 이거 정보가 훨씬 많지만 이것만 봐도 여러분 이게 뭐가 있는지 알겠지 이해돼요.
여러분 정보가 훨씬 줄었는데 추상화시켰는데 뭔가 느낌이 오잖아.
그쵸 나무라는 거 알잖아 나무고 이거 다 알아봐요.
못 알아봐 알아보잖아 그쵸 이런 거를 만들고 싶은 거예요.
우리가 학습할 때 이해돼요. 여러분 근데 이거를 대수로 하면 어떻게 돼 이거 다 펼쳐가지고 쫙 연결해 버리니까 정보가 사라지니까 별로잖아요.
진짜 당연히 학습할 때도 이렇게만 여러분 줘도 이건 아무 뭔가 알아보잖아요.

참석자 1 36:38
그쵸 그래서 이렇게 이런 식으로 여러 개로 이게 이거 필터 하나 쓰면 이렇게 나온다는 거예요.
여러분 실제로 이미지를 만들 때 어떻게 만들면 되냐면은 원래 이미지가 여기서는 지금 사이즈가 이렇게 다르지만 예를 들어서 이미지가 이렇게 예를 들어서 그냥 심플하게 0 1 이렇게 보면 사실 무슨 화살표 같이 보이죠.
여러분 1만 일이 만약에 있으면 이렇게 생긴 거죠.
그치 이미지가 뭐 어쨌든 이런 이미지가 있는데 그쵸?
0 1 이렇게 있는데 이거 인풋 피처가 이제 인풋 피처가 원래 인풋을 말해요.
여러분 알겠죠? 근데 여기에 커너를 터널이라는 게 아까 제가 터널이 필터가 여러 개 커널이 샷이 필터의 일부예요.
여러분 일단은 그렇게 알아보세요. 여러분 그러니까 커널 사이즈가 아까 있었잖아요.
그쵸? 커널 사이즈가 필터의 가로크 세로 모양을 정해 준다고 그랬잖아요.
그래서 얘가 지금 커널이 결국 필터가 될 거예요. 알겠죠?
터널이 필터예요. 결국은 나중에 필터가 여기서는 같아요.

참석자 1 37:45
나중에 만약에 인풋이 3D 여기 만약에 이제 3D 이미지거나 아니면 인풋이 좀 뎁스가 있으면 터미널 필터가 다른데 터널이 여러 개 보여서 필터가 돼요.
괜히 헷갈리나 이거 참 설명 많이 해서 미리 설명해 줄까?
필터는 이거예요. 이거

참석자 1 38:08
여기 지금 인풋이 만약에 칼라야 세장이잖아요. 칼라는 세 장인 거 알지b인 거 알죠?
여러분 그쵸? 여기 한 장의 커널이고 여러 개 세 개가 합쳐진 그러면 이게 하나하나하나 따로따로따로 뭔가 대응하고 싶어서 그 뎁수를 늘리거든요.
그리고 필터라 불러요. 원래 커널은 2D인데 2D 커널은 2D 짜리 필터는 3D 짜리 뎁스 인풋 피처의 뎁스에 맞춰서 늘린 거를 필터라고 불러요.
일단 그렇게 알고 있어 보셔 알겠죠? 괜찮아요 네 그럼 흑백 이미지 같은 거 있을 거예요.
터널이랑 피터랑 같다고 너랑 똑같다고 이거 먼저 이것도 딴 것도 있어 여기는 여기 인풋쉐이 내가 원대만 교수 설명하기 쉬운 거 다 갖다 긁어 가지고 여기 인풋이 지금 RGB 3량 있잖아요.
커널을 이렇게 커너 요가 왜 하나 커널이 3개 있는 거야 커널이 3개야 이게 전부 다 하나가 필터 하나 필터 이해돼요 여러분 r에 대한 커널 지에 대한 커널, b에 대한 커널에서 합쳐서 필터라고 부른다고 한 필터 3개의 커널 알겠어요?

참석자 1 39:22
여러분 또 또 보여줄까? 여기 또 있다. 여기 RGB 있는데 r에 대한 퍼널 지에 대한 퍼널, b에 대한 커널 이 세 개 다 합쳐서 한 필터 오케이 여러분 괜찮아요.
누르기로 했다고 어차피 필터링하는 건데 결국은 커퍼레이션 연산은 커너 단위로 하고요.
한 플레이 하기 때문에 그래서 그거를 터널이라고 부른다는 거죠.
터널은 1 2 d 필터는 3D 오케이 여러분 괜찮아요.
그래 이렇게 가봅시다. 그래서 그렇게 사람들이 용어를 쓰긴 해서 일단 여기서 지금 원디니까 커널로 봅시다.
알겠죠? 커널 불러도 되고 컴퓨터를 불러도 돼. 알겠어요 여러분 어쨌든 컨볼루션 연산하는 거는 기본적으로 컴플레이션 원산은 물론 모르지만 커널이라는 걸로 한다는 건데 별게 아니고 전에 사실 여러분 리니어 리그레션 맨날 결국은 다 리니어라고 그랬잖아요.
제가 리니어 리그레션 리니어 펑션 액티베이션을 통과시키는 거가 핵심이라고 그랬잖아요.
그래서 여기도 똑같아요. 맨날 리뉴얼의 핵심이 뭐였어요?

참석자 1 40:28
여러분 곱하고 더하기지 여기도 곱하고 더하기 하는 거예요.
커널도 똑같이 곱하고 더하면 돼요. 코널의 모양은 예를 들어서 이런 모양 만들었을 때 여러분 101 010 101 보이죠 이런 모양을 여기다가 여기 이렇게 추상화시키고 싶은 거야 이런 걸로 세상을 바라보겠다는 거예요.
이미지를 이걸 여기다가 곱해 곱하고 더하려면 모양이 안 맞으면 모양 맞춰서 더한다는 거예요.
사실은 그래서 이게 이게 시작 여기서 잠깐만요. 시작 여기서부터 쫙 곱하고 곱하고 곱하기해서 하나씩 하나씩 만들어서 여기다 더 하는 거예요.
이해돼요 여러분 봐봐요. 지금 뭐 하고 있냐면은 101 010 101 보이죠.
똑같이 이거 이거를 하나씩 딱 여기 다 그냥 대응해야 되는 걸 곱한다고 그래서 여기다 짝 쓰고 쓰고 쓰고 쓰고 있어요.
느낌이 와요. 여러분 느낌이 와요. 여러분 지금 이거 동영상 안 되잖아요.
여러분 제가 PDF로 줘서 여기 들어가면은 긁어가지고 PDF 긁어지거든요.
동영상 볼 수 있어요.

참석자 1 41:28
알겠죠 GIF 알겠죠 근데 뭐 안 봐도 별로 문제없죠.
여러분 어쨌든 핵심이 뭐냐면은 원래 우리가 웨이트를 곱해서 더 했잖아.
맨날 리뉴얼 리그레션이 얘도 똑같아. 그리고 이렇게 한 다음에 액티베이션 통상 통과시키겠어요 안 통과시키겠어요 통과시키겠지 똑같지 왜냐면은 결국은 난민 인연성이 있어야지 우리가 뭔가 잘라낼 수가 있잖아요.
난민이요 왜 하는데 잘라내려고 하는 거잖아요. 필요 없는 거는 키 여놓고 계속 증가하지 않잖아.
어느 정도 나이가 들면은 나이에 따라서 키를 예측하려고 그러면 20살 넘으면 안 자라잖아요.
그쵸 난니니얼 펑션 있어야 돼. 그렇죠 렐루 같은 거 쓰는 거잖아요.
그쵸 폭 자라 보이려고 그쵸 시그 모이드는 필요 없다.
왜냐하면 시그모이드는 양쪽 다 잘라버리는데 루가 한 번만 잘라버리니까 좋잖아요.
그쵸 렐루 쓰는 거지 다 지금 어쨌든 그래서 이 컨볼루션이라고 이름을 붙였는데 사실은 컨볼루션이 아니고요.
컨볼루션은 우리 알잖아요.

참석자 1 42:24
타딩 디맨던에 대해서 원래 신호 시스템 다 들었죠 여러분 다 들었잖아.
수용 시스템에서 하는 거는 원래 타인 디전 뒤집어서 실패 시켜가지고 하는 건데 그거 아니잖아요.
근데 좀 멋있어 보이려고 이름 붙인 거예요. 진짜로 전혀 아니야 전혀 컨볼루션 아니에요.
이거 아니라는 거 유명해요. 근데 컨볼루션 하면 좀 멋있어 보이니까 시노미 시스템에서 유명한 거라 이름 붙인 거지 그냥 이것도 리뉴얼 이그레이션 똑같은 거예요.
알겠어요 여러분 이름이 잘못됐다는 건 유명한 사실이에요.
여러분 알겠죠? 근데 CNN이라 불러서 이미 고정된 거니까 또 가는 거예요.
알겠죠? 그린디에도 사람들이 이제 부르면 이거 이거 컨볼루션은 여기서 용어는 다르다 이렇게 하는 거지 아그니까 일부러 그런다니까 여러분 일부러 똑같은 용어 쓰면서 사람들이 눈길을 끌려고 한다고 그래요.
그래서 커널이라는 것도 여러분 이 커널 커널 이거 우연 체제 커널인데 이런 거 다 가져왔어요.

참석자 1 43:16
이 사람들 이거 커널이 또 나중에 GPU 가면 또 커널이 거기도 다 다른 커널이야.
CD의 커널 GPU의 커널 운영 체제 커널 정말로 여러분 어텐션이 필요하지?
이게 어디 도대체 어떤 맥락인지 필요해 그렇죠 여러분 알아먹어야 돼.
알겠죠? PC도 여러분 프로그램 카운터 퍼스널 컴퓨터 알아서 먹어야 돼.
그쵸? 맥락에 따라서 그렇죠 킹 받는다 킹이시어 그쵸 다른 거지 그쵸 그렇죠 여러분 알겠죠?
밥맛이다. 맛있는 밥 다른 거죠. 그쵸 그렇죠 여러분 이게 뭔 말 이해하죠?
그렇죠 이 커널은 그 커널이 아니고 이 컨버레이션은 그 컨버레이션이 아니어요.
그쵸 알겠어요 여러분 그래요. 어쨌든 뭔지 알아먹었어요.
이제 여러분 이 컨플레이션이라는 거는 정확히 그냥 리뉴얼 리그레션이다.
알겠죠? 근데 리뉴얼하고 하는데 2D로 바꿔버렸어요.
그쵸 모양 유지가 돼. 리뉴얼은 트릿하게 하는 거였잖아요.
여러분 댄스가 블리니어리 그레신이었잖아요.

참석자 1 44:10
그때 얘는 리뉴얼을 아니라고 하고 싶은 거지 뜻이니까 이지이 되잖아요.
여러분 모양이 이게 보면은 모양을 그대로 유지하면서 이렇게 가잖아요.
그쵸 그래서 여기서 특성 뽑아내고 이게 보면은 위치 정보 그대로 유지되는지 여기 있는 거를 추상화시켜서 여기다 갖다 놓고 그렇죠 이만큼 추상화해서 여기다 갖다 놓고 그렇죠 그 위치 정보가 그대로 유지되기 때문에 그렇죠 정보가 위치 정보가 안 사라지는 추세가 되잖아요.
보면 이게 이걸 여러분 리니이 글씨를 쓰면 어떻게 되겠어요?
이게 옆으로 쫙 나올 거 아니야 근데 지금 이렇게 했으니까 이렇게 예쁘게 나오고 우리가 알아볼게 나오잖아요.
이해되죠? 여러분 이걸 컨볼루션이라고 부른다고요 됐어요 됐지 그래요.
그리고 용어를 봅시다. 여러분 그래서 이거를 이렇게 리얼 웨이트 애들을 이렇게 2D로 만들어 놓은 거 있잖아요.
이에 레션처럼 웨이트 투지를 만들어놓은 거를 퍼널이라고 불러요.
알겠죠?

참석자 1 45:04
그리고 이렇게 웨이트 터널을 원래 이제 입력 피처에다가 적용해가지고 나온 결과 있죠.
결과를 컴벌브드 피처라고 불러요. 적용하는 걸 컨볼루션이라고 부르고 알겠죠.
그리고 요거를 컴블루드 피처 그러니까 이건 여러분이 상식적으로 컨볼루션 하는 건데 컴벌브 결과가 나왔으니까 컴벌브드 피처라고 할 수 있겠지.
그쵸 이해되죠? 불러요. 그런데 이거를 다른 말로 피처 맵이라고도 불러요.
피처 맵이라는 거는 여러분 이게 맵이 기본적으로 뭔가 농구 매핑시켜 나온 거잖아요.
그쵸 사상시켜서 그러니까 이거를 그냥 피처 랩이라 부른다고 알겠죠.
컴버모드 피처 피처랑 같은 말. 그리고 이게 컨볼루셔널 레이어에 속해요.
컨볼루셔널 레이어라는 게 원래 우리가 레이어가 이 레이어 가서 교과서에 지금 나온 여기 컴브 2D 컴브투디 이렇게 있잖아요.
요거 요게 컨볼루셔널 레이어겠죠. 요게 댄스 레이어인 것처럼 그쵸 근데 제가 여기 속한다고 했잖아요.

참석자 1 46:19
속한다고 그랬지 속한다고 한 거는 보통 이렇게 커널을 하나만 쓰는 게 아니라 커널이 결국 피타가 된 된다 그랬죠 여러분 그쵸 필터를 하나만 쓰는 게 아니라 아까 필터 몇 개씩 썼는지 봤죠?
여러분 아까 몇 개 썼어요? 32개 기본이었죠? 그쵸?
32개씩 쓰기 때문에 컨볼루션 레이어는 보통 피처에 32개씩 필터별 개수별로 만들어지거든요.
이해돼요. 여러분 필터를 서로 2개 추상화를 이렇게 한 가지만 하는 게 아니라 여러 가지로 한다고 이렇게 액자 뽑아내기도 하고 질러 뽑아내기도 하고 좀 보여줄까 미리 필터를 이 코너링 예를 들어서 이거 이런 요 7페이지 볼래요 여러분 미리 보여줄게요.
이게 원래 이미지가 이렇게 생겼어요. 그러면은 이제 컨을 이 세 가지 쓰는 거야.
예를 들어서 이 표들 3개 때야 그러면 하나 둘 세 개가 결과가 나오잖아요.
이게 이게 모여서 컨볼루셔널 레이어라고 부른다고 필터가 여기는 필터가 3개인 거지 요 커널이 사실은 3개가 있는 거예요.

참석자 1 47:20
3개가 있는 게 3개가 있는데 커널 하나가 필터 하나가 되고 사실은 이게 지금 이렇게 칼라죠 칼라잖아 칼라면은 사실 이게 코널이 사실 세 잔씩 필요하겠지 또 그렇죠 그래서 한 필터가 되고 그래서 이게 나온다고 이해돼요.
여러분 여기서 사실은 세상이 나와 이거 하나로 그려놨지만 세 끼씩 나온다고요.
알겠어요 여러분 RGB 별로 알겠어요 여러분 이거 사실 이거는 정확히 말하면 얘를 흑백으로 만든 상태에서 하면 맞는다고 이 알겠죠 여기 이렇게 여기 나왔잖아요.
벌써 지금 세 장이 겹쳐야 이렇게 나온다고요. 여기 RTV가 있어야 이 그림이 나오잖아요.
여러분 여러분 원디맨전으로 만약에 칼라를 이렇게 표현할 수 있는 기술을 만든다.
여러분이 그러면 여러분 떼돈을 벌 수 있어 RGB 밖에 안 돼 아직은 왜 근데 RGB가 좋은 게 여러분 생으로 벌어봤자 별로 소리가 없는 게 실제로 여러분 지금 이 모니터고 뭐고 다 RGB로 표현해가고 쏘거든요.

참석자 1 48:15
여기 이 액적 있잖아 액적 액적 이거 다 RGB 동시에 켜가지고 하는 거예요.
여러분 알아요. 그러니까 뭐 RGB가 낫지 뭐 그렇지 그렇죠 모니터 킬 때도 그러고 아몰레드도 그러나 어쨌든 세상이 변하지 않는 한 계속 알지리는 유지된다는 거지.
그래서 이게 커널 용어 필터 용어 따로 필요해요. 알겠죠 커널이 여러 플랜드는 이해되죠 여러분 그리고 보면은 이 필터는 엣지 디텍션하는 거 필터라는 느낌이 더 잘 와닿죠.
필터링해서 엣지만 디텍션하고 얘는 뭔가 샤프닝만 하고 얘는 블러링만 하고 이런다는 거지 특성을 다양하게 잡아낸다는 거예요.
알겠어요 여러분 근데 이게 사실 여러분 50분이구나 10분 쉬었다가 할게요.
여러분 10분 쉬었다가.


clovanote.naver.com

딥러닝 15_2
2025.05.07 수 오전 11:01 ・ 49분 14초
심승환


참석자 1 00:00
필터 싸우기 필터라고 이거 하나하나 터널 세 개 다 합치면 필터 그렇게 부른다고요.
그래서 여기 다시 얘기하면 무슨 얘기냐면 API에서 지금 질문하고 대답하고 있어요.
여러분 여기 어디 갔어? 여기 강의 자료 여기 보면은 이게 필터가 32개라고 돼 있잖아요.
32개가 아까 그 3D짜리가 3개 32개 있는 거고 코너 사이즈가 3이라는 거는 사실 가로세로 같은 경우를 의미하거든요.
이게 사실 3은 이거랑 뭐가 똑같냐면은 3 콤마 3 이렇게 적는 거랑 똑같아요.
원래 2D로 줘야 돼. 원래는 코너 사이즈를 원래는 td 커플로 줘야 된다는 거야.
td td에 2개 2개 아니고 그냥요. 벡터로 원래 2 두 개의 숫자 2개 줘야 돼요.
가로세로 커널이 이제 이렇게 아까 봤잖아 곱하는 거 그쵸?
가로세로 필요하잖아요. 가로 세로 원래 이렇게 줘야 되는데 3 곱하기 3 이렇게 쓰는 게 귀찮으니까 그냥 하나만 쓰면은 그냥 가로세로 똑같다고 본다고요.

참석자 1 01:06
그리고 사실 그래서 여기 32개인데 이 지금 쉐입이 28부터 28 하필이면 이제 1위죠.
1위 이거는 지금 이거 엠리스트인가 보네. 그쵸?
엠리스트 흑백 이미지 흑백 이미지 흑백 이미지면은 이거는 필터랑 커널이랑 사이즈가 사실상 똑같죠.
어쨌든 사드 하나 더 있지 32개가 하나가 각각이 3급 여기 앞에 뎁스가 있어 3급 이렇게 생긴 거지 2 3 4 이런 게 32개가 있는 거지 이해돼요.
뎁스가 여기 맨 앞에 있어요. 지금 맨 앞에 있다 치면 이거 뒤로 갈 수도 있는 거고 알겠어요.
만약에 여기가 3D야 여기가 만약에 3D래 여기 e2d 만약에 RGB야 그러면 3이 되잖아요.
그럼 여기가 3으로 바뀌고 그만큼 코너를 뻥튀기 시켜서 데스만큼 뻥튀기 시켜서 써야 된다고요.
필터는 근데 여기도 좀 헷갈릴 만한 게 내가 이렇게 강의 자꾸 하면은 필터를 필터 어디가 되지?
여기에서 제가 필터가 이렇게 이거 얘는 이렇게 생긴 필터는 이렇게 액자 뽑아내지 이런 거 하잖아요.

참석자 1 02:21
그쵸 생긴 게 사실 이게 좀 약간 뭔가 1년 1년 바뀌니까 바뀌는 부분만 뽑아내는 거잖아요.
바뀌는 부분만 뽑아내고 있어요. 진짜로 이렇게 생긴 모양이 우리가 직관적으로 또 알 수 있어요.
커너 생긴 모양이 여기 보면은 이게 여기 가운데만 크죠.
가운데만 큰 것도 쯤 이 가운데 여기 나머지는 제가 확 죽여버리잖아요.
그러니까 가운 날 뽑아내서 이제 액지 패션이라고 돼 있지만 어쨌든 이렇게 나온다는 진짜로 이렇게 하면 얘는 어때요?
여러분 여기 가운데 크고 바로 옆에는 또 작다가 또 옆에는 또 약간 그 중간으로 되잖아요.
이런 거는 샤프닝을 하고 더 날카롭게 만들고 굉장히 강조시키는 거지.
그리고 얘는 9분의 1을 곱해놨잖아요. 9분의 1 숫자는 틀리잖아요.
되게 뭉뚱그려져서 블러링이 되고 이런 식이에요.

참석자 1 03:09
그런데 이거가 이게 커널이 이렇게 숫자가 정해 여기 지금 웨이트라고 그랬잖아요.
내가 웨이트 맞죠? 근데 이거 학습의 대상이잖아요.
이게 처음에는 이렇게 디폴트로 줬다가 나중에는 이게 학습이 돼서 바뀌어요.
실제로 문제에 맞춰서 학습이 돼서 뭐냐면 사실 이것도 미리 여러분이 좀 아는 것에서 얘기해 주면은 하도 CN는 오래됐으니까 이게 이게 컴퍼레이션 커 유니티 원래는 아까처럼 이렇게 여러 가지 생겼다가 나중에 하다 보면 이런 게 나와요.
나중에 이렇게 일으키는 게 이게 뭐예요? 여러분 눈이잖아요.
그러면 얘를 똑같은 걸 찾으면 거의 배가 커지는 거예요.
숫자가 이런 건 다 안 맞으니까 나오다가 여기 100이 된다고 요 위치에 눈이 있다는 걸 알게 된다고 그러니까 이게 커널 있죠 커널이 하는 일이 뭐냐면 사실은 자기랑 비슷하게 생긴 놈만 뽑아내는 거예요.

참석자 1 03:56
자기랑 비슷한 놈을 어디 있는지 알려주는 거라고 나중에 이 위치에 눈이 있으면 이건 얼굴이기만 하고 안다고 그게 사람 만약에 얼굴 디텍션 한 거라고 그러면은 눈이 있느냐 없느냐 이게 시작하는 게 중요한 그런 뭔가 문제라면 여기 나중에 벤스 네트워크 통과 할 때 이게 또 값이 커지게 나오는 거죠.
그런 식으로 하는 거예요. 그러니까 지금 여러분이 다시 얘기하고 싶은 거는 커널이라는 거가 원래 디폴트 값으로 되게 유명한 걸 주고 나 30이 아까 했잖아요.
필터를 32 초기화를 어떻게 하냐 유명한 것들로 한다고요.
아까 샤 분위기 이런 것들로 나중에 학습이 돼가지고 여러 레인을 거치고 나면은 처음에는 이제 초반 여러 회의를 거치니까 초반부에 눈이라는 건 잘 안 보이는데 원래 이제 전체 이미지가 막 있을 거 아니에요 근데 어떤 데는 이제 이것만 여기 이 부분만 가져오고 여기는 다른 데는 다 있을 거 아니에요?

참석자 1 04:47
여기에 이제 나중에 눈이 있는 치아에서 나중에 상위 레이어의 필터는 이런 식으로 학습이 된다고 눈이 있다는 것을 알게 된다고 여기 보면은 여러분이 좀 안 하는 것 같으니까 계속 질문하는 거 보니까 여기 여기 있네 여기 잘 되는 거야.
여기 보면은 이렇게 맨 처음에 컨버레이션 필터들이 이렇게 생겼는데 거의 뭔지도 모르게 가로가 있니 세로가 있니 막 이러다가 그다음 필터는 약간 좀 뭔가 동그라미를 알아내고 막 이런 식으로 한다고요.
마지막에 가서는 이 바퀴가 있니 없니 막 이런 식으로 바퀴가 여기도 있구만 이런 것도 있구먼 이러면서 알아낸다는 거죠.
이거 이것도 재밌는 게 교과서도 다시 한 번 보여줄까 교과서도 필터가 여러분 전체가 학습 대상이라는 걸 알리고 싶어서 8장에

참석자 1 05:40
8장에 8장에 보면 이거 이거 이거 볼까 이거 요거 이게 8장에 이게 127쪽에 있는 건데 이게 인프 피천인데 인프 피처가 고양이 이미지예요.
그쵸 근데 이 중간에 있는 필터들 있잖아 이거 몇 개 몇 개인가 하나 둘 셋 넷 하나 둘 8 9개 9개 이 9개들은 얘는 얘 얘만 찾아내고 얘는 얘만 찾아내고 얘만 찾아내고 이렇게 한다고요.
이렇게 해서 이렇게 필터가 변한다고 이해돼요. 나중에 학습시키다 보면은 이렇게 변한다고 필터들이 그러다가 사실 맨 처음에는 이 정도 아니고 굉장히 별거 아닌 것 시켰다가 나중에는 이제 점점 추상화시켜서 이렇게 되고 마지막 판에는 이런 게 생긴다고 그런 거예요.
나중에 고양이 정말 자체가 되는 문제라고 학습을 시키면 이런 거 이거 이게 고양이 결정적으로 고양이를 알아내려면 이런 게 있어야 되네.

참석자 1 06:29
눈인데 이렇게 눈이 고양이는 여러분 눈이 이렇게 진짜 고양이들의 핵심은 이거죠.
여러분 여우가 고양이 이런 애들은 눈이 이렇게 생겼잖아 그쵸?
호랑이나 이런 애들은 걔는 이렇게 안 생겼어 걔는 어떻게 생겼어요?
여러분 문이 이렇게 막 걔는 이렇잖아. 걔는 눈동자가 엄청 동그랗게 커요.
진짜 무서워 그래서 약간 약간 뭘 무슨 여러분 알잖아요.
흰 자가 없어 얘 흰자 투성이야 그쵸 아니 이런 거를 여러분 고양이 눈인 사람들 있잖아요.
여러분 방탄소년단 b 이 사람 무서워 약간 이 흰자만 아 그렇죠 그렇잖아.
근데 또 보면은 어떻게 아이돌 중에 나 좀 예쁜 사람 중에 막 이렇게 거의 어은 자 혼자가 없어 그렇죠 개같이 보이지 그렇죠 진짜 그러겠지 근데 무슨 얘기냐면 이기려고 하는 얘기고 어쨌든 여러분 무슨 얘기냐면은 이게 고양인지 알려고 그러면 이걸 학습시켜야 되고 개인지 알려면 이걸 학습시켜야 돼.
그쵸 필터가 변한다고 알겠죠 여러분 그래요.

참석자 1 07:17
그래서 이게 처음에는 막 이렇게 디폴트로 있다가 그리고 이제 각 계층별로 이렇게 뭔가 구체적인 걸 알아내는 게 맨 마지막에 나타나고 구체적인 거는 좀 멀리서 바라봤을 때잖아.
사실은 왜냐하면 이게 이게 하다 보면은 요렇게 요렇게 이렇게 필터링하고 있잖아요.
그러다가 나중에 사실은 미리 얘기해 주면 여러분 여러분 우리가 가까이서 바라보면 내가 맨날 여러분한테 공부할 때 사실 대학원이나 이런 연구나 이런 쪽이 되게 중요한데 그런 논문도 그렇고 좀 나무만 보면 안 되고 여러분 뭘 봐야 돼요 숲을 봐야 되잖아.
그쵸 나만 보고 막 이러고 있으면 여러분 제가 안 보인다고 공부할 때도 제가 어떻게 하랬어요?
미니 배추 하라 그러면서 막 그러면 뭐예요 그게 다 차례 좀 말라고 그렇죠 차례 교과서 차리지 말라고 컴퓨터 구조에 예를 들어서 캐시라는 챕터가 있잖아.
그쵸 우연 챕터가 아니야. 그쵸 캐시는 우연 체리가 하는 게 아니라 하드웨어가 하는 거야.

참석자 1 08:04
그치 캐시 관리는 그런 거 있죠 그거를 알려고 막 그러잖아요.
캐시가 이렇게 되는지 지는 게 중요 아니라 캐시가 오 차트에 들어있다.
컴퓨트 우자였다 이런 게 중요하잖아요. 그러니까 이런 눈을 봐야지.
요요요 요요 바라보고 있으면 되겠어요. 그렇죠 안 되잖아요.
그쵸 그래서 이게 뭐 하는 짓이냐면은 멀리서 바라봐야 돼서 뭐 해야 되냐 정보를 줄여야 돼.
자꾸 스프 보려면 정보를 줄여야 된다는 거 여러분 알아요.
여러분 정보가 너무 많으면 안 돼. 정보를 줄여야 돼.
간결하게. 그렇죠 추상화시켜야 돼. 추상화를 잘해야지.
그쵸 추상화 잘하게 이거 학습시키는 거예요. 알겠어요 여러분 근데 그리고 그럼 멀리서 봐야 되니까 어떻게 돼야 돼요 이미지를 자꾸 어떻게 해야 돼 줄여야 돼.
추상화시켜야 돼. 그러면 어떻게 해야 돼 썸네일이 좋은 거지 썸네일이 이거를 이미지를 썸네일로 쫙 보면서 하는 편하잖아요.

참석자 1 08:51
여러분 한꺼번에 그래서 어떻게 되냐면은 여기 사실은 교과서에 중간중간마다 계속 이렇게 맥스 풀링 2D를 해버리거든요.
여러분 넥스트 플링이라는 거 이게 정보를 줄이는 거예요.
사실 이미지를 줄여 아까 원래 컨버레이션만 해도 이미지 줄어드는 거 봤죠?
맞나요? 여러분이 원래 아까 이게 한꺼번에 안 나오네.
여기 이것만 해도 지금 이미지가 이렇게 컸다 이렇게 줄어들었죠.
근데 사실은 옛날에 이렇게 하다가 이게 잘 안 된다는 거 알았어요.
이미지 정보가 자꾸 사라지는 게 안 좋아서 그냥 이미지 자체를 유지하기 위해서 나중에 캐릭이라는 걸 해가지고 원래 사이즈를 유지하게 만들고 이런 식으로 하다가 결국은 아까 중간에 패딩 들어 있는 거 봤잖아요.
여러분 스프린트 2D 여기 미리 그냥 한꺼번에 또 톱 다운으로 합시다.
여기도 보면은 굳이 중간에 이렇게 맥스 플릭 맥스 클린이 들어 있잖아요.

참석자 1 09:48
그쵸 이게 뭐 하는 거냐면은 이미지를 추상화시켜버리는 거예요.
작게 만드는 거예요. 왜냐면은 숲을 보게 만들려고 멀리서 바라봐야지 보이잖아요.
여러분 여기 계속 이렇게 가까이 들여다보고 있으면 안 보이잖아 멀리서 봐야지 뭔가 여러분 그런 거 있잖아요.
저기 항공 왜 저기 항공우주 항공 사진으로만 보이는 VR 모양 있고 그런 거 있잖아요.
무서운 거 아 옛날 여러분 뭔가 나는 그때 한때 되게 유행했는데 이거 외계인이 했나 이러면서 막 그 옥수수 밭에다가 모양 만들어놓고 이런 거 있지 사실 알고 보니까 사람이 한 거더라고 어쨌든 진짜 거기 사는 사람들 모르는데 항공 사진 드론 띄워보니까 막 갑자기 모양이 막 유유 다임 이런 거 적혀 있다는 거지.
그렇죠 여러분 그렇죠 근데 그게 그래서 가까이서만 안 보이고 멀리서만 보이는 거 있잖아요.
그런 게 많아요.

참석자 1 10:37
세상에 그쵸 그래서 이게 이미지도 여러분 이게 가까이서 보면 안 보이고 멀리서 이거를 계속 아까 그렇게 터널 사이즈 3 곱하기 3 같은 것만 하면 이게 안 보이잖아요.
그쵸 이게 이게 고양이인지 이것만 보고 고양이인지 알겠어요 지 그 고양이인지 모르잖아요.
그쵸 그래서 이런 걸 보려고 그러면 좀 멀리서 봐야 된다고 이거 이것만 딱 보는 게 생겨야 되잖아요.
그쵸 이걸 더 작게 잘라서 보는 게 아니라 그래서 이미지 사이즈를 줄여야 돼요.
멀리서 보기 추색 축약시켜서 그래서 매스플링하는 게 무슨 뭐 하는 거냐면 여러분 정말 별 게 아니고 미리 추상화에 대해 중요성을 보여주면은 여기 강의 자료에 다 있는데 교과서에 또 그림이 안 나와서 이게 더 좋은 것 같아.
왜냐면 여기 보면 매스쿨링이 원래 이제 이미지가 이렇게 생겼는데 여기서 제일 큰 숫자 터 제일 큰 숫자 터 이해되죠 제일 큰 정보만 갖고 오는 거예요.
원래 이미지 스릴 때 이렇게 하는 게 맞아요.

참석자 1 11:36
그래서 예를 들어서 맥스플링 한 거 보여주면은 이게 이걸 맥스플링하면은 이 그림이 이게 이게 넥스트 플링 한 게 이 그림이에요.
아까 여기서 이렇게 이렇게 아까 봤잖아요. 이렇게 이렇게 하면서 제일 큰 숫자만 뽑아내는 거 그러면 이렇게 이거 알아보겠죠.
여러분 이거 말고 이걸로도 알아보잖아 이해돼요.
이거 이 그림 말고 이렇게 작은 그림으로도 여러분들 충분히 알아보잖아.
오히려 더 잘 알아볼 수 있어요. 아까 얘기했듯이 가까이서 보면 안 보이는 게 멀리서 보면 보이는 거 있잖아요.
그쵸 이 멀리서 보는 거랑 똑같다는 거 느껴져요. 여러분 작게 보는 게 한꺼번에 정보를 보잖아.
한꺼번에 멀리서 보지 않으면 안 보이는 게 많다고요.
여러분 짧게 만들지 않으면 안 보이는 게 있어요. 그러니까 정보를 그냥 한꺼번에 볼 수 있기 때문에 그런 거죠.

참석자 1 12:30
여러분 만약에 필터링을 아까 연산할 때 곱하기 옆에 연산할 때 요렇게 요렇게 요렇게 이렇게 되고 하면은 제대로 안 나오는데 이렇게 되고 하면은 나오기 시작한다는 거지 이제 어차피 필터 크기는 한정이 되니까 이해되죠.
여러분 우리가 보는 시야는 한정이 돼 있잖아요. 여러분 그래서 옥수수 밭에 있는 글씨를 볼 수가 없다고 옥수수 밭으로 쓴 글씨 그 영화도 하나 있었는데 제가 까먹였네.
뭔 얘기인지 알겠죠? 여러분 달 분화구는 우리만 볼 수 있지.
달에 있는 사람 사는 생명체가 있는데 못 볼 거야 이해돼요 여러분 이해되지 그쵸?

참석자 1 13:08
됐죠 여러분 그래서 어쨌든 추상화를 시키는 게 필요하고 그래서 필터링을 해서 맥스플링 투디라는 것도 필요하다.
일단 그렇게 하고 진도를 계속 나가면 될 것 같아요.
그래서 일단은 여러분이 일단 지금 제 외웁시다. 여기에 이렇게 원래 이미 인도 피처가 있는데 이 터널이라는 거를 그래서 왼쪽에서 오른쪽으로 그다음에 왼쪽에서 오른쪽으로 위에서 아래로 이렇게 내려가면서 다시 곱해가지고 정보를 위치 정보를 유지하면서 그렇죠 위치 정보 그대로 유지되죠.
그쵸 그러면서 추상화시켰죠. 그쵸 이러는 거를 컨볼루션이라고 불러요.
사실은 그냥 메이트 곱하는 것뿐이지만 이렇게 2D를 유지하면서 이렇게 모양이 유지되면서 하는 거를 콤블루션이라고 불러요.
알겠죠? 그래요. 그리고 이렇게 나온 결과물은 루션 컴벌브드 피처 또는 피처 맵 또는 컨볼루셔널 이런 것들이 모이는 컴플레이션 레이어 이렇게 부른다는 거예요.
알겠죠 그래요.

참석자 1 14:13
그래서 그런데 이거를 사실 정보가 이렇게 사라지는데 이러면은 가에 있는 특성들 있잖아요.
가에 있는 거는 보면은 이게 에서 이렇게 하고 이렇게 하고 이렇게 하잖아요.
여러분 또 이렇게 하고 이렇게 하잖아요. 이러면 얘네들은 되게 여러 번 하는데 이런 중간에 있는 애들은 얘네 한 번밖에 안 한 번밖에 안 들어가죠.
얘 특히 여기도 여기 있는 애들이 진짜 문제야 한 건밖에 계산을 못해.
그쵸 밖에 여기 되게 중요한 정보가 있으면 잘 못 보잖아.
그쵸 그래가지고 이게 인풋 이미지 피처가 컨볼루션 했을 때 정보가 이 가에 있는 정보를 살리고 싶어서 패딩을 하면은 똑같은 숫자로 이렇게 밖에다가 채워놓는 거예요.
이미지가 안 줄어들게 채워 넣으면 0으로 채워 넣어서 하면은 정보가 더 살아나거든요.

참석자 1 14:58
밖에 정보가 0으로 채워 넣어서 만들면은 제로 패딩이라 그래서 제로 패딩 제로 패딩 일반적으로 제로 패딩을 해서 정보 이렇게 하면 컨버레이션 연산을 하면은 원래 이미지가 유지가 된다고 그 크기가 커지는 건 어쩔 수 없는 커지지 않지 똑같이 만들려고 하는 거예요.
커지게 만들고 싶은 게 아니라 똑같이 유지하고 싶은 거예요.
커지지 않아도 똑같아 똑같이 만들게끔 패딩을 해요.
패딩이 채로 0을 채우는 건데 원래는 이렇게 뻥튀기 시키는 건데 원래 컨버레션 한 다음에 나오는 결과물이 똑같은 사이즈가 되도록 하려고 하는 것뿐이에요.
알겠죠. 만약에 필터를 크게 쓰려고 그러면은 더 크게 만들어 패딩을 더 많이 해야 되고 왜냐하면 왜냐면 필터 정도가 이제 사라지지 않게 하기 위해서 원래 줄어드는 정도만큼 어쨌든 보존하기 위해서 그러는 거예요.
이게 보면 여러분 느끼겠지만 처음에는 안 늦겠지만 여기 마지막에 이렇게 막판에 이렇게 딱 끝나잖아.
그쵸 막판에 이렇게 끝나잖아.

참석자 1 16:00
그리고 더 이상 이제 얘는 다시 계산 안 할 거 아니야 그쵸 이런 게 사라진 이게 만약에 필터가 더 커봐 그러면 더 많은 정보를 많이 한 번 더 연산을 못하잖아요.
필터가 작으면 더 연산을 많이 하잖아. 필터가 크면 연산을 진짜 많이 못하고 끝나버리잖아요.
그러니까 필터가 큰 만큼 많이 채워야겠다. 밖에다.
그쵸 느낌이 오죠. 여러분. 그래서 그거 정확히 계산 어떻게 하냐면은 그냥 산수적으로 하면은 그냥 2분의 f 마이너스 1 하면 돼요.
f 마이너스 1을 필터 크기에서 1을 뺀 거에다가 1을 나눈 만큼 밖에 채우면 돼요.
양쪽으로 왜냐하면은 당연한 게 마지막 막판에 여러분 필터 크기에서 뺀 것만큼 다 전부 계산 더 못하잖아.
봐봐. 여기 보면은 여기 이만큼 더 이상 한 번 계산 못하잖아요.
그쵸? 얘네들 계산하려고 그러면은 양쪽에다. 이만큼 여기 여기는 지금 이만큼 나잖아요.
필터 크기가 3 곱하기 3이잖아요. 컬러들이 그러니까 여기 마지막에 두 개 여기 한 번만 하고 끝나잖아요.

참석자 1 16:55
그쵸 그래서 양쪽으로 3 빼기 3 빼기 1 한 거에다가 2 나누면은 2 나누기 2니까 1이죠.
1만큼 채우면 돼요. 그렇게 채워지는데 여러분 이거 일일이 우리가 신경 쓸 필요 없게 API 다 있어요.
지금 API로 API로 보면은 사장 여기도

참석자 1 17:23
여긴 여긴 없는 것 같아요. 여기 없네. 없는데 원래 여기 원래 여기 교과서에 받아오면은 선부 2D에 금방 나오는데 금방 나오는 대로 보여주고 싶은데 금방 나오는 거예요.
이게 다 이미지로 돼 있어서 불편하네. 어디서 보여줬어?
보여주고 싶은데 미리 저게 이게 조금만 제대로 된 문제 하려고 그러면은 저게 다 지 미안해요.
여러분 잠깐만 으로 교육적인 걸로 하느라고 전부 다 있는데 조금만 제대로 된 거 하려고 그러면은 나오거든요.
32 미리 찾고 왔어야 되는데 기억이 안 나네. 안 되겠다.
네 할 수 없다. 내가 여기서 보여줄게요. 여러분

참석자 1 18:29
이게

참석자 1 18:41
패딩이라는 게 이 34페이지에 여러분 강의 자료 있는데 패딩이 디폴트가 세임인데 패딩이 디폴트가 쓰임 패딩이 디폴트가 쓰이긴 해.
지금은 패딩이 엘리드랑 세임인데 여기 세임이라는 게 이제 패딩 위드 제로즈 이불 미 이게 패딩을 제로로 하는 거네.
어쨌든 패딩을 해주는 거예요. 알겠죠 기본적으로 패딩을 해줘.
그리고 크기가 유지가 되게 그렇게 하고 있어요. 이것도 디폴트 값이 뭔지는 사실 여러분 외울 수가 없기 때문에 알려줄게요.
알겠죠 CMR 본다고 그러면 어쨌든 알겠죠 자요.
계속 저도 이거 API 마다 다른 걸 수도 있으니까 어쨌든 디폴트로 패딩을 해준다는 거지 알겠죠?
패딩 패딩이라는 게 프라미터가 있고 디폴트가 세인 패딩이 있구나 그래요.
그리고 밸리드라고 적어주면은 줄어드는 거예요.
이미지가 밸리드라는 세임이 있고 밸리드가 있어요.
여러분 기본적으로 아까 이 그림에서는 지금 밸리드 패딩이었던 거예요.
그냥 패딩 안 하는 거지 알겠죠?

참석자 1 19:56
이거는 아까 세임도 표했잖아요. 세임 세임이 패딩 해 주는 거예요.
세임이라는 게 이미지가 똑같이 나오게끔 원래 인풋 한 다음에 가로 세로가 변하지 않게 해주는 게 세임 패딩이에요.
됐죠 그리고 다른 말로 지로 패딩이라고 하기도 하고 다른 말로 해피 패딩이라고 부르기도 해요.
왜 해피패딩이냐면은 피터 크기에서 1 뺀 거를 나누기 2하잖아요.
그러니까 해프라는 느낌이 들잖아. 나누기 2에서 필터 크기 나누기 2지 사실은 여기 2분의 f 마이너스 2분의 1이잖아요.
여러분 여러분 이거 사실 계산하면 2분의 x로 하고 짝수면은 그냥 사실은 필터를 짝수로 잘 안 하거든요.
필트 보통 호스로 해요. 홀트 커널 크기가 보통 호수라고 3이면은 1만큼 채우면 되고 오면은 이만큼 채우면 되고 그래요.
그러면 머리만 하는 거지 사실은 이해돼요. 여러분 이게 세트 패딩이라고 부른다고 필터를 반으로 나눠가지고 그냥 버리는 걸로 채우기 때문에 패딩이라고 불러요.
알겠죠?

참석자 1 20:58
필터를 짝수로 하는 건 내가 본 적이 없네. 그러니까 피터한 사이즈를 보통 홀수로 해요.
알겠죠? 그래요. 홀수를 해야지 좀 알아보고 싶어도 나중에 이제 어쨌든 유지가 되기 때문에 여기서 그래서 지금 여기 f라고 적은 거는 커널 사이즈를 또 f라고 쓰는 사람들이 이게 f가 어디서 나왔겠어요?
여러분 필터에서 나왔겠지 용어가 그쵸? 여기 가 필터에서 나왔겠지 그쵸?
이거 왜 k라고 안 적고 f로 했냐 그냥 컨벤션이라면 되겠죠 여러분 필터는 사실 이해되죠?
여러분 f라고 하는 거 그래요. 그리고 많은 경우에 이제 만약에 인풋 이미지가 원디면은 뎁스가 이제 뎁스가 없으면 뎁스가 1이면 피터랑 커널이 똑같기 때문에 그래요.
어쨌든 컨퍼레이션 하고 나면 f 마이너스 1만큼 줄어든다는 거 여러분 느낌이 와요.

참석자 1 21:52
여러분 왠지 알아 이거 보기 무잖아 여기 f 마이너스 1만큼 다 못 하잖아 더 이상 여기 딱 끝나서 더 이상 못 하잖아요 그쵸 f 마지막에 필터 크기 빼기 이만큼 더 이상 진행을 못하잖아.
여기서 한 번 더 하고 또 하면 좋겠는데 못하잖아 그렇죠 f 마이너스 이만큼 줄어드는 거야 그렇죠 외워 알겠죠 f 마이너스를 하고 줄어들잖아요.
이거 이거 안 사실 추론할 수 있어야 되는데 알겠죠 이거 기억하면 당연히 그렇잖아 더 이상 못 가잖아 여기가 그쵸 피터 크기가 크면 그것만큼 그냥 피터 크기 피터가 한 번밖에 못하니까 백이 1만큼 줄어드는 거지 그쵸 알겠죠 터널 가로 길이만큼 터널 가로세로 길이만큼 알겠죠 잘 됐어요.
그다음에 패딩이 피터를 짝수인 경우 좀 이상할 때 넘어갑시다.
짝수인 경우 왜 이래 그냥 내가 그때 궁금해서 해봤어요.
여러분 그래요. 짝수 별로 없어요. 보폭이라는 건 당연히 스트라이드가 1로 보통 하고 있어요.
지금 제가 보여주는 거는 한 칸씩 하나씩 하잖아요.

참석자 1 22:54
근데 이걸 뭔가 좀 더 추상화를 잘하고 싶으면은 두 칸씩 막 뻥땅뻥 트여서 할 수도 있어요.
여러분 그렇겠죠 한 번 본 거 다시 안 보겠다 이럴 수도 있잖아요.
필토크가 2일 때 그렇죠 피터 토일 3일 때 한 번 본 거 다시 안 보겠다 그러면 피터 스트라이드 3 하면은 한 번 연산한 거 다시 안 보잖아.
그렇죠 이해되죠 여러분 여기 여기가 필터가 3 곱하기 3이죠.
스트라이드 3으로 하면은 한 번 보고 다시 1로 옆으로 넘어가 이 넘어가도 모자르지만 다시 한 번 곱한 건 다시 안 곱하겠다는 거지 이해돼요.
필터 사이즈 터널 사이즈랑 스트리 사이즈가 똑같으면은 한 번 보면 다시 안 보는 거야.
한 번 연산하는 거 다시 연산하네. 그렇죠 보통은 그렇게는 안 하고 그냥 보통 2 정도 많이 해요.
2나 3 정도 많이 해서 어쨌든 이거 뭐 하려고 그러면 정보도 줄이려고 하는 거예요.

참석자 1 23:41
그렇죠 이해되죠? 여러분 보폭을 늘리는 거지 스트라이드가 보폭이에요.
보폭 스트라이드가 일반적으로 이를 많이 사용해요.
알겠죠? 됐죠? 뭐 하는 건지 알겠죠? 여러분 이 그림 좋잖아 그렇죠 됐죠?
이렇게 해서 하나 나오고 이렇게 해서 하나 나오고 이게 스트라이드 2고 요렇게 요렇게 이렇게 3개서 나오는 게 스트라이드 3 스트라이드 1이고 알겠죠?
이것도 여러분 보폭도 사실은 이 가로 세로를 다르게 할 수도 있어요.
세로 정보가 너무 막 좀 늘려져 있어 이미지가 그러면은 세로 정보를 스트라이드 크게 할 수도 있잖아요.
그럼 보폭을 스트라이드 1 콤마 3 이렇게 할 수도 있지.
가로로는 한 칸씩 가는데 세로로는 다음에 여기 3은 말도 안 된다.
여기 2에 이렇게 돼 여기 하겠다는 거지 스트라이드 2는 그쵸?
이해되죠? 이해돼요.

참석자 1 24:28
여러분 스트라드가 1인데 이거 사실은 만약에 다음에 여기를 한다고 그러면은 이거는 1 콤마 1이라고 사실은 근데 1 콤마 2를 하면은 여기 한 다음에 다시 여기 한다는 거지 이거 알아야 돼.
이해됐죠? 그다음에 아웃풋 사이즈가 어떻게 줄어드는지에 대해서 제가 헷갈릴까 봐 여러분 막 적어놨어요.
여기다가 그냥 컨버레이션 연산을 보통 이렇게 표시하기도 했고요.
지금 이제 곱하기 2 40 그죠? 근데 퍼널이 이 정도 크기면은 이렇게 줄어들고 한 칸씩 한 칸씩 줄어들어서 이렇게 줄어들고 터널이 이렇게 크면은 두 칸씩 줄어들 거 아니야 그렇죠 다 없어지는 거죠.
그쵸? 이걸로 이미지가 이렇게 나온다고요 재미있죠 느낌을 가지라고 제가 이렇게 이렇게 그러니까 이 코너를 쓰면 원래 이미지가 이건데 led 패딩이죠.
패딩 안 하는 거 이렇게 컬러를 쓰면 이렇게 줄어들고 그쵸 요렇게 컬러를 크게 쓰면은 요렇게 이렇게 줄어들어 정보가 알겠죠 스트라이드가 다 1인 상태를 말해요.

참석자 1 25:31
스트라이드가 만약에 더 많아지면 더 트라이 더 줄겠죠 여기 길이 수시에 근데 이게 실제로 패딩 패딩이 얼마나 필요하냐가 중요하잖아요.
사실은 우리가 그렇죠 보통 패딩이 원래 이제 이미지 사이즈가 l 곱하기 n이고 피터가 f 곱하기 f고 페이지 사이즈가 p면은 이미지 자체는 n 플러스 EP 마이너스 m2를 스트라이드만큼 나눠가지고 더하기 1 한 거 곱하기 제곱은 이제 가로세로 똑같다고 이렇게 해놓은 거고요.
가로세로 같은 경우에 계산해 놨으니까 여러분 여러분 유치할 수도 있지만 그냥 보고 따라 할 수 있으면 되겠어요 알겠죠?
여러분 당연히 계산하면 가능한데 하면 되잖아요.
그렇죠 유명하니까 그렇죠 됐죠 오픈으로 나올 수 있어요.
알겠죠?

참석자 1 26:21
여러분 계산해 보면 알겠죠 할 수 있어야지 그쵸 찾아서 할 수 있어야 될 거 아니야 그쵸 채팅 페티트 부르면 얘는 키수 이런 거 너무 많이 해 걔는 걔는 걔는 좀 아이템나 빌리브염이나 이렇게 하면 안 소리 들으면서 하여간에 조금만 계산하면 다 틀리더라고요.
저도 여러분 아까 페이션스 틀리는 거 봤죠 저도 엄청나게 틀리잖아요.
사람을 믿을 수가 없어요. 그렇죠 어쨌든 시험 볼 때는 여러분 검토를 많이 하셔서 제대로 하세요.
그다음에 아까 터널이 여러 가지 쓰는 거 얘기했죠.
그렇죠 필요하고 그다음에 샤프닝이 어떻게 하는지에 대해서 보여주는데 재미있으니까 이것들이 인사이트 로드라고 원래 터널이 이렇게 생긴 건데 이미지가 이런 거였으면 만약에 여기 여기 3이 되게 크잖아요.
여기 중간에 크죠. 이런 거 있으면 이게 크게 숫자가 7이 되고 여기가 작았잖아요.
주위보다 그럼 이게 마이너스 3이 돼. 그래서 g보다 작은 거 확 작아지고 g보다 큰 거 확 커지잖아요.

참석자 1 27:14
이거 계산하면 진짜 계산하면 그래가지고 이게 아웃풋이 하나만 나오는 거 이해되죠?
여러분 터널 사이즈랑 이미지랑 이런 거 똑같은 크기면 웃풋이 딱 한 개만 나옵니다.
이 이미지 자체가 이 정보 하나로 줄었잖아요. 요 퍼널에 의해서 보다 정보 주의보다 작은 숫자가 있으면 숫자가 확 그쵸 터지고 느낌이 뭐지 이런 게 왜 필요한지에 대해서 그 샤프닝이 되는 거지 재밌잖아.
그렇죠 그렇죠 그리고 이런 것도 재미있다고 해서 갖다 놨는데 이게 얘가 원래 이미지 자체가 여러분 이게 지금 검은색 흰색이 이게 10 10 돼 있는 게 이제 숫자 크고 0이 작은 거잖아요.
이거를 바이너리로 보여주면은 여기 숫자 크기 흰색으로 나올 거 작은 이 검은색으로 나오겠죠 이런 이미지예요.
이해되죠? 그쵸 필터를 만약에 이런 거 썼어요. 필터가 어떤 거예요?
여러분 점점점 커지는 거 밑으로 가면서 숫자 위로 가면 숫자가 점점 커지는 거 그쵸 그런 의미잖아요.

참석자 1 28:09
그런 걸로 컨버션 연산하면은 이렇게 나온다는 거예요.
이게 뭐냐면은 여기 여기 숫자가 점점 커지죠. 여기 세 개는 그렇죠 커지는 건 여기 커진다고 나오고 여기 중간은 별로 안 커지니까 회색 빛이 나오고 여기는 반대로 되니까 이렇게 검은색으로 나오고 나머지는 그냥 회색으로 나오는 거.
정보가 없음 여기 별로 이런 식으로 변하는 건 여기 없잖아.
여기 여기만 이 정보에 의해서 영향받는 거는 여기밖에 없잖아요.
가로 세로로 색깔이 변하는 거는 여기 얘가 잡고 싶은 건 뭐야 가로 세로로 색깔이 변하는 거잖아요.
점점점 위쪽이 커지는 거를 잡고 싶잖아. 위쪽이 커지는 거는 자기를 닮은 놈을 세게 해주는 거잖아요.
계속 강조하지만 나랑 닮은 놈을 강화시키는 거야.
그쵸 나랑 닮아. 이거랑 닮은 놈은 여기잖아. 여기가 제일 닮았죠 여기가 제일 닮았잖아.
여기가 확실히 제일 닮았죠.

참석자 1 28:57
여기가 여기는 약간 좀 회색 지대잖아. 그쵸. 그래서 여기 확실히 제일 센 게 나왔죠 그쵸 그쵸 흰비 제일 센 거잖아요.
지금 그쵸 제일 안 달았으니까 제일 약한 게 나왔지.
그쵸 완전 반대잖아. 여기는 중립이라고 그냥 아예 그냥 회색으로 나오는 거죠.
아무 영향을 안 받는 거지 이해돼요. 여러분 그런 식으로 재밌잖아.
그렇죠 재밌지 않아요 여러분 그래요. 그래가지고 그렇게 돼서 여기 제일 보여주고 싶은 거는 여기를 이걸 연산하면 여기 탁 나오고 여기를 연 사람은 일로 나오고 여기를 연 사람은 일로 나와요.
그렇죠 위치 정보가 제대로 유지가 되지 그쵸 그리고 줄어들어요.
정보가 패딩을 해도 어쨌든 전과 유지가 돼. 그 위치에 그래요.
그래서 이것도 아까 보여준 거죠. 눈이 있으면 눈 쳐야 된다고 여기 봐봐요.
이렇게 하다 보면 똑같은 거를 그냥 숫자를 아니다.
아니다.

참석자 1 29:51
여기 똑같은 거 비슷한 거 있네 이러면서 이해되죠 여러분 빅데 나무 이렇게 피토가 하는 일이 뭔지 알겠죠?
나랑 똑같은 검사라는 거고 그게 학습이 문제 잘 푸는 데 도움이 되는 식으로 피토가 변형이 된다는 거지.
문제를 풀기 위해서 필터가 계속 변형이 돼요. 어떻게 변형되냐 우리가 로스터 변형이 똑같은 식으로 우리가 배웠던 왜 코스 엠플이랑 있잖아요.
다 그렇죠 개 갖고 학습시키냐면 백플 포기 하다 보면 이런 게 만들어지는 거예요.
재밌죠 똑같은 식으로 앞에서 배웠던 게 그대로 그래요.
그리고 이제 이거는 또 다른 데서 이거 보고 드리면 스탠퍼드 대학교에 교수님이 어떻게 잘 만들어 놨길래 제가 뺏겨놨어요.
사실은 조교가 아들 같은데 그때 갖고 왔어요. 여러분 그래서 여기 용어가 뎁스라는 용어랑 채널이라는 용어랑 같아요.
여러분 옛날부터 r 채널 g 채널 b 채널 이런 거 RGB 채널이라고 그러잖아요 그쵸?
뎁스랑 채널이랑 같은 말이에요. 여러분 알겠죠?

참석자 1 30:45
그래서 어쨌든 여기 이미지가 예를 들어서 인풋이 3 곱하기 3 곱하기 3 이렇게 돼 있어요.
그래서 이거는 이제 화이트 위드스 뎁스 이렇게 보통 순서 이렇게 해요.
여러분 알겠어요 여러분 이것도 정하기 나름인데 그것도 이렇게 알겠죠 그래서 지금 하이트 30 미트 32 s 3 이렇게 32 30 이해되죠?
여러분 이런 상황이에요. 이게 이제 이미지가 35 TB짜리 이제 RGD 이미지인 거죠.
보통 그럴 경우에 필터 만약에 커널이 5라고 그러면 커널이 사이즈가 5예요.
정확히는 5 곱하기 5인 거지 이해돼요. 여러분 아까 그 API에서 커널 사이즈를 5라고 하면 그게 사실은 5 곱하기 5 이렇게 들어 커널 사이즈를 5 곱하기 5로 줘도 되고 5로 줘도 되고 똑같다고요 알겠죠?
이렇게 되는데 실제로 필터는 이제 여러 필터가 32개 있으면 32개가 생기는 건데 이게 하나의 필터가 무조건 요 뎁스의 크기만큼 뻥 튀게 되는 거예요.
이렇게 터널은 여러 장 만들어요. 알겠어요 그래요.

참석자 1 31:54
그렇게 해서 필터가 아까부터 계속 강조하지만 필터가 웨이트를 가져요.
필터가 필터가 곱하는 놈이잖아 그쵸 서너리 곱하는 놈이잖아 그쵸 여기 다 이렇게 웨이트가 있는 거예요.
여기 여기 여기 알겠어요 여러분 여기 지금 이게 이게 여기서부터 이렇게 착착착 하겠죠 그쵸?
이해되죠? 여러분 그래요. 그리고 결과 계산하고 나면 여러분 필터 한번 적용하고 나면 진짜 하나 딱 튀어나오죠.
얘가 결국은 아웃풋 피처가 되는 건데 그쵸? 아웃풋 피처를 뭐라고 부른다고 그랬어요.
그러면 피처 맵이죠. 그쵸 피처 맵 콤말보드 피처 이렇게 부르잖아.
그쵸 이 결과 숫자 숫자 하나 숫자 하나를 의미해 알겠죠 이게 이해되죠 그리고 이 숫자 어떻게 만든 거냐면 이렇게 똑같아 이거 완전 뭐예요?
여러분 이거 이거 이거 지금 뭐야? 매니어리액션 똑같은 거죠 그렇죠 아까 했던 거 그거 바이올 수도 있어요.
여러분 사실은 피했지만 아까는 바이올 수도 있을 수 있어요.
알겠죠 그래요.

참석자 1 33:00
그다음에 이거를 이게 그래서 중요한 게 뭐냐면은 필터가 3개인데 이게 여기서 여기서 갑자기 이렇게 나오는 게 이렇게 나와서 얘가 5 곱하기 곱하기 3 필터를 한 번 적용하고 나잖아요.
필터 하나 적용하고 나면은 이게 20평 208 내는 건 왜 그러냐 이게 5 하고 나면은 4만큼 날아가잖아요.
그쵸 필터 빼기에 그렇죠 마지막에 5 딱 하고 나면 4만큼 못 하니까 날아갈 거 아니에요 전보가 그래서 32에서 4 빼면은 28인 거 이해되죠 28 곱하기 28이 나오겠지 그쵸 그리고 이거 3을 적용하는 거지 3개 3개 이상이 있는데 왜 하나가 나왔냐 한 명만 나왔잖아요.
여러분 왜 그러냐면은 다 합쳐버려 그냥 세 장을 필터를 필터 커널이 3장이었잖아요.
근데 그냥 그거 세 장을 나온 결과를 다 합쳐버려요.
이상하지 다 합쳐버려 그냥 왜 세 장 만드는 게 좋긴 좋을 것 같은데 그렇죠 다 합쳐버리잖아.
이상하지 의문이 들잖아요. 그래서 그런 거 없애게 나중에 잘 됐어요.

참석자 1 34:05
그런 게 없으면 나중에 배송을 했어요. 나중에 인셉션이니 다 그런 거 있죠 덱스트를 살리는 게 결국 잘 됐어요.
나중에 원래 PL은 이렇게 하고 있는데 잘 안 돼 이게 사실은 이상하잖아.
좀 이상한 거 맞다니까요 이게 이상한 거 맞지 이상하다고 느끼는 게 좋다고 그래서 그걸 이거를 다시 되살리는 게 잘 됐어요.
원디 컨볼레이션 이런 게 보여줄게요. 이게 요것만 보여줄게요.
여러분 이거 요거 요거 오는 거 보여줄게 어디 갔지 아까 이거 합치는 거 실제로 지금 원래 디폴트 컴포트 어떻게 하고 있는지 보여주면 이거 어디서 떠놨지 15페이지 15페이지에 만약에 이제 아까 이건 커널이 아까는 28 30이고 여기는 커널이 이거였는데 여기는 지금 달라요.
다른 건데 도라고 그냥 있는 거예요. 알겠죠?

참석자 1 34:55
RGB가 이렇게 있는데 코널 연산을 각각에 대해서 하면은 이렇게 아웃풋이 나올 거 아니에요 그쵸 근데 이거를 아웃풋은 여기 다 더하면 7 더하기 7 7 더하기 5 더하기 7 하면은 109 나오잖아요.
다 더한다고 진짜로 그래서 결국 한 장으로 만들어버려 열심히 3장에 대해서 한 다음에 하나로 합친다고요.
알겠죠? 근데 이렇게 대수 정보를 날리는 게 맞나 이런 생각이 좀 들잖아요.
그래서 좀 안 하는 게 많이 나왔어요. 뒤에 알겠죠 근데 지금 원래 여러분이 컴퓨터를 쓰면 이렇게 하고 있어 되는 거야 알겠죠?
알겠죠?

참석자 2 35:31
교수님 근데 필터가 웨이트랑 리니어 리그레션에서 웨이트랑 동일하게 동작하면 학습을 하는 과정에 따라서 필터도 계속 업데이트가 되는

참석자 1 35:44
계속 업데이트하는 게 백프라포기션 하면서 업데이트하는 거지 로스크 계산한 다음에 백프라포기션 언제 하는 거예요?
코디 패스트 다 한 다음에 결괏값 나왔잖아요. 그다음에 로스 계산하지 그다음에 백퍼 퍼게산하죠.
그래서 업데이트하는 거지 로스는 최대한 줄이고 그렇죠 똑같이 똑같이 해 똑같이

참석자 2 36:03
근데 초기에 필터는 이제 유사한 특징을 찾는 애들로 구성이 돼.

참석자 1 36:09
아니 근데 원래 댄스도 막 우리가 무작위로 막 넣어놓잖아요.
근데 옛날에 영어로 시작했다가 망해가지고 그게 사실 다른 교과서에 엄청나게 자세하게 나오는데 나는 그거 이 교과서에 없거든요.
0 말고 르쿤이니 그러니까 인슐라이저가 많아요.
이니셜 라이저가 이 디폴트로 쓰고 있는 게 많거든요.
근데 디폴트로 하는 게 디폴트가 되게 중요해 출발은 제대로 됐는지 하는 게 좋거든요.
전에도 로컬 라틴만 봤잖아 이상한 데서 하면 영원히 못 가잖아요.
그러니까 초기화를 다양하게 하는 게 좋지 그래서 필터도 되게 초기화를 다양하게 해주고 있어요.
그냥 유명한 걸로 할 수도 있고 우리가 직접 줄 수도 있어요.
필터를 이미 이미 직접 주는 게 바로 뭐냐 바로 트랜스퍼 러닝이 바로 그런 거예요.
전이 학습이라는 게 팀 필터가 이미 있는 거거든요.

참석자 1 36:57
이미 잘 푼 필터들이 있으면은 바라보는 문제가 비슷하면 필터가 원래 디폴트 시작하는 게 좀 뭔가 기본적으로 바퀴나 알아보고 이래 자동차 알고 싶으면 그렇죠.
만약에 동물 문제 맞추는 거라면은 뭔가 일단 강아지랑 고양이는 구분해서 갖고 시작하는 게 좋잖아요.
고양이 품주가 알아 사람 다 고양이인지 강아지인지를 구분하는 것부터 시작하는 게 좋고 이런 식으로 피터리 디폴트 값을 미리 좋은 걸 주는 게 바로 트랜스포 러닝이에요.
전이 학습 저녁 학습 시킨다고 여러분 이번에 아주 숙제 중에도 저녁 학습되고 빨리 들고 나와야 됩니다.
또 질문해 봐요. 지 이해했습니다. 그래요. 어쨌든 필터 값이 중요하지 처음에 그쵸?
전이 학습이 그래서 필터 값이 좋은 것부터 시작하는 거거든요.
안 그럼 영원히 잘 안 되거든 전 연습이 그래서 최대한 좋은 웨이트 값부터 시작하려고 하는 거예요.
벤스도 네트워크도 사실 마찬가지예요.

참석자 1 37:51
그냥 맨 땅에 헤딩하는 거 있죠 그걸 프론 스페치라고 그러는데 러닝 폼 스케치 스케치 스포츠 여러분 학습이라는 거 들어봤죠?
맨땅에 헤딩하기 위해 사실은 더보 같은 거 사실은 그것보다는 그냥 원래 잘 푼 웨이트를 가지고 와서 하는 게 좋고 근데 이제 보통 내가 되게 돈이 많고 굉장히 좋은 뭔가 모델을 만들었고 문제가 데이터셋이 많으면 맨 땅에 헤딩하는 게 더 좋을 수도 있어요.
처음부터 공부하는 게 더 좋을 수도 있잖아요. 우리 뭐 그래요 알겠죠?
여기 이거 지금 초기 값은 되게 잘 돼 있는 걸로 시작하는 게 좋긴 하지.
그쵸? 그래요. 그다음에 그래서 이렇게 하고 이렇게 나오고 이게 1 되는 거 여러분 이게 약간 좀 찝찝한데 진짜 찝찝한 거 맞고요.
알겠죠? 다 더해버려 세 개 세 번 계산해서 세 번 열심히 계산한 다음에 다 합쳐버린다고 알겠죠?
그래요.

참석자 1 38:45
그다음에 이거는 보여주고 싶은 게 이게 실제로 원래 이미지가 이래요.
만약에 원래 이미지가 이게 알지 여기 이 led잖아요.
그쵸? 그러면은 레드 채널에서는 얘만 세고 그리 채널에서는 얘만 세고 블루 채널에서는 얘만 센 거예요.
근데 재밌는 거는 이게 여기 약간 보이죠. 여러분 여기 파란색인데도 약간 보이잖아.
이게 완전 파란 게 아니라 약간 보랏빛이 감돌아서 그래 그러니까 여기 약간 이게 보랏빛이 섞여 있으니까 이게 보이는 거지.
근데 초록색은 진짜 하나도 안 섞여 있으니까 하나도 안 보이잖아.
그냥 그렇다고요 알겠더라고요. 알겠죠? 진짜 파란색이 아니었던 거 진짜 파란색 아니잖아요.
여기 아까 보라빛 같지 않아요 여러분 그쵸? 그래요.
어쨌든 그렇게 해서 왜 이렇게 3개가 있는지 이해되는데 이게 사실 아웃풋이 하나로 줄었잖아요.
여러분 하나로 그쵸 그래서 사실은 이게 안 좋은 거지 사실은 이게 파란색에 사실은 빨간색 여기 있고 초록색 여기고 이런 정보가 좀 사라지는 면이 있어요.

참석자 1 39:49
그쵸 원래 원래 얘는 이런 거야. 알겠죠? 여기서 보여주고 싶은 거는 원래 이제 이미지가 보통 rg이면 이렇게 세 장씩 세 플랜이 있고 플레인이라고 불러요.
여러분 보통 이해되죠? 여러분 플레인 플레인 3개라는 거 이해되죠?
r 플레인 g 플레인 d 플레인 그리고 커널이 그래서 커널이 이게 한 세 장이 있고 알겠죠 그게 하나의 필터가 되고 이 커널이 이렇게 인풋보다 작을 때는 9 이렇게 줄어들고 있죠.
그 3 플레인이 원 플레인으로 줄어들고 그렇죠 알겠죠 그거를 기억하시고 그다음에 이것도 여기서 보여주고 싶은 것은 그거밖에 없어요.
여러분 알겠죠? 됐어요. 여기 다친 거 잘 보여주잖아.
되게 그렇죠 애니메이션보다 이게 좋은 것 같아서 내가 이거 열심히 찾았어요.
제가 안 그리려고 같이 찾았지 그쵸 잘 보이지 않아요.
그쵸 그다음에 그리고 요거를 제가 설명을 더 하는 게 이게 여기 웨이트가 필터에 때 필터 여기 있는 거라고 생각하시면 되고 결국 웨이트 결과가 하나 나왔다는 거죠.

참석자 1 40:48
그쵸 근데 이 웨이트는 원래 뉴런이 있으면 이게 뉴런이 결과적으로 이렇게 계산해서 나온 다음에 결국 이렇게 여기 뉴런이 이렇게 하나씩 하나씩 28개씩 있는 거잖아 28개 28개 그쵸 벤슬리컬렉티드는 다 연결된 거잖아요.
여기랑 여기랑 다 연결된 거잖아. 그쵸 근데 여기 그게 아니라 얘를 재사용해서 얘 얘가 계속 똑같은 게 쓰이는 거죠.
그쵸 계산할 때 똑같은 이런 가산 됐어요. 얘네들이 그렇죠 똑같은 유런이에요.
똑같은 웨이트가 계산된 거예요. 점수 걔는 옛날에 똑같은 웨이트가 아니었죠 전혀 벤스 RNA rn 얘네 데스트리 커넥티드 데스트 레이어는 전부 다 뉴런별로 다른 웨이트가 있었어.
근데 얘네들은 전부 다 같은 웨이트를 썼다는 게 중요한 거예요.
필터 하나 갖고 만들어졌으니까 똑같은 필터 갖고 만들었어요.

참석자 1 41:38
그쵸 전부 똑같은 연산을 통해서 똑같은 웨이트 갖고 만들어줘야 돼 이해되죠 근데 그러면은 특성을 다르게 여러 개를 잡는 게 원래 그쪽에서 원래 그러니까 베스트 네트워크에서는 그 뉴럴 하나하나하나가 사실 뭔가 다른 추상을 한 거였잖아요.
여기는 이 플랜 하나가 다른 추상을 한 거예요. 그쵸 이해돼요?
필터로 동일한 위트 썼으니까 플레인 하나가 동일한 웨이트를 쓴 거니까 여러분 이거 다 여러분 잘 기억하세요.
벤스 네트워크에서는 뉴런 하나하나가 다른 레트 쓴 거잖아.
출력에서 거기가 뉴런 하나하나가 추상화를 한 거야.
그치 그쵸 여러분 여기는 컨볼루션 레이어 요거 요거 요거 요거 이니까 여러분 피처 맵 있잖아요.
피처맵 요 피처 맵 하나가 같은 헤이지 쓴 거지 전부 다 여기 하나만 주사만 한 거야.
그쵸? 요 하나하나하나가 다른 추사가 난 게 아니야.

참석자 1 42:33
전체가 다른 추 추사가 하나 난 거라고 그러니까 이런 게 원래 늘어는 개수만큼 필터의 개수가 있어야겠구나 이런 생각이 들어요.
안 들어요. 뉴런의 개수만 원래 데스슬리 컬리티 네트워크에서는 뉴런의 개수만큼 필터의 개수가 필요한 거야.
추상을 그렇게 많이 해야 되니까 전에 뉴런을 막 256개 하고 막 그랬잖아요.
그럼 필터가 그만큼 있어야 되는 거지 이해돼요. 여러분 필터가 그만큼 있어야 되는 거예요.
필터의 개수가 아까 필터 32였잖아. 사실 32개 뉴런이 있는 거나 마찬가지예요.
사실 31과제의 추상을 하겠다는 거지 그거를 염두에 두세요.
여러분 느낌이 와요. 계속 해봅시다. 일단 그래서 이게 실제로 여기 이거 만약에 아까 아까 필터 말고 두 번째 필터가 생기면 이렇게 또 새로 만든다고 여기다가 또 계속하면 계속 다 열 안에 필터를 6개 쓰면은 6개가 이렇게 만들어지는 거죠.

참석자 1 43:32
전에 댄스 리커렉티드에서 6개의 뉴런이 나오는 거랑 사실 여기 유런이 여러 개 들어 있지만 얘가 추상을 6번 한 거라고 이렇게 추상화된 거 6개 들어 있나 알겠죠?
됐죠 필터가 6개인 경우에 이렇게 나온다고 이해됐죠?
여러분 하나하나가 한 플레이 한 플레이 전부 다 똑같으면 왜 이렇게 썼어?
알겠죠? 똑같은 웨이트 똑같은 필터를 썼다는 거지.
그쵸? 학습을 통해서 필터는 변하지만 어쨌든 계산 포스 포워드 캐스 할 때는 똑같은 웨이트 나 맞는 거야 알겠죠?
됐죠 그래요. 그래서 그거를 얘기했고 그다음에 이거 시간이 많이 걸리네.
그래도 이렇게 이해하는 게 필요하지. 사실은 그렇죠 그래요.
그리고 이게 여기는 이 필터가 뭐가 들어오든 간에 요 위치 요 위치에 요 입력 키스 상에서 요 위치의 정보는 다 요 위치로 생긴다.
입력 위치 정보가 사라지지 않는다라는 얘기를 하고 있어요.
이 위치의 게 지금 하나 둘 셋 넷 다섯 개. 이거 필터가 5개인 거지 이해돼요 여러분 됐어요.

참석자 1 44:41
그쵸 여기 이거를 이걸 통해서 아웃풋이 이렇게 나왔어.
그런데 여기에 다섯 뎁스가 5개면은 필터 5개 쓴 거고요.
여기서 보여주고 싶은 거는 위치 정보가 사라지지 않는다 고 입력에서의 그 위치 그게 그대로 일로 온다는 거지 위치에 대한 거를 여기서 다시 해줄게요.
여러분 보면은 아까 아까 봤던 거 요거 봤던 거 기억나죠?
여러분 요거 요거 지금 18페이지예요. 여러분 슬라이드에서는 18페이지 요 위치가 일로 오고 요게 노란 게 일로 와요.
여러분 초록색이 초록색으로 가고 어쨌든 위치가 줄어들어 정보가 줄어들어도 위치 정보가 그대로 뭔가 상대적인 위치가 유지가 되는 게 보이죠.
그래서 이게 CNN이 어디서 잘 막힐 건지 여러분이 느끼는 느낌을 가져야 되는 게 상대적으로 위치가 뭔가 중요한 놈들 숫자 같은 경우에는 구가 있잖아요.
한편도 위치가 되게 중요하잖아. 여기 동그라미 여기 있어야 되고 여기 여기 그렇죠 이런 게 되게 중요한 거죠.

참석자 1 45:40
그쵸 그쵸 구를 이렇게 쓰면 여러분 이렇게 이렇게 쓰면 이거 9예요.
6이에요. 6이지 그러면 알아야돼. 알겠죠? 여러분 근데 어떤 데서는 9랑 6이랑 이게 같은 걸 수도 있잖아.
사실은 사실 이거 이거 너무 야했어요. 이거 별로죠.
여러분 사실 거꾸로 헷갈려 가지고 맨날 이것 때문에 추리 소설 재미있는 거 많이 나오잖아요.
어쨌든 그렇잖아요. 여러분 그래서 여러 실제로 6에 여기 언더 바치는 거 많이 있잖아요.
사실 헷갈리지 않게 알지 여러분 만약에 실제 고 같은 거 안 들면 6 같은 거 구면 안 되니까 동그라미 쳐야 돼.
여기다가 이게 여기 다 쳐야 돼. 사실 6은 이렇게 써야 돼.
사실 여러분 아니 만약에 가로 세로 정보가 안 나와 있어 RI를 알 수가 없으면 알겠죠.
그래요. 그래가지고. 근데 CNN은 철저하게 아래 위 정보가 다 유지가 돼.
알겠죠 됐죠. 근데 사실 사람이 안 그런 정보가 많지 뒤집어도 똑같아야 되잖아요.
그래서 알파고 같은 거 있잖아.

참석자 1 46:41
알파고 두판 과두판은 사실은 여러분 아래로 뒤집는다.
옆에서 본다. 오른쪽으로 그려져나 똑같아야 되는데 CL은 다 다르게 보잖아요.
그때는 이렇게 된 놈 이렇게 다르게 본다고 이거랑 구가 이렇게 옆으로 된 거랑 다른 걸로 본다고 그렇잖아요.
여러분 사실 똑같은 건데 똑같지 않지 숫자는 하필이면 그런데 많은 정보들은 여러분 걔가 누워 있건 서 있건 옆에 있건 똑같잖아요.
여러분 사람이 이렇게 있건 이렇게 있고 그 사람이잖아.
이렇게 있거나 이렇게 있거나 다 저잖아요. 여러분 근데 이렇게 있는 거랑 이렇게 있는 건 다르게 인식한다고 이해돼요.
여러분 얘랑 얘랑 다른 거야. CNN은 그렇잖아요.
아니 그걸 알려고 여러분 그래서 이런 정보가 만약에 상관없는 거면 CNN이 안 좋아 뭐가 좋을까요?
그런 네트워크이 또 있어요. 그래프 뉴럴 네트워크가 새로 나왔어요.
요즘에 하는 것도 그래프 같은 것도 많이 뜨고 있어요.

참석자 1 47:30
여러분 CNN이 다가 아니라고 알겠어요. 여러분 공부가 끝이 아니고 실제로 여러분이 이 회사를 제대로 하려고 그러면은 CNN 말고 딴 거 써야 돼.
GLL 같은 거 써야 돼 알겠어요? 여러분 교과서에 못 나와 그쵸 여기까지 진도 못 나가는 애들 CN은 제대로 알고 알겠죠?
CN은 정확히 가로세로 아래 위 정보가 그대로 줘야 된다는 거예요.
알겠죠 근데 그게 좋을 때가 많아. 실제로 우리가 그렇게 보잖아요.
거꾸로 하면 여러분 사실 이런 거 있어요. 사람 표정 있죠?
사람 얼굴이 손바로 백대를 뒤집어 보면 완전 웃는 얼굴 우 얼굴 되고 막 이런 거 알아요.
여러분 그러니까 우리는 완전히 사람을 얼굴 울고 나면 선 사람의 표정을 읽을 수가 없어.
CNN도 그런 놈인데 근데 그게 중요하긴 하지. 사실 그러니까 똑바로 사람이 있는 얼굴 보는 게 중요하니까 알겠죠 CNN이 많은 경우에 좋고 아닌 문제도 많다.

참석자 1 48:19
알겠죠 그 정도만 알고 계시고 위치 정보가 그래서 여기 제가 계산한 건데 어쨌든 여기 가운데 있는 게 이렇게 정확히 이렇게 딱 오기 때문에 어쨌든 스트라이딩까지 하면 이렇게 계산된다는 거 적혀놨어요.
알겠죠? 오픈북으로 볼 때 여러분 알아먹으세요.
알겠죠? 이거 저기 위치가 어떻게 되는지 얘가 정확히 여기서부터 여기까지 이렇게 딱 된다 이런 거 있죠 여기 여기 일러는 여기서 온 거고 여기 이러는 여기서 온 거로 계산할 수 있어야 된다고 그랬죠 산수예요.
산수 진짜 산수예요. 50대 돼버렸네 말을 많이 해야지 알겠죠 여러분 됐죠 근데 CNN은 좀 약간 생각할 거리가 많고 이렇게 여기서부터 합기적으로 좋아졌기 때문에 그다음에 또 획기적으로 좋아지는 건 또 다른 것 때문이니까 CA를 하려는 건 아니고 알겠죠 CA는 정확히 뭐 하는 운동인지 여러분 이해합시다.
알겠죠? 그래요.


clovanote.naver.com