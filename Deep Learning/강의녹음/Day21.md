딥러닝 day21_1
2025.05.28 수 오전 10:02 ・ 50분 9초
심승환


참석자 1 00:00
이게 굉장히 좋더라고요. 이게 여기 가면은 구글에서 나온 랭귀지 모델인데 여러분 공부할 때 이해할 수 있어요.
제목이 시작이 무엇이든지 이해할 수 있어 이해하기 어려운 걸 이해하기 쉽게 만들어 준다는 거예요.
그래서 여러분이 굉장히 긴 블로그 글이나 이런 것도 많은데 되게 장하고 뭐가 뭘 따라는지 잘 모를 때가 있잖아요.
그쵸 논문들이 논문들도 있을 수 있고 그렇죠 종합적이나 이런 거 할 때 그런 거 할 때 얘를 소스로 주고 요약을 해달라고 그러면은 오디오 요약이라는 게 있거든요.
오디오 요약 이름이 레설치라고 돼 있는데 레설치 맞고 그래서 여기 보면은 오디오 요약을 해주거든요.
오디오 요약 그래가지고 오디오 요약이 재미있는 게 두 사람이 이렇게 대화하는 식으로 해줘요.

참석자 1 00:47
근데 원래 사람이 뭔가 이렇게 서로 상호작용하면서 이해 잘하잖아요 라고 여러분도 저랑 이렇게 막 얘기하고 있는 것처럼 마주 보고 있는 것처럼 제가 일방적으로 하는 것 같지만 사실 여러분 표정을 보면서 뭔가 좀 그러고 있죠.
그래서 예를 들어서 제가 여기 이 논문이 이제 이 논문은 이제 DNN 딥러닝 논문이니까 사실 여러분들이랑 관련이 있죠.
이제 여러분이 이거 내가 중요하다고 그래서 만약에 이거를 하지 않지만 지금 여러분한테 시키지 않지만 DNN을 파티셔닝 해가지고 IoT 네트워크에서 파이프라이닝 해서 인퍼런스 하는 거라고 그런 논문인데 여러분이 이 논문을 읽고 잘 이해하는지 궁금한데 근데 이제 여러분 이거 이해하라고 그러면 희한이 힘들잖아요.
사실 아까 그렇죠 이게 잘 썼지만 그러면 이거를 예를 들어서 이걸 여기다가 주고 영어 한국어로도 요약할 수도 있고 영어로도 요약할 수 있거든요.
근데 진짜 여기 둘이 이 시키면 소리가 나는데

참석자 2 01:50
주변에 스마트 기기들 점점 더 똑똑해지

참석자 1 01:53
네 그렇죠

참석자 2 01:54
근데 이 기기들이 실시

참석자 1 01:56
지금 만든 거예요.

참석자 2 01:57
좀 복잡한 인공지능 AI 작업을 하려면 힘에 부칠 때가 많아요.
맞습니다. 예를 들어 이상하네 홈 CCTV가 실시간 영상을 막 분석해야 하는데 버벅거리거나 되게 중요한 순간 놓치면 안 되잖아요.

참석자 3 02:10
그렇죠 성능이나 메모리가 보통은 좀 제한적이니까요.
아

참석자 1 02:15
메모리가 부족한 IoT 기기에서 분리하기 위해서 DNN들을 쪼개가지고 돌리는 방법인데 거기에 이제 굉장히 똑똑한 방법을 두 가지 제시를 했거든요.
근데 그거를 설명을 너무 잘해요. 이 서로 막 있잖아요.
제가

참석자 3 02:29
얘네들이 IoT 기기들은

참석자 2 02:31
그래서 오늘 저희가 바로 이 문제를 해결하려고 서울대랑 한국외대 연구진들이 내놓은

참석자 1 02:37
한국에 연구진들이 바로 저죠. 이제 한국에 대해 저고 서울대는 제가 원래 석사했던 애를 서울대 박사 과정을 보냈기 때문에 걔가 같이 했거든요.
그래서 어쨌든

참석자 2 02:48
파이크라는 기술 이거 한번 제대로 파헤쳐보려고 하

참석자 3 02:52
DNN 파이프요. 네

참석자 2 02:54
관련 연구 자료 보면서 이게 어떻게 돌아

참석자 1 02:57
걸리는 게 이상하 뒤에 가면 보시면 버퍼링 하는 거야.

참석자 3 03:03
어장해 뒀다가 다시 써서 중복 계산을 피하는 아주 영리한 방식

참석자 2 03:08
그냥 동적 계획법만 쓰는

참석자 1 03:10
동적 계획법이라고 하면 이제 그냥 이해 안 되실지 모르지만 또 동적 계획법 뭔지 설명도 해줘요.
그러니까 이해하기 쉬우라고 이해되죠. 여러분 그러다가

참석자 2 03:18
라면서요. 또 똑똑하게 만드는 비결이 있다던데 그 가지치기 푸르닝이라고 하던가요?

참석자 3 03:24
맞아요. 가지치기 이거 노래 하는데

참석자 2 03:27
전원 사과 나무가지 쳐내듯이 답이 될 가능성 없는 애들은 미리 쳐내는 그런

참석자 3 03:32
네 아주 좋은 비유입니다. 이게 DNN 파이트는 두 가지 강력한 가지치기 기법을 써서 탐색 시간을

참석자 1 03:38
논문에서 비의무실 안 하죠. 왜냐하면 논문이니까 수학만 나오는데 네

참석자 3 03:42
첫째는 상 기반 가지치기 ubp라고 하는데요. 이건 뭐랄까 이론적으로 계산해 최저 파이프라인의 최대 단계의 시간 그러니까 상한선 있잖아요.
어떤 계획을 짜는데 특정 단계의 예상 시간이 이미 그 상한선을 넘어버린다.
그럼 이건 볼 것도 없이 탈락시키는 거야.

참석자 2 04:02
이 길은 가봤자 최적이 될 수 없어 하고 초반에 그냥 잘라버

참석자 1 04:06
이런 말을 굳이 여러 번 하면서 굉장히 다이키잖아요.
뭔가 이름이 전혀 안 나오잖아요.

참석자 3 04:11
아예 쳐다도 안 보는 거죠.

참석자 2 04:12
그럼 두 번째 가지치기는요.

참석자 3 04:14
둘째는 저활력 단계 가지치기 osp라고 합니다.
왜냐면 이건 약간 조별 과제

참석자 1 04:21
가서 얘기해야 돼요.

참석자 3 04:22
조별 과제예요. 어떤 친구가 너무 일을 적게 맡아서 다른 친구들한테 부담이 가는 그런 상황이랑 비슷해요.
측정 단계 측정 기기에 할당된 작업량이 너무 적어요.
너무 빨리 끝나요. 심지어 다음 단계 작업 일부를 미리 가져와서 해도 여전히 시간이 너무 남는다.
네 그럼 이건 자원 낭비고 전체적으로 봤을 때 불균형한 계획이니까 이것도 탈락시키는 겁니다.

참석자 2 04:48
특정 기기가 너무

참석자 1 04:49
어쨌든 전 놀고 있다는 표현도 좋죠. 그렇죠 그러니까 굳이 논문에는 그런 얘기 안 할 거 아니에요 여러분 더 와닿지 않아요 되게 특정 기기가 놀고 있다 이런 표현 쓰고 조별 과제 얘기도 굳이 하고 뭔 얘기인지 알겠어요 여러분 왜냐면은 논문은 거의 수학으로 점철되어 있는데 거의 수십 대 투성이죠.
근데 여기는 지금 뭐 핵심 아이디어를 이해할 수 있게 굉장히 다른 걸 막 섞어가지고 얘기해 주잖아요.
그렇죠 중간중간 뭘 할까 이렇게 한번 쉬어지기도 하고 이해하라고 그렇죠 가보자.
그러니까 이게 동문 이해하는 데 되게 도움이 되겠죠 여러분 그렇죠 그래요.
정말 놀랐어요. 이렇게 잘할 수 있다니까 그가 너무 제가 공유해가지고 다른 동문도 막 넣어봤는데 논문이 워낙 원래 논문이 좋아야 되더라고.
우리 논문은 너무 좋았어. 이 논문은 너무 좋아가지고 잘해주고 별로 논문이 별로 안 잘 써져 있는 건 잘 못하더라고요.

참석자 1 05:32
원본이 되게 중요해요. 원본에서 그래도 어느 정도 이렇게 좀 강조를 해주고 잘하는 거는 잘해주는데 원본이 좀 납득이 잘 안 되더라고요.
어쨌든 근데 이걸 전체적으로 이게 다 하면 8분으로 나오는데 근데 영어로 하면은 영어로 하면은 왜 이건 스크립트지 영어로 하면 여러분이 많이 이거 뭐 이런 것도 많이 활용하면 좋겠어서 얘기해 주는 건데 이러고 영어로 하면 얼마 나오냐 뭐 나오냐 풀어야 되는구나

참석자 1 06:11
이거는 되게 좋은 게 수식도 설명을 다

참석자 1 06:19
15분이잖아요. 거의 2배예요. 2배 영어로 하는 게 더 좋긴 한데 근데 이제 아까 같은 그런 재미있는 뷰는 없어요.
DNN 뷰 여기서는 이제 약간 대상이 다른 여기 대학생 이상인 것 같아요.
스키s 적용하는 예를 들어서 운영 체제 예를 들어 다른 것도 제가 해봤는데 페이징이 나오는 페이징이 뭔지 약간 설명을 해줘요.
우리나라 요약에서는 근데 여기서는 페이징이라는 건 다 알고 있다고 쳐 운영체제 페이징 사실 다 까먹었을지도 모르는데 운영체제 페이징이 뭔지 아시나요?
여러분 근데 그런 건 안다고 생각하는 다이나믹 프로그래밍 같은 건 안다고 생각하고 설명해 영화에서는 그럼에도 불구하고 길가 2배잖아요.
얼마나 자세하게 하겠어요 여기 웍스 리체프도 있고 수식의 내용까지 설명을 다 해줘요.
아까 상한선 하한선 있잖아요. 그것까지 수식도 설명을 해줘요.
수식이 무슨 내용인지 여기 웍스 제프도 설명해 주고 그래서 그리고 마지막에는 더 좋은 게 약간 기분이 좋지 이거 많이 보면 마빡하네.

참석자 1 07:42
어쨌든 여기 여러분한테 되게 엄청나게 칭찬을 해줘 하여튼 간에 이 연구에 대해서 근데 여러분이 잘 안 들리지 그래서 이게 문제는 그리고 내용 그거 아니면 잘 안 들리는 면이 있더라고요.
그래서 실제로 보면 여기 오디오 스크립트 뽑아서 보는 게 필요할 수도 있어요.
여러분 그리고 다시 여러분 영어 약하면 한글로 다시 번역할 수도 있는데 영어 오디오 스크립트가 훨씬 더 잘 되니까 그래도 이제 워낙 부엌체이기 때문에 이렇게 이거 이런 거 스크립 바르는 거는 위스퍼 라이브러리 전에 위스퍼 라이브리 그쵸 여기 쓰고 있죠?
맞죠? 이유진 맞죠 맞아 이스프 쓴 거 맞아요 맞죠?
네 맞습니다. 맞아요. 얘로 하면 좋은 그냥 이거 그냥 아무 컴퓨터에서나 하면 되는데 그래도 이제 여러분 이 자기 PC에는 잘 안 되고 또 노트북은 전 잘 안 되고 PC 정도 돼야지 잘 되고 거기로 해서 이렇게 뭔가 전환해서 보면 되게 잘 보이잖아요.

참석자 1 08:34
그쵸 영어 쪽에서는 보면 마지막에 굉장히 새로운 지평을 연 것처럼 막 해줘요.
오픈 썸 인트리깅 프라퍼서블리케이션 하면서 굉장히 자세하게 무슨 새로운 연구 과제를 만들어주고 그래서 이게 뭐냐면 마지막 같은 거 보면은 히로에서 파이너스 투퍼라 면서 efk 아웃 파인더 메세플 베스트 웨이 투 스프레드 AI 디스크 포스 체인징 그룹 그럼 새로 이제 트롤리 다이나믹하고 세이플링 하면 셀프 아토마이즈 AI 애플리케이션이 매체에서 어떻게 만들어질 수 있을까 이런 새로운 애플리케이션에 대해서 구상해 봐라 그러니까 뭐냐 하면 약간 좀 새로운 프렌트에 대해서 약간 소개해 주는 경향이 있다고요 다음 연구로 뭐 할지 그것도 굉장히 실체팀도 잘 아는 것 같아 그래요.

참석자 1 09:23
그래서 얘들 여기서 요점 정리해서 학습하는 거 그 통찰력을 얻는 게 있죠 아니면 뭐냐면 이게 얘가 좋은 게 오디오 같은 거 보면은 무슨 세인지 하는 것 같아서 좀 그렇기는 한데 너무 여러분 좀 감동받아서 그러는 건데 그러니까 막 좀 같은 말을 반복을 해서라도 어쨌든 중요한 건 되게 전달하고 노력하잖아요.
그렇죠. 남자 여자가 왔다 갔다 하면서 영어로 할 때는 단어 하나를 서로 반복해서 얘기해 줘요.
중요한 단어가 있으면 ust 이러면 여기서 여자 가실 때 ust 이렇게 해주고 하면서 한 번 반복해 주면서 중요한 걸 각인시키면서 이렇게 좀 저도 강의할 때 그렇게 해야 된다는 걸 다시 또 느끼고 이게 전달하기 위해서는 중요한 포인트에서 좀 쉬어야 돼 일부러 쉬어주더라고 그리고 한 번 더 얘기 반복해 주고 좀 약간 더 뜯어 드리는 거 있죠 그런 게 굉장히 느껴졌어요.
그래서 미팅 잘하더라고요. 그래서 여러분 이 발표 스킬이 되게 어렸을 때 발표 스킬 그래서 모범적인 프리젠테이션 있잖아요.

참석자 1 10:20
가이드라인 여러분 발표 자료도 한번 여기 넣어 발표할 때 어떻게 알아야 되는지를 알려주는 게 있어요.
예를 들어서 여기 논문에서 이 논문에 예를 들어서 설명을 이거를 발표를 하라 그러면 저자조차도 심지어 이상하게 발표할 수도 있거든요.
이거를 쫙 잘 발표해 봐 이거 이거 알아듣겠냐고 이게 너무 정신없잖아요.
그리고 이거 이 테이블 설명하려고 그래도 테이블 설명도 이상하게 할 수 있는데 저기 걔 영어 요약본에서는 이 테이블 설명하면 바로 중요한 파라미터 두 개를 너한테 도출하는 걸 보여주고 막 이렇게 설명 잘하더라고요.
정상 그러니까 뭘 상대방이 이해하려면 어떻게 설명해야 되는지 되게 잘 알려줘서 여러분이 뭔가 자료가 있으면 한번 얘한테 먼저 발표 연습시켜보고 여러분도 거기서 조언을 받아가지고 하면 좋겠어요.
자세한 건 좀 잘 안 되는 경향은 있는데 어쨌든 기본적으로 이걸 이해한 다음에 다루는 걸 하면 좋겠지 그쵸.
그래서 이런 걸 활용하기를 바래요.

참석자 1 11:16
그다음에 그러면은 우리 진도 나갑시다. 진도는 10장이고 9장까지 다 했어요.
그렇죠 9장까지 이제 CNN을 한 거죠. 그렇죠 우리가 MMP랑 CML을 주로 했어요.
그렇죠 MMP가 여러분 댄스만 중에 있는 거 그렇죠 아까 지금 어쨌든 dnif 그 논문은 이 10장에 10장 논문은 아예 안 다루고 있는 거예요.
10장은 이제 시계열인데 시계열을 위한 딥러닝 제목이 이렇게 돼 있지만 사실은 이제 RNN이라는 걸 쓰는 논문이에요.
RNN RNN이 유명해요. 이제 RNN이 완전히 트랜스포머라는 게 나온 다음에 죽은 것 같이 보였는데 사실상 죽어 거의 좀 잘 안 되는 경향이 있는데 그래도 그 유용한 뭔가 좀 어떤 핵심 아이디어는 좀 얻어갈 필요가 있어요.
사실 여러분 다시 얘기해 주면은 시리어를 위한 딥러닝이 사실 지금 RNN으로 나와 있는데 RNN이 현재로서는 잘 안 되는 경향이 있어요.
그래요.

참석자 1 12:17
일단 시계열이 시작하면 이제 시계열이 영어로 뭔지부터 시작해 볼까요?
영어로 타임 시리즈라는 걸 그 타임 시리즈 시계열은 타임 시리즈예요.
숫자 그러니까 시계열이나 타임 시리즈랑 이제 우리나라 영어와 우리나라 말 이렇게 다른 거도 똑같은 얘기를 하는 거예요.
그래서 지금 378쪽 바로 들어갔죠 한 시리즈 이런 거 시간 타임 시리즈가 여러분 시퀀스가 있는데 걔가 이제 시간 단위로 나온다는 거 주기적으로 그쵸 그런 걸 의미하는 거지.
그리고 이제 보통 예전에 우리가 뭔가 예측하는 거는 프디트라는 용어 썼잖아 프디트 프리딕트라는 용어를 썼는데 이쪽에서는 프로케스팅이라는 용어를 써요.
프로캐스팅은 우리가 보통 예보라고 하기도 하고 그렇죠 약간 근데 영어로 프로케스트 프린트가 똑같아 우리나라 말로는 예측이 안 된다.
프로캐스트는 뭔가 정말로 미래에 대해서 예측하는 게 포케스트고 프리디트는 원래 있는 건데 답을 몰라서 예측하는 게 프리트 그래 이렇게 뉘앙스가 있어요.

참석자 1 13:27
몰랐으면 지금 알았어요. 여러분들 알겠어요 프린트와 프로케스트의 차이가 뭐라고요?
프로캐스트는 뭔가 시간적으로 미래의 일을 예측하는 거고 프린트는 알지 못하는 것에 대해서 답을 알아내려고 추측하는 게 케이트예요.
다른 거 알겠죠? 여러분 그렇죠 그래요. 그래서 영어로 영어가 약간 이런 쪽은 굉장히 발달했죠.
그렇죠 그래서 얘네들이 주로 하는 거는 어쨌든 입력이 이제 시계열로 주어지는 거고 입력이 타임 시퀀스로 그래서 웹사이트 방문자가 어떻게 들어오는지에 대해서 시계열이 주어졌을 때 이 방문자가 곧인지 아닌지 분류하는 거 이거는 여러분 저기 사실 우리 수강생 시스템 할 때도 분류할 때 이게 지금 사람이 하고 있는 거예요.
아니면 로보트가 고시하고 있는 거예요. 그렇죠 그럼 가짜 프로그램 때 당연히 그걸로 하고 있는 거지 12월로 실제로 잡아서 한번 좀 그런 적이 있었어요.
문제가 이거 여러분 사람이 할 수 없는 일 수가 있잖아요.

참석자 1 14:30
그쵸 그것도 흉내내서 또 하기도 하고 그 요즘에는 어쨌든 이해되죠 여러분 그렇죠 그다음에 여기도 이벤트 감지 이벤트 감지 같은 경우도 이제 스트림이 이거 이거는 시리얼 쪽에서는 또 이게 이게 1개월이 오디오 스트림이라 오디오 스트림에서 헬로우 구글 뭐 이런 거 있잖아요.
여러분 가끔 시리가 또 응답하는 거 있죠 걔도 이제 오드 스트링 모니터링하다가 하는 거라고 이제 시계열 작업이라고 보기도 해요.
계속 이제 계속 모니터링하고 있기 때문에 그다음에 이상치 디텍션 어나뮬리텍션 이런 것도 이걸 꼭 시리아이라기보다는 이런 것들이 있다는 걸 예측하는 데 써줬다는 것만 알면 될 것 같고 그다음에 우리가 시계열이라는 게 뭔가 갑자기 새로운 것처럼 보이지만 사실은 원래 우리 동구통신공학과에서 하는 많은 것들이 뭔가 프리퀀시 도메인을 다루는 게 많잖아요.
프리커스 도메인 그게 다 주기적으로 뭔가 일어나는 거를 바꿔서 보는 거잖아요.

참석자 1 15:36
그쵸 프리 트랜스포메이션도 사실은 시간 단위로 뭔가 들어오는 정보를 그쵸 그쵸 주파수 단위로 보는 거잖아요.
그쵸 역수로 보는 거죠. 그렇죠 그래서 우리가 프리 변환도 마찬가지 뭔가 그런 내용이라는 거를 볼 필요가 있고 그래서 이 챕터는 그래서 마지막에 어디 갔어 여기는 안 적혀 있네.
379쪽에 379쪽에 보면은 2장에서는 순환신경망에 대해서 배우고 적혀 있죠.
그쵸 그래서 여기에 RNA 하고 미크론 디럴 네트워크에 적혀 있죠.
그쵸 이거가 이 챕터 내용이에요. 그리고 여기서 정말로 이제 타임 시리즈 포캐스팅하는 데만 쓰려고 해요.
알겠죠 여기서는 그래서 바로 이제 10.2절이 온도 예측인데 온도가 이제 타임 시리즈별 타임 시리즈로 실제로 존재하는 건 아니지만 우리가 뭔가 우리가 온도를 예측하려고 그럴 때 1시간 뒤 또는 하루 뒤 아니면은 3시간 뒤 이렇게 예측하잖아요.
그쵸 그리고 데이터도 그렇게 쌓고 이해돼요.

참석자 1 16:41
여러분 그래서 얘도 이제 타이 시리즈로 데이터를 쌓고 그리고 미래에 대해서 예측하기 때문에 이것도 RNN으로 하려고 하는 거예요.
알겠죠 여러분 그 성격이 다른 거 알겠어요? 옛날 거랑 미래를 예측하려고 하는 거예요.
온도 예측을 왜 하냐 내일 어떨지 모레 어떨지 일주일 뒤에 어떨지 알고 싶어서 그러잖아요.
그래서 데이터도 타임 시리즈를 쌓고 그래서 이제 이게 이전과 다른 거라는 거 느낌이 오죠.
여러분 그렇죠 그래요. 그래서 교과서에서 쓰는 실질적인 문제가 독일 예나에 있는 막스 플라플라크 예나 시에 있는 막스 플라크 여기서 하는 걸로 데이터 셋이 어떻게 생긴 거냐면은 수년간에 걸쳐서 이제 어 2009년 2016년 사이 걸로 온도 기하 습도 풍향 14개가 다 10분마다 기록되어 있는 거예요.
10분 10분이면 굉장히 다 주죠. 그쵸 그거는 이제 오픈해 놨기 때문에 이것만 가지고 해보려고 하는 거예요.

참석자 1 17:36
그래서 꼭 몇 개 14개가 있어요 14개 14 리트가 있고 여기서 이제 보면은 3 80점 넘어가면은 이제 이렇게 닫아가지고 하면은 지금 다 콤마로 되어 있나 보네요.
그래서 스플릿 시켜가지고 돼 있고 원래 라인지에 있던 것 중에서 1부터만 저장을 다시 라인지 하잖아요.
왜냐하면 맨 처음에 0에 들어 있는 게 헤더가 0에 들어 있고 그다음부터가 이제 라인즈 여기로 들어 있다는 거예요.
그래서 헤더만 찍어보면은 이런 게 있다는 거죠. 보면은 데이트 타입 p 이렇게 쭉 적혀 있죠.
이게 14개인데 이게 뭐냐 정체가 보면 이게 피가 이제 기압 같은 거네.
그렇죠 우리가 궁금해하는 온도는 어디 있나 온도가 디그리 c인가 보다.
템플러처인가 보다. 디 그쵸 바로 세 번째 있는 첫 번째가 데이트 타입이니까 몇 월 며칠 그렇죠 몇 년 몇 월 며칠 그게 있겠지.
일단 기압 기압이 중요하긴 한데 여기는 온도를 우리가 주로 많이 보니까 온도 이렇게 돼 있는 거죠.

참석자 1 18:40
그리고 그 뒤에도 여러 가지가 있는데 이거보다 우리는 일단 이것만 보려고 하는 거고 그리고 데이터가 우리 42만 551개나 된대요.
그래서 그래서 지금 이거를 실제로 이렇게 데이터가 있으면은 데이터 파싱을 시켜서 원래 여기서부터 원래 있는 데이터 중에서 이제 템퍼러처만 저장을 해야 되니까 원래 템퍼러처랑 이제 원래 템퍼러처랑 전체 데이터를 원래 여기 저기 382쪽에 나오는 거 햄프로치랑 로 데이터를 원래 제로로 만든 다음에 다시 데이터를 끼워넣으려고 하고 있어요.
전체 라인 개수만큼 아까 4만 얼마 42만 개를 하는 거고 그래서 이렇게 만들어 놓고 있는데 지금 이게 원래 이제 원래 데이터에 있는 것들로 이제 여기 콤마가 들어 있으니까 콤마를 세프로 시켜가지고 다시 넣어주고 있고 그리고 첫 번째 거는 제외시키는 게 데이타임 들어가 있으니까 제외시키는 거고 이렇게 아까 나온 대로 하고 있는 거예요.

참석자 1 19:49
그다음에 태프로처가 이제 데이타임 제외시키고 나면은 두 번째니까 그렇죠 1에 있는 걸 넣고 그렇죠 그다음에 나머지들을 전부 다 이제 로데이터라는 데 넣고 있는 거죠.
주 로 데이터라는 데 이해되죠? 여러분 뭐 하고 있는지 그래서 원래 로 데이터는 뭐가 들어 있는지 여러분 상당히 보여줄 필요가 있나 여기 여기 템플런체에는 그냥 온도들이 쭉 들어 있고 로 데이터에는 데이타임 없는 상태에서 모든 데이터를 아까 여기 요 데이터들 키 붙어 있잖아요.
값들이 딱 들어 있는데 한 행에 일일이 다 들어 있고 그다음 행에 다시 다음 데이터 들어 있고 이런 식으로 돼 있어요.
이해되죠? 그래서 그다음에 잠깐 그래프를 한번 온도를 본 건데 팩트 워처를 이제 한번 그림을 찍어봤어요.
그래서 이렇게 온도가 데이터가 이렇게 만 42만 개가 있으니까 이렇게 되고 온도가 이렇게 올라갔다 내려갔다 이러고 있는 게 보이죠.
그쵸? 이 10분마다 기록인데 이게 전체가 몇 년이죠?
그쵸?

참석자 1 21:06
몇 년간의 기록이니까 8년 동안이 하나 둘 셋 넷 다 8개 봉이 있죠 그쵸 8년에서 여름이 제일 높았겠지 그쵸 그쵸 하루 사이도 왔다 갔다 하고 있고 그렇죠 그런 걸 보여주고 있네.
그렇죠 이해되죠 여러분 뭘 보여주고 있는지 그래요.
이게 이제 1개월 데이터인 거지 이해되죠 10분마다 있는 거니까 그리고 이렇게 너무 많으니까 한 10일간만 좀 뽑아보자 그러면은 그다음에 이제 382쪽 아래쪽에 있는 게 10일이 10분마다 하루에 144개가 있어서 이거 굳이 계산을 이렇게 그냥 해서 넣었어요.
그쵸 해서 이렇게 10일 동안은 이렇게 실동안도 굉장히 막 드라마틱하네.
그렇죠 옛날에도 얘기를 했는데 운동 감동 지속 영화네 겨울인가 봐.
그렇죠 그래요. 섭시겠지 그래요. 아까 섭씨라는 표현이 있었나 c라는 게 있었나 보다.
여기 디그리 씨가 섭시겠지 그쵸 화씨 섭씨 있죠 여러분 고시 적혀 있네.

참석자 1 22:10
그렇게 된 거고 그래서 데이터에 이제 이렇게 주기성이 없는 데이터 주기성이 보통 항상 거의 있는 게 보이고 수요 데이터에서 주기성이 없다면은 이거는 사실 거의 이상한 거의 예측이 불가능한 거고 주기성이 어느 정도 있어야지 돼요.
그다음에 이걸 하기 위해서 뒤에서 찾아야 된다는 얘기를 해놓고 예측하는 걸 하려고 그러면 여러분이 더 하려고 그러면 여기 적혀 있지.
바로 여기 382쪽에 맨 마지막에 처음 50% 데이터를 훈련에 사용하고 다음을 검증 마지막 테스트에 사용하려고 하는데 여기서 중요한 게 우리 수율 예측할 때 검증 데이터랑 테스트 데이터가 오늘 데이터보다 더 최근의 데이터여야겠죠.
그쵸 거꾸로 하면 안 된다는 거죠. 그거를 조심해야 되는데 진짜 여러분 제가 막 의무심사 같은 데 가보라 이거 진짜 이렇게 안 와서 너무 많아서 재미있어요.

참석자 1 23:18
왜냐하면 이게 이렇게 하면은 잘 안 되거든 이렇게 안 해야 잘 되는 경향이 있어서 그러니까 여러분 주식 데이터를 하든지 아니면 강수량 예측하든지 아니면 강의 수위를 예측한다든지 이런 거 정말 시니어를 많이 하거든요.
데이터가 시간 많이 쌓여 있고 미래 어떻게 예측하는지 예측하는 거라서 데이터가 과거 데이터를 훈련해 쓰고 그거 갖고 미래 예측해야 되는 게 맞잖아요.
여러분 사실 우리가 예측할 때 하면 과거를 가지고 미래 예측할 수밖에 없잖아요.
실제 그렇잖아 그렇죠 그런데 이제 여러분이 이제 이런 일이 실제로 맡으면 이러지 않고 싶은 유혹에 빠지지 그렇지 않겠어요 왜냐면은 사제 딜레야 잘 되니까 그리고 심지어 여기 있는 거 막 섞어가지고 훈련시켜 그래놓고 잘 됐지 이 그런 게 여러분 하지 마세요.
여기서 그런 거는 절대로 실제로 쓰면 망연한 거예요.
그렇죠 잘될 수가 없어요. 실제 있는 거 갖고 했는데 여러분 유튜브에 그거 있잖아요.

참석자 1 24:10
맨날 신기하게 다 맞추는 거예요. 대통령이 누가 든지 맞추는 거 나중에 막 나오거든요.
올린 영상이 이번에 이제 대통령이 누가 됐는지 맞추는 사람이 있어.
이번에 6월 3일에 선거를 하는데 데이터를 대통령이 누가 냈다고 그거를 1년 전에 올리는데 만약에 지금 현대 우리 잘 모르잖아요.
환경현신 나씨가 나왔는지 환경 현대 대통령이 됐다는 걸 누가 올려놨어 그러면 그분이 대단한 사람이 되잖아요.
그걸 어떻게 하는 거냐면은 미리 이제 다 올려놓는 거예요.
10개를 그래놓고 다 이제 안 보이게 해놔요. 그러니까 비공개로 해놓지 올린 날짜는 남잖아요.
2년 전에 그냥 공개로 바꿔버리면 되지. 아니 근데 그런 연구 결과도 되게 많고 하여튼 간에 진짜 사기치는 사람이 너무 많아가지고 다 여러분 조심하시고 알겠죠.
함부로 어쨌든 이런 것도 이게 이게 살이 너무 많이 써서 사람들이 이렇게 해야 되는데 훈련을 사용할 때 검증이나 테스트에 사용할 거는 넣으면 안 되는데 많이 섞어서 넣어요.

참석자 1 25:08
그래도 그걸 거짓말하지 않았어 그래 거짓말하지 않았으니 다행이지 그쵸 근데 연구가 제대로 된 게 아니지 그렇죠 그래요.

참석자 1 25:21
그래요. 그다음에 어쨌든 시리어 데이터를 할 때 이해됐죠?
여러분 이거 시험에 낼 거예요. 아니면 여러분 그냥 막 누가 이거 실제로 막 이런 논문이 있는데 여기서 뭐가 이상한지 쓰라고 그러면 쓸 수 있어야 되는 거 알겠죠 실제로 보고도 여러분이 이걸 못 느끼면 곤란한 거예요.
알겠죠? 남들이 이렇게 하고 이거를 이 검증된 테스트했다.
훈련 된 터 최신이어야 된다는 걸 이거 어긴다 이거 안 된다고 알겠죠 2013년에 훈련 2013년에 열심히 훈련시켜놓고 2010년 걸 예측하겠다.
안 된다고 이거 잘했다. 이러면 안 된다고 알겠죠 여기 당연한 얘기죠.
여기 적혀 있죠. 미래에서 과거를 예측하는 게 아니라 여기 적혀 있었나 여기 다 적혀 있네.
미래에서 세 번째 줄 아래서 382쪽 미래에서 과거를 예측하는 것이 아니라 과거를 바탕으로 미래를 예측해야 되기 때문이에요.
알겠죠?

참석자 1 26:12
됐죠 그래서 지금 교과서 383쪽에 이제 그래서 샘플을 이제 숫자는 일단 전체에서 0.5로 트레인 샘플 0.25랑 밸리데이션 테스트에 또 나머지를 쓰기로 했고요.
그래서 이렇게 숫자를 적었어요. 그다음에 데이터를 이제 정규화를 하는데 383쪽에 나와 있죠.
정규화를 이렇게 해야 되는 이유가 뭐냐면은 여기 883쪽에 스계열의 스케일이 각각 다르죠.
여기 보면은 여기 위에 지금 데이터가 수치 여기 보면은 여기 원래 우리 쓰던 데이터들이 어떻게 생겨먹은 거였냐면은 이렇게 섭씨도 있고 그다음에 여기 다라는 기약이잖아요.
그렇죠 당연히 스케일이 다르잖아요. 그쵸 똑같이 하면 곤란하죠 그래요.
그래서 여기 풍속도 있네. 풍속 그쵸 메이브 같다요 풍속 그쵸 여기 전부 다 완전 완전 스케일이 다르잖아요.
그렇죠 이런 거를 다 자기들끼리 다 데이터별로 정규화시켜놓을 필요가 있겠죠.

참석자 1 27:23
평균 0에다가 분산 일로 그래서 정규화하는 게 지금 383쪽 아래에 나와 있지 로 데이터의 평균 그다음에 로 데이터의 민 평균이랑 분산 구해서 표준 편차 구해가지고 그래놓고 빼고 나누고 하는 거죠.
여기 그리고 이제 액시스가 여러분 이게 액시스를 0으로 해놨잖아요.
그쵸 액시스를 마이너스 1로 하면 어떻게 돼요? 여러분 엑시스가 이게 지금 몇 개가 있나 근데 엑시스가 액시스가 원래 이게 쉐입이 얼마였냐면 로데이터의 쉐입이 어떻게 되냐면 샘플 축이 가로고 그다음에 세로가 행열이잖아요.
그쵸 여기 아까 같이 행렬이에요. 사실 이렇게 매치를 지로 만들어놓고 쉬웠는데 행열이잖아요 그쵸 행이 샘플 개수고 그쵸 날짜 시간 계측성 날짜가 아니라 10분 단위 열이 그 데이터들이잖아요.

참석자 1 28:26
아까 맨 처음에 기압이랑 온도랑 관계있는 거 축이 디멘전이 2고 그쵸 축이 0 1 2개가 축이 0 1 2개지 그쵸 얘가 축이 0이고 배치 샘플 축이 0이고 원래 한 날짜 한 측정 데이터에 대해서 여러 값이 있는 게 1이지 그쵸 또는 마이너스 1이지 그쵸 내 말 알아요 여러분 다 알지 요 축은 요 축이 0 요 축이 1 알아요 그다음에 더 있으면 2 2 3 이렇게 되는 거지 그쵸 그리고 맨 오른쪽에 있는 거 그거를 1이라고 하든지 여기서는 아니면 마이너스 1도 되지 그쵸 알겠죠 그래서 지금 여기서 지금 뭘로 여러분이 어떤 거에 대해서 이 이야 이축인가 이축인가 우리가 평균하고 분산돼야 되는 게 각각 데이터 얘네들을 평균 분산 내면 안 되잖아요.
이거를 이거를 평균 분산 내면 안 되잖아요. 한 여기 얘네가 다른 샘플에 대해서도 해야 되잖아요.

참석자 1 29:26
그쵸 그러니까 축이 어떻게 돼야 돼 0이어야지 그쵸 액시스트 0에 대해서 축이 축이어야 돼 그쵸 샘플 축에 대해서 그렇죠 여기 이거 여기 0 그쵸 0이라고 셀프 축이야 이게 제일 앞에 거 알겠죠?
됐어요 시험에 낼게요 안 낼 수도 있지만 알겠죠 여러분 예 뭔 얘기 알겠죠?
이것도 샘플 축이 0 그다음 이렇게 하는 건데 마이너스 2로 해도 맞지 저거 0시 마이너스 2로 해도 돼.
마이너스 2 마이너스 2로 하는 건 좀 이상하긴 하다.
그치 그쵸 그치 이해되죠 여러분 보통 사람들이 0 1 마이너스 1 이런 거 많이 쓰지 그쵸 여기는 이제 0이 맞지 샘플 축이니까 그렇죠 왜 이렇게 하는지 알겠죠 여러분 우리가 여러분 의도를 다 알잖아요.
여러분도 어떻게 해야 되지 상식적으로 다 알잖아요.
근데 이걸 코드를 어떻게 해야 되는지도 알아야 될 거 아니야 그렇죠 그래요.

참석자 1 30:25
그리고 이제 우리가 뭐 하려고 그러냐면 오을 예측하려고 그러는데 과거 과거 5일 치 이거 이제 이거 이거를 그냥 이제 지금 데이터가 10분 단위로 저장이 되어 있는데 그래서 그래서 이제 우리가 뭐 하고 있냐면은 과거 oh 데이터와 24시간 뒤 타격 온도 여기 보면은 이 후로피스 세트로 넘어가 보세요.
884쪽 이렇게 그냥 바로 얘기하지 말고 이렇게 있네요.
885쪽에 뭐라고 적혀 있냐면은 실제로 10분 단위로 하는 거는 좀 너무한 것 같아가지고 시간당 하나로 좀 하는 게 좋겠다라는 생각이 들어가지고 여기 말고 요 책 이거 볼까요?
이거 여기 이거 볼래요? 여러분 385쪽이 바로 블릿으로 샘플 네이트 6 이런 거 좋겠죠 여러분 그렇죠 10분 단위인데 6으로 6배 하면 이제 1시간 단위가 되겠죠 그쵸 60분이 1시간이잖아요.
1시간 단위로 뭔가 하고 싶어 해요.

참석자 1 31:26
이제 실제로 데이터 쓸 때는 원래 로 데이터는 그렇게 10분 단위로 돼 있었는데 우리 이제 시간당 하나의 데이터 포인트만 써서 해보려고 해요.
너무 많아서 이해됐죠 여러분 그다음에 기존 5일간 데이터 120시간 5일이면 24 곱하면 120시간이잖아요.
120시간만 데이터 5일 거 보고 그다음 하루 뒤에 거 하루 뒤에 거를 예측하려고 해요.
알겠죠? 그런 거를 하고 싶어요. 이런 걸 하려고 그러면 이런 걸 하기 위해 도와주는 또 도구가 있으니까 이게 이제 왼쪽에 주황색 박스로 여기 지금 타임 시리즈 데이터 세프랑 어레이라는 게 384쪽에 주황색 값으로 타임 시리즈 데이터 스프랑 어레이라는 거 있죠 그쵸?
요거 요거 요거를 쓰는 거를 가르쳐주고 있어요. 교과서에서 보면은 예를 들어서 교과서에 지금 보면은 데이터가 이제 0 1 2 3 4 5 6이라는 게 있어요.
여러분 보이죠 여러분 데이터 012 3 4 5 6이라는 게 있어요.

참석자 1 32:28
예를 들어서 여기에 그런데 이거를 이제 시퀀스 랜스를 3으로 하고 전달하면은 이제 이거 시퀀스를 3으로 해버리면 얘를 이제 좀 쪼개가지고 0 1 2 1 2 3 2 3 4 이런 거 만들어줘요.
그 샘플을 3개씩만 시퀀스를 해서 3으로 해주면 그리고 우리가 이제 여기서 예측하고 싶은 거는 실제로 012가 들어가면 3을 예측하게 하려고 하는 거 도 1 2 3이 들어가면 3를 예측하게 하려고 하면 쉽잖아요.
그쵸 이해돼요. 여러분 예를 들어서 여기 보면은 385쪽 한번 볼래요?
385쪽 요거 385쪽에 이런 게 이렇게 여일리가 들어가면 3일 예측하고 1 2 3이 들어가면 4가 되고 이런 식으로 만들고 싶은 거 이렇게 데이터를 뭔가 우리가 변형하고 싶은 거예요.
이해돼요.

참석자 1 33:11
원래 시퀀스 데이터는 순전히 이거밖에 없었는데 0 1 2 3 4 5 6밖에 없었는데 우리 것도 지금 쫙 있는 것밖에 없잖아요.
근데 뭐 이렇게 딱 5일치 해가지고 바로 24시간 뒤 탁 예측하게 하고 이런 데이터를 만들려고 하는 거죠.
그쵸 그쵸? 그렇게 하기 위해서 어떻게 하느냐 이거를 아까 원래 이제 예를 들어서 지금 여기서 MP 점 어레이 레인지 하면 연구 2가지 연구 2가지 수가 나오고요.
지금 교과서 뒤에 있는 거예요. 지금 근데 이제 요거 요거 요거 캐라스 유티 타임 시리즈 데이터 프롬 파이스 데이터 스프롬 어드라는 거를 요요 INT 시퀀스 이거 있죠 여기 넣어줘서 만드는 건데 이거 넣을 때 어떻게 하고 싶냐면은 아까처럼 요거 요거 요거 요거 만들고 싶어가지고 일단 이거 이거 맨 마지막에 이제 하려고 그러면은 우리가 하고 싶은 의도가 뭐였냐면 마지막에 이제 요거 요까지 7까지 만들고 싶은 거잖아요.
그쵸 7까지 그러면은 987은 빼고 해야 되거든요.

참석자 1 34:12
9 8 7은 9 8 7을 빼야 되잖아 0부터 그쵸 9 8 7을 빼야 되는 9 8 7을 빼고 여기 c코스를 만들어야 되잖아요.
그쵸 그래가지고 마이너스 3 한 거예요. 3개 그쵸 마이너스 3 빼고 여기 데이터를 줬고요.
그쵸 데이터를 아까 0부터 6까지 준다고 했으니까 마이너스 3 9 8 7을 빼고 주려고 마이너스 3 해 준 거고 그다음에 이제 타겟은 이제 계속 이제 3개 3개씩 뺀 상태에서 3개 한 다음에 그다음 게 나오는 거니까 3 뒤에 나오게 되는 거고 이해됐죠?
여러분 그쵸 그리고 시퀀스 맥스를 샵으로 하기로 했고 그렇죠 아까 3개씩 3개씩 하기로 해서 그리고 배치를 두 개씩 뽑으라고 이제 배치 시 배치 사이즈를 2개를 줬어요.
이건 내부적으로 하는 거고 그렇게 하고 나면은 더미 데이터셋이라는 게 만들어지는데 더 미터 데이터셋이라는 게 만들어지고 이 더미 데이터셋에서 이제 우리가 인풋 타깃이 아까 얘기했던 대로 이렇게 딱딱딱 들어가는 거고 걔를 지금 찍어본 거예요.

참석자 1 35:14
인풋 타겟을 알아볼 수 있게 하려고 인풋의 셰일에 맞춰가지고 이렇게 프린트를 시킨 거예요.
아까 그래서 여기 여기 여기 찍은 게 프린트 해서 이게 어레이 하나죠 그쵸 인풋에 있는 거 하나씩 하나씩 인테저로 해서 이렇게 만들어 놓고 그다음에 타깃도 집게 만들어놨어요.
이렇게 해가지고 타겟이 하나밖에 없는데 그렇죠 그렇게 해서 나오는 게 이렇게 되는 건데 이런 식으로 할 수 있다는 걸 안 상태에서 우리도 이제 이 문제를 이 아까 온도 문제를 풀어봅시다.
여러분 이제 이제 온도 문제를 그래서 샘플 네이트 6 아까 얘기했잖아요.
그쵸? 이게 아까 그 파라미터랑 똑같이 만들어 놓은 거예요.
지금 샘플레이트라는 게 아까는 샘플레이트라는 거 없었죠.
아까 여기는 없었거든요. 없었어 없었는데 넣을 수 있다는 거예요.
이 착 나왔어요. 이건 또 갑자기 샘플 데이트도 있어요.

참석자 1 36:07
그래서 이거는 이렇게 요 프라이드도 주면은 아까 타임 시리즈 데이터 세트 워에 이것도 주면은 벙벙 뛰면서 여기서 6다 저스끼 바다 하나씩만 쓰는 게 된대요.
이렇게 하기 위해서 쓰는 방식이 그리고 변수를 그냥 아예 그냥 헷갈리지 않게 그냥 숫자를 쓰지 않고 이 변수 마을로 써요.
그렇죠 스틸레이트 시퀀스 젠스 120 5일치라고 120이라고 해놓은 거예요.
그다음에 딜레이는 딜레이는 이제 막판에 이제 나올 우리가 예측하는 걸 얼마나 더 예측할 거냐에 대해 했던 거기 때문에 시퀀스 랭스에서 24시간 뒤 거거든요.
그래서 24 더하기 24를 하는데 빼기를 하셔야지 진짜 24시간 뒤가 돼요.

참석자 1 36:50
여러분 시퀀스 레이스가 6인데 이거를 이거 헷갈리지 않게 하려고 그러면 여러분 이게 안 헷갈리게 하려면 요게 나는 이거 이렇게 하니까 너무 헷갈려가지고 여러분 실제로 이거 여기 있지 이거 어떻게 이해하면 좋냐면은 빼기 1이 앞에 있다고 생각해 봐요.
빼기 1이 시퀀스 센서에서 빼기 1을 해야지 데이터의 마지막 인덱스가 나오거든요.
인덱스가 0부터 시작하거든요. 인덱스 0부터 시작해가지고 빼기를 해줘야지 마지막 인덱스가 돼요.
마지막 인덱스가 돼요. 그래가지고 거기다가 더하기 24를 해주는 걸로 생각하시면 여러분 덜 헷갈리더라 나도 헷갈려가지고

참석자 1 37:35
그래요. 인덱스 0부터 시작하거든요. 그래서 어쨌든 이게 지금 원래 이거 보면은 이게 실제로 이 딜레이라는 거 어디서 쓰고 있냐면요.
여러분 딜레이 아까도 여기 딜레이가 여기 여기 들어가서 마이너스 3 3 썼잖아요.
그쵸 똑같은 게 들어가죠 그쵸 시작할 때 끝날 때 그쵸 이게 이게 3 하면 여기 인덱스 여기 첫 번째 거 배우세요.
이게 3이 이렇게 3개 빼는 거잖아요 앞에 그쵸 그래서 여기도 실제 코드 하는 거 보면은 원래 데이터에서 딜레이만큼 마이너스 딜레이만큼 제외시키기 시작하고 그다음 딜레이 이후에 것만 쓰거든요.

참석자 1 38:21
여기 요거 요거 딜레이가 이게 중요한 게 여러분 이게 내가 진짜 헷갈리는데 여러분 요거 요 딜레이 땡땡하잖아요.
그럼 이 딜레이 숫자 거는 안 들어가지 그다음부터 들어가죠.
3 땡땡하면은 3이 아니라 4부터 리스가 4인 것부터 들어가지.

참석자 1 38:46
원래 그래요. 그러게

참석자 4 38:49
시작 인덱스는 포함되고 급 인덱스는 포함 안 되어 있는 거

참석자 1 38:52
아닌가 근데 이게 이게 있어 봐야 돼. 맞다. 3이 맞는데 3이 맞네.
3이 맞는데 내가 잘못 말했나 잘했어요. 3이 맞는데 이 3이 사실은 두 번째 거다 그런 거였어요.
맞죠? 저기요. 이거 지금 56 56였어다. 3이 맞는데 두 번째 거야.
이 딜레이는 들어가는 이미 인덱스는 들어가는데 딜레이 빼기 1부터 들어가는구나.
실제로 몇 번째 인디스트 자체는 잠깐만 이 숫자가 3이잖아요.
숫자 3이면은 실제 인덱스가 3인 게 맞는데 데이터는 더하기 1이구먼.
시발려 다시 할게요. 여러분 원래 이 값보다 더하기 1이네.
왜 안 되지? 이 수도 시간 참 나이가 네 여러분 지금 엄청나게 헷갈리는 거 보이죠.
조심하세요. 여러분 여러분 이렇게 양을 잘하세요.
딜레이가 있는데 이 딜레이부터 들어가는 거 맞고 그리고 실제로 딜레이라고 적혀 있는 거는 딜레이 플러스 1번째부터구먼.

참석자 1 39:59
그래서 여기에 지금 백이라는 게 상세가 되는 거더라고 사실은 어쨌든 여러분 지금 내가 항상 지금 막 착착착 나오는 건 되게 위험한 거야 틀릴 수 있어요.
알겠죠 잘 검증하셔서 오픈 북으로 됐을 때 잘 맞춰서 하세요.
여러분 알겠죠 그래요

참석자 4 40:15
근데 이 함수는 예측값 하나만 받을 수 있는 거죠. 타임 시리즈를 제공받을 거

참석자 1 40:22
예측 값 하나 출력 값이 저는 하나만 나오는 거예요.
그렇게 하는 게 아 그렇게 하는 거 는 아니잖아요 여기 지금 여러 개 나오네.
그쵸 이게 지금 타겟이 하면은 타겟 질은 여러 개가 들어가는 건가 지금 타겟 자체는 그렇죠 근데 타겟 쉐입하니까 그냥 한 개만 나오네

참석자 1 40:55
하나만 예측하는 거 맞네. 그러니까 그것도 중요한 포인트네.
타겟즈는 값 하나만 예측하는 거네. 그쵸 실제로는 여러 개가 나올 텐데 이렇게 해서 로 데이터와 타겟 로데이터가 아니라 이게 원래 데이터 자체고 타겟 자체가 이제 이런 게 여러 개로 시리즈가 나올 텐데

참석자 1 41:24
아니 이거 자체는 여러 개가 나오는 거죠. 여러 개 나오는 건데 이거를 이제 우리가 어떻게 쓰느냐의 문제거든.
사실은 이게 나중에 만들어내면은 우리가 뽑을 때 이런 식으로 뽑아내니까 이렇게 뽑아내니까 하나씩 하나씩 이제 여기서 이렇게 콜 인프츠 하면서 이렇게 뽑아내면 하나씩 하나씩 튀어나오면서 여러 개 쓸 수 있는 거니까 사실 들어 있기 자체는 쫙 들어가 있는데 우리가 쓸 때 이렇게 하나씩 하나씩 뽑아낼 수 있게끔 쓸 수 있는 거네요.
그렇죠

참석자 4 41:54
근데 이게 인풋에 대한 타깃은 무조건 하나씩 나오는 거 아니에요 그러니까 월요일 화요일 수요일에 날씨 정보를 넣으면 목요일에 날씨 정보만 나오고 그 뒤에 거는 아예 안 나오고 하나만 나오는 거

참석자 1 42:09
지금 여기서는 그렇게 하는 게 아니라 그냥 왕창 다 넣은 거 같은데 왕창 다 넣은 거 아니에요 여기는 딜레이 뒤에 거

참석자 4 42:21
실제로는 로 데이터에 대한 타깃은 하나씩만 이라는 거지

참석자 1 42:30
그건 맞아요. 로이스에 대한 데이터 하나씩만 증세해요.
여기 숫자가 얘랑 얘랑 저 결과 똑같이 원래 이제 나오는 게 여기 이제 항상 이게 데이터 두 개로 쭉쭉 뭔가 뭔가 데이터가 두 개로 인풋이랑 타겟이랑 두 개로 나오게 돼 있잖아요.
인플의 타겟이랑 이제 요 타임 시리즈 데이터 세프로 어레이를 하고 나면은 두 개로 저장이 되게 되는데 여기 이게 인풋으로 들어가는 게 얘가 들어가게 되지 그쵸 여기서 되는 거 여기서 샘플링 해가지고 이 시퀀스 랜스만큼 들어가는 거 그쵸 익스 센스마크 여기 들어가고 쌍으로 들어가는 거죠.
그쵸 그리고 여기 타깃에 해당하는 게 여기 들어가는 거지 그쵸 그쵸 타겟에 해당하는 게 들어가지 그래서 근데 이제 이게 배치라는 거지 배치 배치라서 결국은 이제 25 여기 개수랑 여기 개수랑 맞게 되면서 하나씩 여기 여기 여기에 있는 여기에 여기에 얘도 여러 개 배치로 져 있고 여기도 여러 개 배치로 이루어져 있어가지고 하나씩 하나씩 빼가지고 쓰게 돼 있어요.

참석자 1 43:41
이게 무슨 얘기냐면은 여기가 실제로 데이터 자체는 이게 무슨 얘기냐면은 여기에 데이터 뽑아내는 게 이렇게 한 덩어리 이렇게 한 덩어리 들어 있거든요.
수입 자체는 그런데 이제 이렇게 뽑아서 쓰라는 거지 그래서 실제 이거 봅시다.
이거 봅시다 봅시다. 여러분 이 3386쪽 볼까요?
380쪽 181쪽에 결과가 나와 있는데 여기 이렇게 해가지고 나오는데 아까 트레인 데이터스 방금 만든 거 있잖아요.
지금 방금 제가 버벅거리고 있는 485쪽에 모 데이터 타겟 해가지고 나온 거 있죠 그거 파일이 보이죠.
여러분 885쪽에서 로데이터 타겟 해가지고 나온 거 걔가 이거잖아요.
그쵸 트렌드 데이터 셋이잖아요. 뭐 하고 있는지 알겠어요 여러분 요거 요거 요거 요거 요거 프렌디트 사이스를 지금 하고 있는 거잖아요.
그쵸 알겠죠 그쵸 요거 요거 한 거에서 결과 나온 거가 이거 이거 예지 얘 얘를 이렇게 두 덩어리 뽑을 수가 있고 샘플링 타겟이 아까 인풋 즈 타겟 이렇게 됐죠.

참석자 1 44:46
그쵸 주황색 박스에서는 걔가 수입이 어떻게 생겼냐 그러면 수입이 256 여기도 256 똑같은 수익이 실제 나중에 쓸 때는 그게 여기 256인데 이 하나가 이렇게 120 1 4개씩 들어 있어요.
여기는 120 14개씩 들어있는데 아까는 그냥 덜렁 3개씩만 들어 있었잖아요.
아까 이 주황색 박스에서는 여기는 120 14개 들어 있는데 120이 5일치 데이터 120이 5일치 데이터 맞지 5일치 데이터 이거 14가 또 14개씩 아까 각 들이 이렇게 들어가 있는 거죠.
그게 256기가 들어 있는 거지 그래서 여기 요거 요거랑 요거 256p 하나랑 쓰는 거지 나중에 그렇죠 다 뽑아가지고 그래요.
그렇게 쓴다는 거지.

참석자 1 45:45
그다음에 이게 여기 할 때 좀 약간 아까 이거 설명 덜한 게 있는데 배치 사이즈가 256개인데 배치 사이즈가 배치 사이즈가 256개라서 256개 좁아진 거고 아까 아까 여기는 별로 광고가 안 됐는데 여기 어쨌든 나는 내가 지금 이게 좀 덜 했네.
여기도 배치 사이즈 왔다 갔다 해서 미안해요. 여러분 여기 배치 사이즈가 요 앞에 선을 배치 사이즈가 2였죠 그쵸 2였죠 여기는 설명 안 했잖아요.
이거 내가 그쵸 이였다는 설명 안 했죠 그쵸 그래서 사실은 이게 이게 그냥 나오는 게 아니라 이렇게 두 개씩 또 한 개로 묶여 있었어요.
사실은 아까 2개씩 두개씩 배치라는 게 여러분 한꺼번에 튀어나오는 놈이거든요.
샘플링 할 때 이렇게 한 번 튀어나오고 거기서 또 안에서 들어온 거고 이렇게 한번 튀어나올 수도 하면 손도 들고 이렇게 튀어나오고 그랬었어요.
그런데 80년대까지 하는 거고 그래서 여기도 지금 전체가 256개 나온 것도 배치 사이즈 256으로 해가지고 그랬어요.
알겠죠?

참석자 1 46:57
여러분 나도 지금 공부해서 하는 건데 좀 잘 안 써봐가지고 잘 몰라서 그래 알겠죠 일단은 보고 따라서 할 수 있게끔 하면서 이상한 거 있으면 물어보세요.
여러분 그래서 매치 사이즈 256개로 해서 뽑았기 때문에 256개가 튀어나온 거야 다음에 브레이크 해야죠.
그쵸 다음에 몇 개인지 또 256개 튀어나오겠죠 그렇죠 마지막에는 이제 못 자르는 만큼 하고 그렇죠 여러분의 스텝 같은 거지 포에서 스텝 그쵸?
뭔 말인지 알겠죠? 그래요 그래가지고 다 설명했나 그리고 드도 있지 여기 배치 사이즈도 설명했었고 다 했나 배치 사이즈도 있었고 여기 셔플이 또 트루도 있잖아요.
셔플 트루 커플로 트는 데이터를 또 섞는 거예요. 원래 이게 순서대로 있잖아요.
시간이 근데 그거를 또 굳이 섞어요. 나중에 배치를 만들 때 이 트레이트 만들 때 원래 이제 날 순차적으로 있었잖아요.

참석자 1 47:49
날짜들이 그러니까 여기 이걸 셔프로 트로로 해버리면은 이거 다음에 이게 들어 있고 이거 다음에 이게 나오고 이런 식으로 막 섞여요.
원래 예측할 때 이것만 갖고 이걸 예측하게 하고 이것만 갖고 예측하게 하는 건데 순서대로 놔두지 않는다는 거지 셔프를 2로 하면 데이터를 골고루 섞어요.
대체 이거 자체를 넣는 건 아니고 영인이 다음에 3 나오는 걸 넣는 건 아닌데 개 자체를 섞이려고 한다고 알겠죠 모르겠어 이게 원래 이거 다음에 이거 나왔잖아요.
이제 첫 플리 하면은 맨 처음에 이게 나오고 1번 이게 들어 있고 2번은 이게 들어 있고 그다음에 3번에 이게 들어 있고 막 이런 식으로 된다는 거 그렇게 해서 왜냐하면 이게 예측하는 게 0인만 갖고 3을 예측하게 하려고 그러고 1 2 3만 갖고 3 예측하려고 하게 하려고 그러고 이런 거거든요.
원래 이런 거라 생각 그래서 순서를 섞어버린다고 골고루 그렇게 하기 위해서 샤프로 2 이런 거 준 거예요.
알겠죠?

참석자 1 48:47
그래요 다 했나 그 스타트 인덱스를 0으로 했고 스타트 인덱스는 원래 데이터에서 그리고 로 데이터에서 뽑는 데이터의 인덱스를 0부터 시작하겠다 이렇게 한 거였고 그다음에는 스타트 인덱스가 넘버 러브 트레인 샘플로 돼 있지.
밸리데이션 트레인 샘플 끝난 다음부터 하고 여기는 스타트 인덱스가 밸리데이션 트레인 다 한 다음에 하는 거지 나머지는 똑같죠.
그런 식으로 해서 이제 데이터를 뽑을 때 미래 거 뽑기 하는 거 이런 식으로 해서 하면 된다는 거예요.
알겠죠 이런 식으로 해서 실제로 여러분이 써 먹으라 하는 거지 시계 같은 거 할 때 뭐 어떻게 쓰는지 알겠죠 그쵸?
그리고 셔플 하는 게 훨씬 훈련이 잘 돼요. 순서대로 두는 것보다 셔플은 이 안에서만 셔플 하는 거지 여기를 넘어가지 않는다는 거지 이 안에서 딜레이 여기 요구되는 데까지 원래 해당하는 데이터까지만 셔플링 하는 거지.
여기 테스트가 밸리데이션 여기 트레인 밸리데이션 이 안에서만 서플링 하는 거지 각도를 벗어나지는 않아요.

참석자 1 49:52
그런 것도 다 정해져 있는 거죠. 그래서 시기열 데이터를 먼저 만드는 작업을 했어요.
그렇죠 처음해 보는 거잖아요. 이것도 그렇죠 그래요.
그래서 이거는 좀 약간 헷갈리죠. 여보세요. 그럼 일단 10분 쉬었다 할게요.
여러분.


clovanote.naver.com
딥러닝 day21_2
2025.05.28 수 오전 11:02 ・ 48분 29초
심승환


참석자 1 00:00
이거 일단 여기 원래 파라미터 이름이 다 나오는데 원래 파라미터가 여기는 그냥 데이터 데이터 있을 거를 넣는 거고 여기가 이제 타겟으로 만들 거를 넣는 거잖아요.
원래 소스가 되는 거. 그쵸. 근데 여기에서 넣을 때 항상 이렇게 식별 데이터 학습시키는 거는 이렇게 뒷부분을 빼고 그리고 또 이 앞부분을 빼고 이렇게 넣잖아요.
그렇죠 예측하는 거니까 앞부분을 날리는 거 그다음에 여기 또 소스 하는 것 중에서는 마지막 부분을 또 빼야 되니까 앞부분은 뒷부분은 빼야 되니까 뒷부분 날리는 거 앞부분 날리는 거잖아요.
그쵸 여기 두 개가 서로 맞아야 되잖아요. 개수가 맞잖아요.
그렇죠 항상 그렇죠 여기 쓰는 딜레이라서 이게 인덱스로 쓰는 거잖아요.
인덱스로 그래서 여기 아까 내가 이거 막 풀 했는데 여기 딜레이가 여기 데이터부터는 쓰는 거고 여기 데이터를 날리는 거잖아요.

참석자 1 00:59
그쵸 그래서 그래서 여기 인덱스 어쨌든 둘 다 인덱스거든 쓰는 건데 여기 원래 여기 데이터는 그대로 쓰는 거의 데이터를 기준으로 하면 여기 데이터가 여기 이렇게 스트라인 돼 있어 그랬잖아요.
그렇죠 우리 디스를 그대로 쓰는 거잖아요. 그쵸 맞아 맞죠?
내가 안 틀렸죠 그쵸 타겟이 이제 예측할 값이 여기서부터 시작하는 거잖아 여기서부터 시작하는 거죠.
그치 예측하는 값이 이건 진짜 내 진짜 값이잖아 여기는 이거에 맞추는 거라고 생각하시라고 지금 저도 여러분 안 헷갈리려고 발악을 하는 중이에요.
너무 헷갈려서 아시겠죠? 이거 두 개 똑같아요. 그렇죠 하나는 마이너스고 하나는 그냥 쓰는데 이게 이거야 이렇게 딜레이 땡땡으로 돼 있는 이 로고는 인덱스 그대로 쓰는 거라고 여기서부터 이제 예측하는 거라고 맞죠?

참석자 1 01:57
그래서 그게 딜레이가 지금 우리가 예측하는 값이 어디서 시작하느냐 어디서 인덱스가 시작하느냐의 문제인데 원래 시퀀스 넥스에서 24 더해서 샘플레이트 곱하는 것만큼 하는 건데 실제 인덱스가 0부터 시작하니까 그냥 빼기를 한다고 생각하시면 될 것 같아요.
EBS 0으로 시작하니까 EBS 0으로 시작해서

참석자 1 02:24
그러면 만들어진 모델에 대한

참석자 2 02:29
프리딕션만 진행하는 거고요. 이미 학습은 다 끝난 거고

참석자 1 02:35
학습이 아니야 학습 아직 안 시키고 학습할 거 만들어 놓은 상태인데 학습할 거 지금 준비하는 상태예요.
학습시킬 데이터를 준비하는 거예요. 지금 아직 학습 안 시켰어요.

참석자 2 02:45
이 함수는 그러면 그냥

참석자 1 02:47
이 함수는 완전히 그냥 우리가 이거 얘도 지금 계속 우리 슈퍼바이즈드 러닝만 하고 있어요.
그쵸 슈퍼바이즈드 러닝만 해요. 우리는 계속 그래서 학습시킨 데이터를 만지작거리고 있는 중이야.
그러니까 뭐를 가지고 올 예측하라고 하려고 하는 거잖아요.
옛날에는 그림 갖고 이게 레일 붙이고 이러는 거였잖아요.
그쵸 지금은 그런 게 아니라 수개월인데 20개월 가지고 이걸 지켜라 이런 거잖아요.
오히려 내가 아까 5 1 치라 그랬는데 이거를 oh라고 불러서 필기해놓고 이게 뭐냐고 물어가지고 웃겼는데 oh 5일치 이게 진짜 아까 그 오디오 스크립트 만드는 거 재밌는데 그거 진짜 희한하게 나올 때가 있어.
스크립트 만들면 어쨌든 5일 치 5일치 데이터 있잖아요.
5일치 데이터를 가지고 그쵸. 근데 5일치 데이터인데 10분 단위가 아니라 1시간 단위로 돼 있는 거 가지고 이제 24시간 미리 예측하는 데이터를 만지작거려야 되는 거예요.

참석자 1 03:51
우리가 그러니까 정답 값을 저장하는 거랑 정답 값이랑 그다음에 트레인 데이트 입력 값이 항상 이게 우리가 두 가지가 있는데 항상 이게 트레인 데이터가 두 세트죠.
근데 입력 데이터랑 타겟이랑 그랬었어. 원래 그렇죠 그랬었어요.
여러분 옛날에 이미지들 앱 리스트 이미지 28 곱하기 28 이미지랑 그다음에 라인 레이블 이런 식으로 얘도 마찬가지예요.
그 시리즈로 된 시리즈인데 여기는 지금 온도뿐만 아니라 몸 밖에 다 14개 14가지나 있죠.
그쵸 14가지 데이터들이 쭉 있잖아요. 그쵸 14가지 데이터 가지고 14가지 데이터 이게 14가지 데이터가 이렇게 있는 거야 이런 식으로 여기서 이제 이렇게 생긴 게 아니라 14개가 있는 거야.
14개 이게 14개 여기는 3개 알겠죠 그리고 여기 온도 24시간 뒤에 온도 14개 데이터가 아까 14개 데이터 곱하기 미안해요.
14개 데이터 곱하기 5일 5일치 5일치 그죠?

참석자 1 05:01
14개 데이터가 5일 치 있어야 돼 그렇죠 너무 헷갈리 처음 하는 거예요.
처음 하는 패턴이에요. 여러분 그렇죠 14개 데이터가 5일 치인데 5일치는 여러분 한 120개 포인트 한 하루 하루는 일은 1일 1일이니까 1일은 1일은 120개가 아니지 21일은 24개고 아니면 1일은 24개 5일은 120개 되시겠죠 알겠죠?
여러분 120개 14개가 120개 있는 걸 가지고 숫자를 타 됐어요.

참석자 2 05:38
그러면 지금 하는 과정이 케이 폴드 할 때처럼 케이 폴드 케이 폴드 할 때 전처리할 때 앞에 쪼개잖아요.
구간별로 데이터들이 그것처럼 트레인

참석자 1 05:50
케이 폴드 할 때 쪼개는 거 아니야 그건 아니에요. 거기서는 순전히 검증 데이터랑 저기 트레인 데이터 있잖아요.
걔를 막 여러 가지로 나눠보는 거 있잖아요. 얘는 그런 건 아니고 또 얘는 정말 다른 게 식이요 하는 거니까 뭐 같다고 느끼는 것도 뭔지는 알겠네.
트렌 데이터 마사지 하는 것 때문에 그렇죠 그런 거랑은 좀 다르죠.
왜냐하면 여기는 지금 미래가 예측하려니까 또 또 원래 전체 데이터가 이렇게 전체 데이터가 쫙 있었는데 여기서 이만큼 이게 이게 과거 과거에 있어 과거 데이터에서 이만큼 50%는 이제 이미 정해졌잖아.
딱 여기 여기는 트레인 데이터를 쓰고 여기는 검증 데이터 여기는 테스트 데이터를 쓰기로 했고 여기 중에 여기 여기 각각의 전부 다 이렇게 마사지 해야 되는 거예요.
케이코드랑은 다르지 그쵸 p 코드는 위에다가 이렇게 했다가 또 이것도 이쪽으로 갔다가 이쪽으로 갔다가 막 이러는 거잖아.
그렇죠 그거랑은 다르지 그쵸.

참석자 1 06:48
여기는 아예 원래 시계열이 쫙 있는데 시계열이 쫙 있는데 얘를 조작을 하는 거야 이거 다음에 요거 요거 다음 그렇죠 이런 식으로 이거 갖고 이거 예측해 봐 이러는 거잖아요.
그쵸 다르지 달라요. 엄청 달라 그래요. 처음 보는 거 맞고 여러분이 처음 보는 거 맞아요.
이거 이런 시열 데이터가 세상에 많거든요. 지금은 데이터가 이런 게 많아서 수요 데이터가 예를 들어서 트래픽도 그렇고 자동차의 센서 데이터들도 너무 많고 이게 이런 정도로 가다 보면 나중에 고장이 나지 이런 것도 많고 그렇죠 그리고 오디오 데이터 이런 것도 되게 많아가지고 또 고장나는 거 다 이런 것들은 오디오 데이터 같은 것도 다 이제 시계 연류로 바꿀 수가 있기 때문에 굉장히 은근히 많이 문제가 많죠.
이런 문제도 우리가 안 보던 문제들이죠. 그래요.

참석자 1 07:44
그래서 이제 이렇게 데이터는 이제 우리가 훈련에 사용한 데이터들을 훈련과 검증과 테스트에 사용한 데이터들을 만들어놓은 상태고 참고하시면 이쪽이고 그다음에 이제 387쪽부터 이제 이거 갖고 이제 우리가 정말 이제 머신러닝 딥러닝을 해보려고 하는 거예요.
그렇죠 그래서 첫 번째 이제 할 때 이제 우리가 이 문제 이런 문제 처음 다루니까 또 베이스라인에 대해서 베이스라인 항상 우리가 먼저 도대체 잘한다 그러면 얼마 정도 어느 정도 일 잘하는 거냐 이거에 대해서 이해를 깊게 할 필요가 있죠.
옛날에 그 확률형 얘기하듯이 그렇죠 12년 3 18 9 중에 예측하려고 그러면 여기부터 10분의 1 이상의 확률이로 맞아야 되는 거고 그렇죠 그리고 만약에 특정 데이터가 많다 그러면 그 데이터의 퍼센트별로 이상은 맞춰야 되는 거고 그렇죠 가야보를 하면은 30% 넘게 맞춰야 되는 거 아니야 그치 최소한 같이 하라 그러면 그래요.

참석자 1 08:37
그래서 여기 똑같은 얘기 나와 있고 그래서 지금은 해 수준으로 아무것도 모르고 할 때는 그냥 현재로부터 24시간 후에 온도를 예측하려고 하는 건데 그렇죠 우리 항상 그렇죠 근데 과거 지금이 이제 지금으로부터 과거 5일치 5일치의 데이터가 있는 상황이에요.
그쵸 그쵸 그 상황에서 24시간의 온도는 그냥 심플하게 현재 오토와 온도와 같다 이렇게 해버리면 제일 심플하잖아요.
이거보단 잘해야 되겠지 그쵸 이 정도 이렇게 똑같은 거랑보다는 더 잘 맞춰야 되겠다 이런 기준점을 세울 수 있다는 거예요.
그래서 그렇게 한 다음에 이제 오차는 절대값 오차로 하기로 했대요.
교과서에서 그래요. 그래서 만약에 이런 그냥 이렇게 24시간의 온도를 지금과 동일하다고 예측했을 때 MA가 어떻게 나오는지 한번 해본 거예요.

참석자 1 09:38
그렇게 맞췄을 때 얼마큼 나오나 한번 해보려고 지금 교과서에서 이게 387쪽에서 이벨류에드 나이오 메시 나이보드 이브 나이오 메시지 해봤는데 프레이션을 그냥 프레션이 원래 원래 샘플에 샘플이랑 데이터셋이 지금 밸리션 데이터셋이랑 테스트 데이터셋에 돈 갖고 하려고 하는 거거든요.
여러분 지금 사실 개에 있는 거 갖고 하는 거잖아요.
그쵸 데이터셋에 원래 샘플 타겟 이거 우리 나왔잖아요.
그렇죠 이미 만들어 놓은 거죠. 거기에서 프릭션을 원래 이제 있는 샘플이 제일 마지막 가 있지 제일 마지막 과 제일 마지막 값으로 한 거예요.
제일 마지막 값이 지금 제일 마지막 값이 이게 1인 거는 온도 값이 두 번 인덱스가 1이거든요.
아까 이 기억나죠 여러분 압력이 제일 먼저 이게 EDS 1이라서 여기 됐고요.
제일 마지막 거 한 거예요.

참석자 1 10:49
알겠죠 그쵸 그래서 그리고 전부 다 다른 거 앞에 거는 샘플로 전부 다 해가지고 샘플 전부 다 해가지고 여기다가 이제 재미있는 건 이제 우리가 이제 우리 예측기 만들 때 계속 이제 우리 데이터 전부 다 저장을 해놨어요.
이미 벌써 스탠러드랑 민 이거 해놨잖아요. 그쵸 그래서 이거 STD랑 민값 이거 아까 구해놓은 거 있죠?
갖고 한 거예요. 여기 아까 구했거든요. 이거 이게 지금 혼자 들어가는 게 아니라 STD랑 민값을 여기 앞에 383쪽에서 보냈었어요.
그쵸 그쵸 거기에 이제 일이 이제 온도가 그렇죠 0이면 이제 그 압력 이면 이런 식으로 했죠.
걔 거 갖고 온 거예요. 알겠어요 여러분 이거예요.
뭐 하는지 알겠죠 그다음에 이 토탈 에러봐 포털 엑셀루트 에러는 프렉션 요 프릿을 우리가 계산한 거랑 타겟을 타겟이 원래 우리가 나오잖아요.
여기 그쵸 뺀 거로 해서 해갖고 그냥 샘플 샘플 개수를 여기다가 저장해 놔서 나중에 이제 에러를 평균 낸 거죠.

참석자 1 12:01
그래서 해봤더니 얼마 나왔냐 여기 이거 뭐 하는지 알겠죠 여러분 좀 조심할 게 우리가 노갈레이지서 쓰면은 데이터 자체를 우리가 노멀라이즈 써가지고 학습시키면은 나중에 예측하고 할 때도 항상 노멀레이션 다시 시켜야 돼요.
그렇죠 그럼 여기 노멀라이제이션을 시키는 게 아니라 잘못했다.
노멀라이제이션을 원복을 시켜야 되는 거야. 원복을 여기 곱하기 하고 더하기 했으니까 원복을 시키죠.
원복 원복 원래대로 만들었어. 그렇죠 원복을 원래대로 복구시킨 거야.
그렇죠 원래대로 복구시켰어요. 아니 그래야지 비교 당연히 원래 값이랑 비교할 거 아니야 그렇죠 원래 데이터는 그냥 온도가 들어 있으니까 원래 값을 만들려고 하지 이렇게 했어요.
그렇죠 조심하라는 거지. 그렇죠 지금 데이터가 지금 막 변형돼 들어가 있잖아요.
그쵸 타깃 데이터는 변형을 안 시켰나 안 시켰나 보지 로 데이터에 변형을 시켰고 타겟은 그 그래 이게 이게 헷갈리는 거다.

참석자 1 13:05
진짜 타깃은 번영을 안 시켰고 하겟은 로 데이터가 아니었나 미안해요.

참석자 1 13:16
그랬네. 미안해요. 여러분 아까 좋은 처브이트였네.
여기 내가 놓친 게 설명 안 한 게 있었네. 여기 아까 만들 때 템플러처로만 해놨어요.
여기 템프로처 그쵸 아까 이거 물었구먼 이예준이 맞아요.
네. 맞습니다. 진짜 내가 이걸 설명 안 했어 여기 이거 이거 데이터 템플러스만 더 넣어놨네.
그쵸 이거 이거에 대한 거네. 여기가 같은 로 데이터가 아니라 템플러스만 넣었잖아.
그쵸 그렇죠 그랬어요. 잘했어요. 여기 로데이터 안 썼어 그 얘기인 것이요.
그 얘기에서 그렇기 때문에 지금 내가 여기 이렇게 지금 다시 원복을 시켜야 되는 거예요.
그렇죠 캠프 워처를 거기도 로데이터 그대로 썼으면 사실 저장 안 해도 되는데 근데 알아보기 힘들겠죠 여러분 그렇죠 그랬어요.
여러분 알겠어요. 타겟은 또 우리가 예측하는 값을 원래 온도로 예측하려고 하네.

참석자 1 14:13
로 데이터로 안 나오게 하고 입력 몇 대는 항상 이렇게 조작을 해야 되고 민 평균 그거는 민이랑 그거는 또 이제 우리가 여기서 쓰는 걸로 그쵸 트레인 걸로 해야 돼요.
그렇죠 밸리데이션이랑 저쪽에서 다시 쓰면 안 된다는 거 알죠?
여러분 그렇죠 밸리데이션 테스트 쪽에서 다시 계산하면 안 되고.
그쵸 그래요. 그런 걸로 봤었구나. 캠프러치를 적어 이게 중요하다고 중요하다고 적어놓고 내가 그거 설명 안 했네.
그래서 이런 거를 한 거지 됐죠. 너무 시간 많이 걸렸네.
지금 이거 왜 여러분 다 뭐 하는 건지 알겠죠? 여러분 이상한 거 있으면 질문하세요.
그래서 그다음에 그래서 생각들이 그게 궁금하네.
어떻게 나오는지 이렇게만 무식하게 해도 어떻게 나오나 그랬더니 2.44도 2.62도 밖에 안 틀린대.
현재 온도로 그냥 내일 온도 하면은 보통 틀린 게 2.44도나 2.62도밖에 안 틀리대요.
그쵸 플러스 마이너스 순정 되나 보네.

참석자 1 15:16
그렇죠 대충 2.5도 정도라고 했네. 그래서 근데 이든 어쨌든 이러면은 이거보다 잘해야 되는 2.5도보다는 좀 작아야 되는 거라서 제가 작은 예측기를 만들어야 된다는 거죠.
그쵸 이해되죠 기준점이 생겼어요. 그렇죠

참석자 1 15:38
그다음에 내일 온도 내일 온도는 어떠냐 그러면 오늘 온도대로 얘기하는 거지 그래도 그 정도는 안 풀린다는 거죠.
그쵸 대충 보통 평균이니까 사실은 그래서 이제 기본적인 머신러닝으로 뭘 했냐면은 댄스만 그냥 해보는 걸로 여기 보면은 MLP죠 MLP 488쪽 에스리퍼렌스 네트워크 하는 건데 그냥 여기에 인풋을

참석자 1 16:08
시퀀스 램스가 아까 10 120이었나 이게 120이 120 그죠 120개의 데이터가 행으로 있고 로 데이터 얘가 이제 14개지 아마도 그렇죠 있는 걸로 입력을 주는 거예요.
인풋이 그리고 얘를 이제 일단 원래 베스트에서 주입하려고 그러면 플래트 시켜야 되죠 여러분 그쵸 플래튼이 이제 쫙 펼치는 거지 120 곱하기 24로 쫙 펼치고 그다음에 댄스 이거 이거 그냥 뭐 하나만 하네 하나만 해서 렐로 해가지고 댄스 1 하면 이거 뭐 거의 딥러닝도 아니고 그냥 쉘로우 러닝으로 그렇죠 16개만 해 16개 하는 것도 그냥 보 16개로 되게 얇게 해봤어요.
잘 못하고 아주 그냥 해가지고 보통 이제 할 때 마르시 포트 할 때는 세이베스토니 항상 하시고요.
여러분 그다음에 이제 데이터셋 넣을 때 프레임 데이터셋을 바로 그냥 줘버려서 이렇게 줄 수가 있어요.
옛날에 여러분 줄 때 트레인 데이터셋에서 보통 가로하고 이제 원래 트레인 입력이랑 이미지랑 그다음에 우리 라이브 같이 썼잖아요.

참석자 1 17:21
그쵸 근데 여기 그냥 같이 지금 이미 돼 있으니까 같이 질 수 있는 거예요.
이렇게 이해돼요. 얼마 옛날에는 두 개 같이 썼잖아요.
따로따로 따로 품만큼만 줬었는데 아닌가 아니었나 어디 가서 볼까요?
여러분 옛날에 피트 할 때 보면 그랬었던 것 같은데 트윈 이미지 트윈 레이블 중 여러분 예를 들어서 263쪽 같은 거 보면은 223쪽 대충 263쪽 223쪽 한번 봐봐요.
223쪽에 마델즈 PC 중간에 떡 칸이 있는데 그러면 트레인 이미지즈 트인 레이블도 이렇게 따로따로 있잖아.
263쪽에 그쵸 여기 안 보여 여기 없어. 보통 223쪽 같은 데 보면은 여기 이렇게 여기가 트레인 이미지즈 트레인 레이블 즈 이 두 개 따로따로 줬잖아.
이렇게 두 개 포함해서 레이블이 원래 입력 데이터 그다음에 네이버 이미지가 입력돼 있다.

참석자 1 18:17
그다음에 얘가 이제 타겟 값으로 이렇게 같이 따로따로 줬는데 여기 이거 하나로 지금 훔쳤다고 왜냐하면 여기 다 들어 있어서 두 개의 파라미터를 얘가 하나로 그냥 끝내버렸어요.
그렇죠 여기 사실 두 개가 들어 있거든 트레인 이미지 트레인 레이블에 해당하는 게 들어 있다고 왜냐하면 여기는 알겠죠.
무슨 얘기인지 그래요 이렇게 하는 거 처음이잖아요.
세인 데이터 셋 자체에 다 들어 있어요. 그렇죠 데이터셋이라는 걸 여러분이 사실 옛날에 우리가 TFDS에 m 리스트 이미지도 다 있는 거였는데 사실은 엠리스트도 사실은 조작하려면 이렇게 할 수도 있었는데 그냥 그때는 우리가 그 배우는 거니까 이렇게 나눠가지고 했잖아요.
이미지는 있는가 그렇죠 그렇게 했었어요. 그다음에 얘를 그래서 핏을 하고 핏을 하고 밸리데이션 데이터 밸리데이션 이터를 하고 밸리데이션 데이터가 있어야지 세일 메스토니가 가능하죠.

참석자 1 19:18
그쵸 그쵸 세일 메스토니 할 때 밸리 레인 데이터가 가능하지 그쵸 기본적으로 그다음에 이제 저장된 거 여기 나리 세 포트에서 저장된 거로 로드임을 하고 왜냐하면 제일 좋은 게 저장됐을 때니까 그쵸 맨날 이거 그냥 피 무조건 시킨 다음에 마지막 걸로 하는 거면 바보지.
그쵸 항상 이렇게 마치 포인트 써가지고 세입 레시 포니 한 다음에 그걸 로딩해 쓰는 게 좋겠죠.
그렇죠 이미 배웠으니까 우리 그렇죠 여러분 숙제도 그런 거 하고 있잖아요.
그쵸 그래가지고 걔를 제일 좋은 걸로 해서 테스트를 하려면 이벨리이티 부르는 거죠.
그쵸 했더니 얼마 나오나 그래 그림도 그려봤어요.
그래서 얼마 나왔대? 교과서에 얼마 나왔다는 게 안 적혔나 안 적혀 있어

참석자 1 20:11
안 적혀 있네.

참석자 1 20:17
이게 성적이 성능이 안 좋다는 거 안 나오네. 근데 밸류에이션 데이터는 보통 2도까지 나왔네.
그쵸 2도까지는 그렇죠 트레인 데이터 점점 더 나아지고 사실은 에폭이 몇이었어요?
10이었죠? 그렇죠 여러분 이게 밸리데이션 이거구나 미안해요.
트레이닝 트레이 당연히 좋아지고 밸리데이션 여기 여기 이쯤이네.
그쵸 얼마였어요? 2.5도 정도 되는 것 같네요.
그쵸 2.5도 미안해. 트레이는 당연히 더 낮아졌는데 트레이는 무조건 좋아질 수밖에 없어요.
그쵸 요즘에 요거겠네. 그쵸 베이스트 여기 2.5도 정도 되네.
그쵸 MA가 그쵸 그리고 테스트에도 아마 비슷하게 나왔겠지.
테스트는 더 나쁜일 가능성이 높고 어쨌든 그래서 별로 잘 못한다.
얘는 아까는 3점 모델에서 베이스 라인에서 2.44도였는데 베이스 라인에서는 0이었다는 거잖아.
이 그쵸 이해되죠? 여러분 메이즈 밸리데이션만 해도 2.44니까 이해되죠?
2.43 여기 맞지 2.44 그치 그러니까 더 못하네.
그쵸.

참석자 1 21:36
그래서 여기서 이제 모델이 베스로는 잘 안 된다 이런 걸 알려주고 있는 거고 그다음에 원기 합성부 또 해보자.
언제합 선고 다음에 이제 시점이 2.4절에 언제 합성고 언제 선고도 해봤더니 언제 합선고 교과서에 지금 391쪽에 컴브 원디 했죠 컴브 원디 여기 보면은 필터 개수가 8이고 퍼널 사이즈가 무려 24개나 돼요.
그렇죠 24개는 이렇게 거 쓰는 거죠. 그냥 그렇죠 24개나 있는 거예요.
24개씩 그냥 한꺼번에 이렇게 딱 뽑아내고 이러는 거겠죠 그렇죠 어쨌든 중요한 거는 맥스플링 원디도 뭐 하는 건지 알겠지 두 개 중에 제일 큰 값이고 이런 거겠지 그쵸 처음 보는 거지만 알겠죠?
여러분 했더니 얘는 그래프도 그려봤더니 밸리디네이터 여기 있는 제일 좋을 때가 더 나도가 2.9도 막 이렇게 나와 2.8도가 넘어버려요.
그쵸 더 못한대 그렇죠 더 못하지 더 못해요. 그렇죠

참석자 1 22:39
그래서 이게 왜 이렇게 못하는지에 대해서 교과서에서 392쪽에다가 맨 위에 날씨 데이터는 평일 이동 불가 불변성 가정을 따르지 않는다.
아침 데이터와 저녁 데이터 다른데 그걸 평균 내가지고 하니까 잘될 리가 없지 뭐 이런 얘기하고 있어요.
데이터 순서 많이 주면 순서를 신경도 안 쓰고 하니까 좀 문제가 된다.
그래서 이제 우리는 그래서 이제 여기서 보여주고 싶은 거는 우리가 앞에서 배웠던 두 가지는 별로 도움이 안 되니까 새로운 걸 해보자 이런 거예요.
알겠죠? 그래요. 그래서 또 있네. 또 거기서 또 제 첫 번째 순환신경망만 또 해보면 얘가 이제 못 쓰는 신경만 생긴 모양이 이 얘 LSTM이라는 걸 쓰는데 LSTM 룽 소프톤 메모리라고 나중에 나올 거예요.
얘로 이제 뉴러 16개 써가지고 하나 딱 넣어가지고 해보는 거지 바로 바로 인풋 다 바로 넣었어요.

참석자 1 23:35
그리고 얘의 셰이프도 변형시키지 않고 그대로 넣어가지고 거기 마지막에 이제 댄스 값 하나 예측한다고 댄스 넣어가지고 해봐라 해버렸죠.
잘 모르겠지만 이렇게 했어요. 그렇죠 그렇게 했더니 얘를 똑같은 식으로 했죠.
그렇죠 일단 배운 거를 아까 배운 거랑 비슷하게 그렇죠 일부러 이제 16도 아까랑 똑같이 한 거예요.
그쵸 앞에도 대수로 16 했잖아요. 그쵸 그랬어요.
그래서 했더니 결과가 어떻게 나왔어요?

참석자 1 24:05
제일 좋죠 2.3 그 때 2.4도 안 넘는 거 처음 나왔다.
그렇죠 그랬어요. 그래서 잘 된다. 그러니 여러분 공부 열심히 하자 이런 얘기를 하는 거야.
알겠죠? 20대 사람들 공부해야겠지 이런 거죠.
그렇죠 순환 시간만 공부합시다. 그래서 수학 시험에 처음 보는데 여러분이 이게 이게 rn이라고 적혀 있는 것도 결국은 뉴럴 네트워크 여기 뭐냐면 셀피시 4쪽이에요.
NPC 4 4쪽 입력이 들어가서 출력이 나오는데 출력이 나온 걸 다시 여기다가 넣어서 원래 원래 원래 베스 계산하는 거예요.
또 입력을 또 써가지고 첫 번째 첫 번째 입력은 상관이 없지만 두 번째 입력부터는 원래 이제 입력 데이터 들어간 거의 결괏값이 들어가서 얘를 가지고 다시 계산해서 나오는 거예요.
그래서 순환 얼마죠? 그쵸?

참석자 1 24:57
옛날에 댄스 옛날에 레즈 듀얼은 뭐 한 번 하고 나면 이상이 없어지던 걸 다시 출전이 다시 넣어주는 거였는데 그렇죠 거꾸로죠 그쵸 얘는 출력으로 나오는 걸 다시 입력해 넣어주죠.
그쵸 그리고 이거 한 번 하는 게 아니라 여러 번 한다는 거지.
기본적으로 얘는 순환신경망은 데이터를 한 번 뽑아내는 게 아니라 여러 번 얘가 돌아야 된다는 게 핵심이야.
이 그림이 한 번으로 보이지만 여러 번 놀아 이게 사실 교과서에는 이후 교과서에는 우리 교과서는 이렇게 나오지만 이게 이거 얘가 이렇게 들어가는 시점 있죠 여기 순환 연결로 들어가는 거 1번 2번이 2번이 1번이 일어난 후에 들어가는 거예요.
그러니까 이게 지금 입력 데이터가 시퀀셜하게 들어가고 기본적으로 이게 첫 번째 맨 처음에는 이거밖에 없어요.
일단 이거 그래서 맨날 그냥 오히려 맨 처음에는 이렇게 입력 들어가서 수면 나왔어요.

참석자 1 25:55
한 번 나오고 그다음에 두 번째 다시 입력이 또 들어가면서 옛날에 나왔던 입력이 다시 들어가 그런 식으로 시간적으로 이렇게 여러 번 도는 거예요.
그래서 데이터가 시퀀셜하게 여러 번 된다는 게 중요하고요.
그래서 원래 시크는 데이터에서만 쓰는 거고 이거를 교과서에 지금 이게 되게 잘 돼 있는 건데 오히려 이게 374 그 코드 10 13 보면은 이게 스테이트라는 변수가 여기 아까 여기 요 요 아래 여기 순환 연결 다시 입력으로 들어가는 변수라고 생각하시면 돼요.
이게 원래는 처음에는 아무것도 없었겠죠. 처음에 여기 들어가 있는 게 아무 정보도 없으니까 여보라고 쳤다가 맨 처음에는 여기 여기 들어가 있다고 쳐요.
그래서 그러다가 보면 이 스테이치가 여기 채워주는 게 뭐죠?
아웃풋으로 그쵸 이게 보면은 이게 중요한데 인풋이 하나가 있는 게 아니라 시퀀셜하게 여러 개가 들어가는 거예요.
옛날 배치 들어가는 거랑은 달라요.

참석자 1 27:02
배치 들어가는 거는 그냥 다른 거 여러 개 예측하는 건데 그 데이터 한꺼번에 주는 것밖에 없잖아요.
1번 이미지 3번 이미지랑 4번 이미지 그런 건 순서가 있는 게 아니라 그냥 동시에 1번 3번 4번 예측하려고 그냥 넣는 거 있잖아요.
그게 아니라 시퀀셜한 어떤 데이터가 있는 거예요.
그래서 걔를 이제 펑크 돌면서 들어가는데 여기 아까 그 f가 이제 RNN 네트웍이지.
그래서 그 네트웍에 원래 이제 들어온 거랑 스테이트랑 같이 계산해서 아웃풋이 나온 거를 이제 스테이트에 저장을 해가지고 다시 여기다가 놓는 거죠.
그쵸 이게 한 번 노는 게 아니라 여러 번 놓는다는 게 인풋 10% 개수만큼 중요하고 다음 데이터 계산할 때 원래 아웃풋 나온 결과를 넣는다는 게 중요한 거예요.
알겠죠? 여러분 이런 욕구가 좀 생기기도 하죠. 여러분 사실 나왔던 것 다시 보고 하면 좋겠는데 그렇죠 나오는 거 보고 다시 해보면 좋잖아 이런 생각이 들잖아요.

참석자 1 27:58
그렇죠 하나씩 탈트하는 게 한꺼번에 소리 하지 말고 좀 하나씩 팔도 보면서 그렇죠 그런 거를 한 거고 자세하게 표현하려고 아까 여기 f 함수 있죠.
f 함수는 사실은 옛날 보던 거랑 똑같다는 거지 사실은 보면은 원래 다 we2t하고 더하기 b 하는 거 이거 있죠 이게 뭐예요?
여러분 이게 원래 댄스 네트워크에 생긴 거잖아요.
추가로 아까 추가로 스테이트 티에다가 또 다 타 연산하죠.
이것만 더 들어간 거예요. 아까 스테이트 티에도 뭔가 또 파라미터가 더 있는 거지 이해돼요.
여러분 옛날에 미리 추안 나온 거에다가도 뭔가 또 곱하는 거지 원래 입력 들어오는 거에만 국한한 거였잖아요.
반 연산 w w 그쵸? 프라이트하고 w밖에 없었는데 u가 새로 들어간 거지 이해되죠?
은근히 이야기 있죠. 여러분 wr 있었잖아. 옛날에 u가 새로 들어왔고 이 STFT에다가 한다고 이게 맨 처음에 0이니까 처음에는 0에다 하면 아무것도 어향이 없는 거잖아요.

참석자 1 29:01
다음부터는 이제 이게 그 결과가 나온 거를 가지고 누으니까 영향을 미치겠지 그렇죠 두 번째 시퀀스 그쵸부터 이해되죠 그래요.
그렇게 돼서 그래서 그래가지고 이게 더 이해하게 하기 위해서 지금 이 교과서에서 아까 방금 갖다 거데 이거 이거를 다시 그려놨는데 똑같은 건데 이걸 w랑 u가 뭔지 안 알려줬다가 그냥 w랑 u까지 다 지금 아예 그냥 랜덤 값으로 채워가지고 해준 거예요.
그리고 이제 여기 들어가는 거 여기 여기 전부 다 인풋이랑 스테이트가 뭔지도 다 지금 이 가짜로 해본 거예요.
이해되죠? 여러분 앞에 뭐 많아 보이지만 사실 그냥 이 입력 값을 구체적으로 넣어놓은 것밖에 없죠.
앞에서 봤던 코드에서 여기 여기 인풋즈가 뭔지 한번 만들어보고 w가 뭔지 만들어보고 u가 뭔지 만들어볼 거고 그렇잖아요.
여러분 그쵸? 랜덤 값으로 이해되죠 여러분 그래요.
그래서 이게 그리고 이제 인풋 값도 이제 원래 인풋 피처들 개수가 이제 타임 스텝별로 있는 걸 거 아니에요?
그쵸?

참석자 1 30:12
타임 스텝의 개수를 여기서 100개나 했네. 100번이나 데이터가 들어오는 거예요.
그쵸 아까는 우리 타임 스텝이 무려 120이었죠.
oh oh 5 데이즈 그쵸 영어가 더 잘해 그래서 이게 인트피처는 아까 14개 그런 거였잖아요.
그쵸 그런 게 있는 거 이해되죠? 여러분 여기는 32개로 했네.
그쵸 그리고 아웃풋을 몇 개 낼지도 정하기 나름인데 여기 64개로 정했어요.
잎사귀로 정해서 해본 거고 그래가지고 그리고 이제 어쨌든 여기는 그래서 스테이트 t도 스테이트 t가 이제 결국은 아웃 피처 개수만큼 나올 테니까 아웃 피처로 해놨고 그다음에 w는 이제 아웃 피처 곱하기 인프 피처 개수만큼 해놔서 가중치니까 이거예요.
이렇게 돼 있는 거 마찬가지로 이도 마찬가지고 유는 근데 아웃츠라고 하니까 아웃 피처 아웃 피처로 돼 있는 거죠.
아이어스는 아웃 피처 개수만큼 있겠지 아웃 피처 있을만큼 더해지는 거니까 옛날 거랑 똑같은 거예요.

참석자 1 31:17
그래서 여기 MP 점 다 MP 점 돼 있는데 진짜 단 연상하는 거예요.
그쵸 그리고 여기 지금 액티베이션 펑션으로 탄젠트 하이퍼볼릭 칸젠트를 썼죠 그쵸 하이퍼볼릭 탄젠트가 이 마이너스 1하고 일로 이렇게 트레이트 시켜주는 거거든요.
마이너스 1하고 1로 낸드는 연구 연구 다 하면 잘라버렸잖아요.
렐루는 근데 얘는 이제 마이너스 1하고 일사로 바운드 시켜주는 놈인데 이게 잘 되는 걸로 이용해 이쪽에서는 그래가지고 여기 3시버 아웃풋은 그냥 나중에 보려고 넣는 거지 결과를 그래서 하나 어쨌든 아웃풋 t를 다시 세트 t에 넣는 거 똑같잖아요.
그쵸 그래서 이거를 인풋별로 이렇게 돌리잖아요.

참석자 1 31:57
그쵸 인풋 개수만큼 이 시퀀스 개수만큼 그쵸 이게 이게 진짜 여러분 RNN이고 RNN을 교과서 이 교과서 말고 다른 교과서들은 진짜로 저도 옛날에 다른 교과서 쓸 때 시간을 막 펼쳐가지고 여러 그림을 보여주고 했거든요.
근데 더 헷갈리는 것 같아 이게 진실이야 진실은 이거밖에 없어요.
그냥 뭐 하는 건지 알겠죠? 여러분 이게 더 안 헷갈리지 않아요 막 그림 가열하게 하는 것보다 난 이게 제일 좋은 것 같아요.
이거 그냥 진짜 루크 도는 거밖에 없어요라고 넣으실 때

참석자 2 32:25
그러면 웨이트가 두 번 곱해 두 번 더해지는 거예요.
두 번이 두 번째 칼루랑

참석자 1 32:31
9번이라는 게 무슨 뜻이지 예. 다 요 요거 요거 요거 요거

참석자 2 32:37
그럼 2배가 되는데

참석자 1 32:38
웨이트는 와이트 얼마든지 많이 할 수도 있지 사실 상관없죠.
상관없어. 이거 그냥 학습시킬 때 이렇게 하는 거니까 나중에 우리가 마지막 학습시킬 때 전파하면 다 조정이 되죠.
그쵸 팩트라페이션 하면 어쨌든 이게 이렇게 여러 번 전파시켜서 나가게 되고 나중에 셰프로포게이션 할 때도 여러 번 전파시켜서 하는 거예요.
애플 리모게이션도 거꾸로 하는 거라서 그래서 어쨌든 데이터 자체가 시퀀셜하게 돼 있고 계산도 시퀀셜하게 하는 거예요.
근데 이제 나온 결과를 다시 한 번 이렇게 해놓은 거고 그런데 어쨌든 요즘에 다시 유행하는 연구 중에 하나가 원래 뉴럴 네트워크를 한 번 쓰고 뭔가 마는 거였는데 원래 그럴 트워크를 둔 상태에서 또 쓰고 또 쓰고 또 쓰고 하는 거 있잖아요.

참석자 1 33:29
여러 번 생각 많이 하게 한다고 같은 그냥 웨이트 갖고 수명 나온 거 가지고 그런 원리가 많이 있거든요.
나중에 이제 자연어 처리할 때도 트랜스포머도 사실은 결과 나온 거 갖고 또 입력해 넣고 또 집어넣고 입력해 넣고 막 이러고 있거든요.
비슷한 면도 있어요. 그래서 사실은 이렇게 함부로 돌아가는 게 아니라 말할 때 말할 때 제가 이렇게 얘기했죠.
말 한 번 데이트 스트 말이라고 그랬어 할 그럼 그 다음에 나올 수 있는 말은 때밖에 없지 이러면서 말하라라고 그랬으면 그다음에 때밖에 못 나오는 거죠.
이런 식으로 하나 튀어나오면 그다음에 이런 식으로 시퀀셜 하게 된다.
그래서 지금 결과가 나온 뱉어낸 걸 가지고 다시 입력해 넣어가지고 하고 있잖아요.
그쵸 그리고 원래 입력으로 키퍼 되어 있는 거에서도 이미 데이터를 다 섞어가지고 그러고 있고요.

참석자 2 34:19
그럼 저 코드 자체는 레이어는 하나인데 그거를 계속 돌리고

참석자 1 34:23
여러분 리고 있는 거예요. 진짜로

참석자 2 34:25
아이어는 하나도 안 받아

참석자 1 34:26
맞아요. 이렇게 생겨 먹었는데 이게 입력 시퀀스만큼 되겠네요.
뉴런의 개수를 2개라고 생각하면 이 안에 2개 들어가 있는 거 이런 유런이 사실 원래 뉴런의 개수는 여기 우리가 개수는 정해줄 수 있잖아요.
16개 이렇게 거기에 두 배로 더 늘어나고 있는 거죠.
얘 할 것도 있는 거죠. 이런 식으로 그래가지고 이것도 이제 이게 이거 드디어 하이 거에 나오는 그림이 나왔는데 396쪽 볼까요?
여러분 여기는 이것도 여러분 이제 조심하셔야 될 게 시간이 여기 보면은 입력 t 마이너스 1 입력 t 입력 t 플러스 1이 보이죠.
여러분 그쵸 실제 뉴런은 하나 실제 이거는 이 네오플 박스는 하나가 있는데 시간에 20 맨 처음에는 이렇게 여기는 아무것도 없었겠지 사실은 그렇죠 돌았다가 그다음에 여기 나온 게 다음에 똑같은 놈한테 또 들어가는 거예요.
이게 다른 놈이 아니고 얘랑 얘 얘 같은 놈이에요.

참석자 1 35:26
시간이 다른 것뿐이야 그렇죠 알겠어요 여러분 됐지 그래서 출력 출력 출력이 여러 번 시간에 따라 나온다고 알겠죠 아까 그 그 코드가 정확한 이해로 그걸로 기억하시는 게 좋겠어요.
알겠죠? 이거는 마치 블록이 여러 개 있는 것처럼 오해를 할 수 있어서 시간에 따라서 여러 번 그린 것뿐이에요.
알겠죠? 이런 마법은 없어 사실은 같은 놈이 다시 들어간 거예요.
그렇죠 알겠죠? 내가 뱉은 거 다시 넣는 거예요. 알겠죠?
내가 매 같은 놈이야 얘예요. 알겠어요. 그리고 이거를 구현해 주는 라이브러리가 당연히 있을 텐데 제일 간단한 간단한 이제 API가 심플 RLN이라는 게 있어요.
심플 RL 지금 보면 바로 옆에 거 396쪽에 나오죠.
이 그림 밑에요. 그것도 이것도 한 번 해야 되는구나 노트 노트 노트에 최종 출력인 패스 박스 안에 아니 여기는 없네.

참석자 1 36:34
타임 스텝 개수만큼이 나올 거 아니에요 그쵸 아웃 피처로 정해진 것만큼 그쵸 왜냐하면 타임별로 하나씩 하나씩 튀어나오니까 이게 여기 봐 여기 여기 하나 또 치워라 치워라 치워라 이만큼 튀어나올 거 아니야 그쵸 세트 개수처럼 이렇게 개수가 쌓이겠죠 그쵸 여기 나오는 것도 그렇죠 개수가 있을 것이고 그렇죠 다시 입력으로 들어가기로 하고 필러로도 쌓이는 거죠.
그쵸 그렇게 된다는 거죠.

참석자 1 37:03
요 그리고 보통 이렇게 막 많이 나오는데 보통 쓸 때 이제 이런 중간중간 거는 여기 입력이 중간에 쓰는 거니까 맨 마지막에 튀어나온 것만 보통 사람이 조작해서 많이 써요.
필요한 건 맨 마지막에 이제 예측하고 싶은 거 데이터가 있기 때문에 아까 온도도 그렇기 때문에 아까 온도 쪽에서 그리고 여기는 핀만 했으니까 안 보이겠는데요.
그래가지고 계속 하면은 아까 그 코드가 지금 심플 RNN 써가지고 똑같이 해가지고 이렇게 만들 수 있다는 거고 그래서 아까 그래서 교과서에 이제 그래서 397쪽으로 가면은

참석자 1 37:51
27 30 300에서 여기서 보면 이것도 있구나 여기 쉐입이 나인 거는 얼마큼 들어올지 모르니까 그냥 여기 마치 몇 개씩 여기는 이 라인이 이게 몇 개의 시퀀스가 들어올지 모르니까 그쵸 아니라고 해놓은 거지 배치처럼 원피처즈는 아까 14개인 거 기억나죠 여러분 그쵸 그거에 해당하는 거고 그다음에 근데 만약에 정해진 면은 정해진 대로 주면 되겠지 그래서 교과서에서 이제 우리 스텝스가 120으로 정해져 있잖아요.
120개 데이터가 올 거니까 그렇죠 120으로 그냥 정해질 수도 있다 이 얘기지 그래요.
그리고 요 위에 그 교과서 바로 위에 테라스에 있는 순환층이 뭐 뭐가 있는 심플 RNN 말고도 뭐가 있는지 적혀 있죠.
LSTL이랑 GRU가 있어요. GRU LSTM이랑 GRU 그러니까 실제로 사람들이 많이 쓰는 건 LSTM이랑 GRU를 많이 시프라는 잘 안 쓰고 아까도 우리가 그 예를 보여준 건데 LSTM이었죠 그렇죠 근데 LSTM보다 GRU가 좋은 게 유명해요.

참석자 1 39:01
훨씬 가벼우면서도 빠르면서도 성능이 괜찮아서 이게 우리나라 사람이 만든 거라는 게 되게 재미있잖아요.
그거 우리나라 분이세요 우리나라 사람인데 미국 대학에서 워싱턴 대학인가 거기서 교수 하시고 계시고 그래서 카이스트 나오셨거든요.
많이 뉴스도 많이 나오시고 막 그 사람 너무 유명해져가지고 교과서에 나오잖아요.
그래가지고 참 이분은 대박이 났죠. 아무도 연구 안 하지 혼자 연구해가지고 이거 지환류가 진짜 제일 좋거든요.
근데 교과서에서 이게 희한하게 지환류를 잘 안 쓰는데 재활유 확률이 훨씬 더 좋아요.
LSTM 이면 LSTM을 간단하게 만드는 거지.
어쨌든 여기 있고 나중에 나올 거예요. 그래서 어쨌든 결과적으로 만약에 타임 스텝의 출력을 전부 다 모으면 이제 배치 사이즈 타임 스텝 아웃핏처럼 이렇게 나올 수 있겠죠.
여러분 교과서 인식이 있어요. 이거 보이죠. 모든 출력을 다 모으면 배치 사이즈 타임 스텝 값이 이렇게 나오겠죠.
그쵸 그렇게 할 수 있겠지.

참석자 1 40:10
그런데 이게 타이스트도 다 나오는 거 별로 관심이 없을 수 있잖아요.
그쵸 중간중간 쓰려고 나오는 거니까. 그래서 그냥 배치 사이즈에다가 아웃 피처럼 나오게 하는 게 편할 수 있겠죠.
그쵸 그렇게 해서 여기 보면은 여기 첨보는 건데 리턴 시퀀스를 포스로 넣어줘요.
여기는 그쵸 리턴 시퀀스즈는 코스가 이렇게 넣어주면 사실 이게 기본 값이에요.
그래서 이렇게 안 해도 무조건 타임 스텝마다 다 나오는 게 아니라 그냥 이걸 굳이 툴로 하지 않는 한 중간 값은 결과가 나오지 않아요.
알겠죠? 아웃풋에 내부적으로만 쓰이고 있고 그래요.
그래서 아웃풋의 cm을 찍어오면은 나는 16개 있는데 아직 얼마 이게 이게 디멘전이 얼마예요?
여러분 2D죠 2D 그쵸 2D 2D인 게 이게 16개 이거 나온 거에다가 나는 이제 배치 사이즈겠지 배치 사이즈 모르니까 나는 나온 거지 알겠죠 이해되죠 만약에 이거를 트롤로 바꿔줘 그러면은 듣기 신기해요.

참석자 1 41:15
이거 나 교과서가 오류가 있어 여기에 여기 난이 또 있어야 되는데 안 나왔어 오타 오타 이거 이런 걸 어떻게 어떻게 나오는지 신기해 난 콤마가 있어야겠죠 여러분 그래도 국내에서 올려봤는데 진짜 나한테만 나오더라고 알겠죠 그때도 오타예요.
붙으세요.

참석자 1 41:37
그다음에

참석자 2 41:43
그 리턴 시퀀스 인자는 시간 축을 출력할지 안 할지를 결정하는

참석자 1 41:49
맞아요. 그 축이라 치대 축이라고 출력이 여러 번 나오잖아요.
원래 여러 번 나오는 거를 다 출력할 거냐 시간축이라고 생각해도 되겠네.
시간 축이라고 그러지 이제 시간 축 하이 스텝 축 그쵸 하인 스텝 매번 이제 사실 여러 번 돌리잖아.
사실은 이게 뭐냐면 여기도 이거 아까 내가 예를 보여준 거 있잖아요.
여기 있어야겠네. 여기 폴 인풋해서 이거 여기 인풋이 개수가 만약에 만 개면은 만 권이 나올 거 아니에요?
그쵸 아웃풋이 그걸 다 출력하는 게 리턴 시퀀스 2고 기본적으로는 그냥 만 번 출력 중에 맨 마지막 것만 나오게 내부적으로 보고 그렇죠 좀 오래 걸리겠죠 내 RNN 돌릴 때 그렇죠 부수도니까 이렇게 돼요.
다 있나 그다음에 3998쪽에 그래서 398쪽에 그래서 이제 다른 실제로 많이 쓰이는 거에 대한 설명이 398쪽에 여기 LSTM 지금 살펴보죠.
가운데 뚜하이 나오죠 그쵸 LSTM 장단기 메모리 그쵸 여기 영어로 롱쇼트턴 메모리라는 거 외우세요 여러분 이 시험에 나와요.

참석자 1 43:02
나올 수 있어요. 왜냐하면 이런 용어 약자가 나오면 좀 외울 필요가 있죠.
무슨 내용인지 알지 로스트 텀 메모리 이게 뜻이 장단기 기억이잖아요.
그쵸 원래 우리가 장기 기억이 있고 단기 기억이 있고 그렇잖아요.
그쵸 장기 기억 단기 기억을 좀 다 살려보려고 노력하는 그런 RNN이에요.
알겠죠? 여러분 내부적으로 뭔가 또 기억하는 뭔가 회로를 만들었어요.
그런데 그거를 그 자세한 설명은 지금도 안 하고 있지.
벌써 97년이니까 문제가 옛날에 안 들었네. 그렇죠 그래요.
그다음에 GRU도 또 나오고 있는데 GRU에 대한 설명 같은 건 국가사에서 안 하겠다고 돼 있어요.
그래가지고 4분 남았는데 어쨌든

참석자 1 44:04
여기 보면은 교과서에 이제 그래서 이제 여기 내가 이거 그림 108이랑 3이랑 이제 109가 있거든요.
이게 엄청나게 틀렸어요. 실수 실수를 많이 여기 멀쩡하네.
여러분 교과서에는 여러분 교과서에는 제대로 돼 있나 어떻게 있나 멀쩡하네 웃음이 새로 나오나 내 거만 을래요.
그럼 여러분 그린 109에 이게 이제 아까 여러분 교과서에 보면 어쨌든 여기 이따가 고칠 만한 게 뭐냐 내가 이거를 내가 여기 1타 나왔네.
여기 보면 강의 자료에다가 여기 399쪽에 400점에 오류가 많이 있어서 제가 고쳐놓은 게 있는데 한번 보여볼게요.
일단 그림 10 7 8 9에 상태 t 입력 t 출력 티 이렇게 돼 있잖아요.
근데 이게 문제가 뭐냐면은 번역을 했는데 여기 보면 여기 스테이트 티 임프치 이런 게 여기 보이죠.
아프치 여기 그렇죠 근데 이거를 번역을 해버리면 이게 그건지 못 알아보잖아요.
이 출력치가 이 아웃풋인지 못 알아보잖아요.

참석자 1 45:21
그쵸 안 그래요 여러분 번역하면 안 되지 뭔 말인지 알겠어요 여기 다시 여기 출력 t가 아웃풋 t라고 여기 출력 t 플러스 1이 아웃풋 바 티 플러스 1이고 이해되죠 여러분 입력 티가 스테이트 티라고요.
그걸 번역을 해버리면 알아보기 힘들잖아. 여기 코트로 들어가 있는 건데 이해돼요 여러분 입력하는 이 인뷰티 인프티지 스테이트 티가 여기있지 이 제가 실수했었는데 스테이트 티가 스테이트 티고 이 스테이트 티가 이거야 이거야 알겠죠 그래서 스테이트 티는 아웃풋 t 마이너스 1이라는 게 보이지 그쵸?
그쵸? 이렇게 돼 있어요. 뭘 고쳐야 되겠지 요거 요거 요거 여기서 이지 이렇게 붙이고 그다음에 이게 캐리라는 게 새로 생겼는데 캐리 트랙 이동 트랙이라는 게 109에 2등 트랙이라는 게 나오는데 2등 트랙이라는 말이 그게 뭔 말인가 싶지 않아요 케이 트랙이 케이 트랙 KD 트랙이라는 거고 KD 트랙이 변수가 새로 나와서 케리라는 게 생겨요.

참석자 1 46:33
케리 케리가 이제 장단기 메모리를 위한 거고 근데 이거 이렇게 열심히 할 필요도 없는 게 교과서에서 하지도 않아.
여기 왜냐하면 뭐라고 했냐면은 혈액 1쪽에 시간 1분 남았으니까 401쪽에 1 4 위에 요약하면 LHTM셀의 구체적인 구조에 대해서 이해할 필요가 전혀 없습니다.
이를 이해하는 것이 우리가 할 일 해야 할 일이 아닙니다.
이러면서 공부하지 말자고 그래버리죠. 그쵸 그랬어요.
그래서 네 그럽시다. 아니 공부 안 하겠다는 설명 안 하겠다고 그래서 막 여기 지금 번역도 이상하게 돼 있고 막 엉창인데 그래요.
그래서 나도 안 하지 그래요. 그래서 교과서 틀린 거니까 적어놨어요.
알겠죠? 지금 시간도 없는데 아까 구글 LM 구글 노트북 LM 있잖아요.
거기에 그런 거 잘 활용하시고 만약에 필요하시면 LST 논문 넣어서 올리든지 근데 진짜 약간 재미있는 게 영어로 번역을 해주면 너무 자세하게 하려고 그러는데 오히려 오류가 생겨요.

참석자 1 47:31
그래 너 해봤는데 내가 논문 되게 많이 읽기 쉬웠던 논문 있잖니 논문이 안 읽혀 막 되게 당황하고 막 때려 박아서 해봤거든요.
근데 하루에 3개밖에 안 되더라고요. 이게 돈내네 돈 내면 이것만 해주겠다고 그래서 무조건 종료 3개씩이나 이해 하루에 3개씩만 이해하자는 그렇게 하고 있는데 이제 영어로 했을 때는 문제가 뭐냐면은 너무 자세하게 하다가 틀리냐가 나와요.
단위가 예를 들어서 없는데 단위를 다 안 붙여서 시간이 리터라고 불러 원 아워라고 불러 원 세컨드라고 불러 이걸 원 리터라고 부르는 거야.
그래서 얘네들이 막 너무 막 이상해 보이기 시작해.
이제 인공지능이 영혼이 없는 게 보이잖아요. 이제 이렇게 시간을 아무래도 여러분 사람한테 사람이 1시간을 한 원미터라고 안 할 거 아니야 그쵸 그렇게 틀리기 시작하는 경향이 있는데 우리나라 말은 근데 오히려 그렇게 자세하게 하기 때문에 문제지 쓸 만한 게 있고 잘 활용해 보세요.
여러분 좋은 세상이에요.

참석자 1 48:22
그렇죠 좋은 세상이 아닐 수도 있지만 어쨌든 인공지능을 잘 계속 공부하는 거예요.
래서.


clovanote.naver.com

