딥러닝 day22
2025.06.02 월 오전 10:01 ・ 51분 14초
심승환


참석자 1 00:00
올린 거 고치라고 그랬던 거 있잖아요. 오류 가치 있었죠 그걸 기반으로 설명을 마무리하고 이거 399쪽에 30쪽이죠.
문서가 좀 안 틀린 교과서도 있고 틀린 교과서도 있고 그런 거지.
그러니까 약간 판례에 따라 다른 것 같아요. 그래가지고 여기 그림에서 이제 한 글로 지금 예를 들어서 촉수 안 적어놨구나 그림 10 7 10 7 27이 맞나 맞네.
그때 그 207이 이제 396쪽이고 그렇죠 396쪽이 계시면 지금 문체를 잘못 들어갔네.
396쪽부터네. 그래요. 그림 13 17은 396쪽에 있으니까 그다음에 그린 18은 399쪽 이렇게 있는데 똑같은 그림이에요.
여러 번 나와서 107이나 108은 똑같은 걸 또 두 번 그렸어요.
여러분 그쵸 그쵸 교과서가 지금 396쪽이랑 포주기어는

참석자 1 01:14
396쪽 107 이 그림 이 그림이랑 그림 그림 10 8에 그러니까 390 9쪽 이 그림이 똑같아요.
그렇죠 여러분 똑같은 걸 어쨌든 교과서가 좀 쓸데없이 낭비를 많이 해 또 무거워 죽겠는데 그렇죠 어쨌든 뭐 이해되죠 여러분 그렇치 뭔 얘기냐 여기 똑같은 거 또 있는 거야.
그냥 그쵸 신양양 이거 이거는 그냥 아래는 원래 심플하게 생긴 게 이렇게 생겼는데 그다음에 이제 19 그림에서 이제 여기에 새로운 게 들어간 게

참석자 1 02:01
이거 잘못됐어요. 여러분 그쵸 잘못했다고 그랬지 욕을 이렇게 여러분 교과서마다 다른데 곱하기 아니고 교과서마다 다르더라고 사람마다 이거 이거 고치라고 그랬죠.
제가 어떻게 하라고 그랬어요 더하기로 들어가야 돼.
더하기 여기 더하기 더하기 v제로 곱하기 CT가 들어가야 되거든요.
v제로 새로운 이런 식으로 CT가 인풋이나 스테이트처럼 새로 입력으로 들어가는 거예요.
k이라는 게 k라게 생긴 게 뭐냐면은 옛날 옛날 출력에서 넘어오는 거죠.
그쵸 그러니까 지금 상태는 방금 전에 출력해서 넘어오는 건데 CT는 계속 넘어오고 있잖아요.
그쵸 CT도 FT가 넘어오고 있죠. 그러니까 더 이전 출력에서 넘어오려고 하는 거라서 이게 약간 레지듀얼처럼 레지듀얼은 이제 이전 계층인데 이거는 시간 타임 스텝에서서 이전 시간 거를 좀 계속 오래 기억하고 싶어서 옛날에 뭔 일 있었지 이런 거죠.
캐리라고 그래서 이동 트랙이 따로 있는 거예요. 옛날에 뭔 일 있었지를 계속 유지하려고 하는 거예요.

참석자 1 03:05
옛날에 뭔 일이 있었는지 좀 기억해 보려고 그러는 건데 이게 이게 사실 근데 LSTM이 아니고 여기에다가 이걸 약간 더 추가해서 여기 다음에 여기 보면은 요렇게 트로이 상태 여기 지금 400쪽 있죠 트로 이온 상태 계산이라는 거 또 있죠 그쵸 300쪽 보이죠.
여러분 이거에서 뭐 할 거냐면은 CTA가 그냥 들어가는 게 아니라 CTA가 그냥 들어가는 게 아니라 그리고 상태도 그냥 들어가는 게 아니라 요걸 또 통과하죠.
그쵸 그것도 딥러닝 데스트 네트워크 같은 거예요.
이 내부적으로 그래서 때에 따라서는 오래된 기억을 또 잃어버리려고 CT가 이제 가끔 드라바도 시켜야 돼요.
날 오래된 기억은 이제 필요 없어 하고 잊어버리는 거죠.
그 포바이라는 팩터가 새로 들어가기 시작하고 근데 여기도 막 다 틀려가지고 그래가지고 내부적으로 여기 원래 계산하는 것 이것도 다 터졌어.
그래서 제가 고쳐놓은 게 있어요. 여러분 강의 자료에 고쳐놨어요.

참석자 1 04:06
어떻게 붙여놨냐면은 사실은 여기 보면은 여기 어쨌든 지금 액티베이션 하는데 원래 스테이트 원래 이제 스테이트랑 인풋이랑 하는 거 외에 여기 보면은 이제 FT가 또 추가로 들어가 있으면서 이 이거 이런 걸 가지고 나중에 다음 페이지 다음 페이지에 있는 CT 플러스 1이 이거죠.
캐리 아웃 하는 게 캐리 하는 게 이런 거 다 이거 지금 여기 이 it랑 KT랑 곱하고 t2 FT 해서 FT FT랑 KT가 뭐 하려고 그러냐면은 이게 이게 f가 뜻이 저걸 적어놓을래요?
여러분 교과서에 안 적혀 있는데 f가 뜻이 포깃이야 포깃 잊어버리고 싶은 거야.
잊어버리는 것도 학습을 통해서 언제쯤 잊어버릴지를 뭔가 이제 너무 들어오는 값이 이제 미약하거나 이러면 잊어버리려고 하는 거예요.
계속 옛날 거를 더 집착하게 만들기도 하고 잊어버리기도 하고 이런 그런 걸 기본적인 아이들 하고 있고요.
LSTM이 사실 상당히 많이 쓰이다가 또 이게 복잡해서 나중에 giu라는 게 나왔거든요.

참석자 1 05:19
이거보다 훨씬 심플하게 근데 교과서에 아예 안 나오고 있는데 열심히 하려고 그러다가 이제 사실은 망했거든요.
거의 이쪽이 RNN이 트랜스포머 때문에 사실 시계열 문제를 이게 이렇게 이걸로 풀어서 잘 안 되는 경우가 너무 많아서 그래서 그냥 대충 넘어가고 있어요.
지금 알겠죠. 일단은 교과서 틀린 거를 내가 강정해 놓은 걸 알고 있으시고 LSTM에서는 뭔가 옛날 정보를 옛날에 여러 번 리터레이션 하는데 옛날 것이 넘어오기도 하고 넘어오는 게 이제 캐리 캐리 트랙이라고 해서 캐리로 넘어오는데 이게 실제로는 이게 아니라 이제 혈액 종에 나온 것처럼 되는 거고 이렇게 실제 수식은 이런 식으로 되는 거고 그렇죠 이거 틀렸고 이것도 고쳐놨죠.
제가 강의 자료 고쳐놨어요. 여기 너무 시간 많이 쓰고 싶지 않아가지고 내가 여기 강의 자료에 여기 지금 이 코드에서 맨 처음 맨 위에 나온 게 이거 틀렸거든요.

참석자 1 06:17
그냥 되게 심플해 오히려 그냥 이렇게 더하는 다 그냥 아주 심플하게 이게 튀어나오거나 이런 거 없이 CT를 액티베이션 시키는 게 아니라 왜 저런 게 나오는지 모르겠어요.
그냥 이렇게 그냥 더해서 액티베이션 시키거든요.
여기 보면 밖에 교과서는 CT를 액티베이션 시킨다고 돼 있잖아요.
말도 안 되지 CT도 똑같이 이렇게 뭔가 웨이트가 있어가지고 걔를 같이 더해가지고 액티베이션 시켜요.
심플하게 알겠죠 이게 이게 이거 원래 원래 에이스 팀이 이래요.
그래서 요 핵심 아이디어는 뭐냐 과거의 정보를 뭔가 또 이제 가져가기도 하고 같이 버리기도 하고 이러는 거예요.
알겠죠. 그리고 GRU는 이거를 이제 수학적으로 간소화시켰어요.

참석자 1 07:00
더 심플하게 그 GRU는 아직 나오지는 않지만 어쨌든 그래서 여기 교과 이 정도로 일단 끝내고 여러분 여기는 그다음에 그냥 여기로 끝내자 이걸로 끝내고 10장 4절 들어가서 고급 사용법이 나오는데 사실은 지금 우리가 나온 거는 그냥 심플 RNN만 한 번 사용했는데 심플 RNN 아무도 안 써요.
사실은 RNN 써도 LSTM이나 GRU를 쓰겠지 그거에 대한 내용이에요.
그래서 교과서에 지금 이렇게 기본적으로 고급적으로 쓰는 거예요.
GRU RNN 쓰는 것도 하고 순환 드라바웃이라는 것도 쓰면 좋고 드라아웃도 이제 리커먼트하면서 타임 여러 번 루프 돌 때 가끔씩 드라아웃 시키는 거죠.
그런 것도 있고 또 이제 RNN의 아까 계층 자체를 아까 LSTM이나 GRU 같은 거를 여러 번 쌓을 수도 있겠지 한 번만 나왔잖아요.
교관사에서는 여러 계층으로 할 수 있는 것도 나오고 그다음에 이것도 재미있는데 양방향이 있어요.
양방향 그러니까 옛날부터 데이터를 봐왔잖아요.

참석자 1 08:03
채시부터 데이터를 봐 스퍼크로 보는 거를 같이 학습시켜가지고 결과를 또 앙상블시키는 게 있어요.
그런데 트랜스포머보다 훨씬 못하지 그러니까 여러분 이런 거죠.
이것도 다 자이로 처리에서 하는 건데 우리가 말할 때 뭐야 예를 들어서 너는 밥을 먹었니 이렇게 해도 되고 밥을 아니 너는 밥을 먹었니 해도 되고 너는 먼저 들은 다음에 밥을 먼저 들은 다음에 먹었니 한 다음에 이제 말할 거 있잖아요.
그러면은 뭐 다음에 나올 사람 이렇게 생각할 수도 있잖아요.
근데 그거를 먹었니 밥을 너는 이렇게 해도 상관없잖아 전혀 그렇죠 그럼 다음에 나올 말을 생각하는 것도 괜찮잖아요.
그렇죠 그런 것 때문에 이제 양방향이 있어요. 이해되죠.
여러분 그런데 어쨌든 이거보다는 나중에 트랜스포머 훨씬 잘해서 일단은 뭐 그렇게 있다는 건 알고 별로 안 중요하다면서 왜 이렇게 계속 열심히 하느냐 그래도 근본 중의 근본이니까 일단 알고는 있어야지 RNA는 그쵸 알겠죠 계속 갈게요.

참석자 1 09:03
여러분 10.4.2에 그래서 들어가는 게 하나씩 하나씩 순환 드라바웃이 먼저 나오고 수환 드라바웃은 여기 보면 그냥 교과서에 여기 803쪽에 썰렁하게 요것만 여러분 여기 두니 떠놓으면 좋겠다.
여기다가 이거 들어가는 거예요. 파라미터에 여기 LSTM이 들어가는데 이제 아까 심플 RNN 말고 요거 있잖아 리카운트 드라버드 요거 요거 파라미터 써가지고 할 수 있어요.
루프 돌면서 0.25%만큼은 이제 이 이런 안 쓰는 거지 없는 셈 치고로 돌아가는 거예요.
32개 중에서 0.25% 그런 거죠. 그렇죠 여러분 32개가 있겠지 32개니까 그쵸 30이니까 알겠죠 그리고 드라아웃은 여전히 또 이제 다음에 레이어 넘어갈 때 베스 넘어갈 때 쓰기 위한 것들이고 넘어갈 때 여기 드라바웃은 옛날 그 댄스 네트 연결하기 위한 거고 LSTM의 리크론 드라바웃은 여러 번 돌 때 몇 퍼센트를 안 쓰겠느냐 이런 거로 하고 사실 코드는 없는데

참석자 1 10:20
그래요. 어쨌든 여기 정확하게 이 교과서 역주에 궁금하다는 거에 대한 사실 상세 내용이 나와 있어요.
역주에 LSTM 셀의 경우에 인풋에는 드라바 비율이 적용이 되고 스티트 t의 리컨 드라바 비율이 적용되고 이게 더 정확한데 그러니까 옛날 값 옛날 값은 옛날 값에 대해서 적용하는 게 이거고 원래 지금 들어오는 거에 적용하는 게 이거고 우리가 하는 거지 원래 웨이트가 붙어 있는 거는 여러분 어디 이전 유론에서 다음 유론으로 붙어 있는 거니까 근데 이거는 뭐 나중에 여러분 필요하면 보세요.
알겠죠 넘어갈게요. 계속 그다음에 RNN 성능이 어떠냐 RNN 성능은 보통 그리고 CPU가 더 빠른 경향도 있는데 워낙 CPU가 동면 처리를 잘해서 GPU가 빠를 경우는 대규모의 경우에 NVIDIA 푸다가 잘 되는 경우도 있다.
이것도 사실 계속 변하는 거라서 나도 잘 모르겠고 진짜 알 수 없는 거라서 그냥 실제로 항상 좀 조사해 보고 하세요.

참석자 1 11:24
여러분 그다음에 이제 드라바웃을 써가지고 했을 때 이렇게 드라아웃 한 항시 트레이닝이 느려져 가지고 이렇게 천천히 내려가는 경향이 있고 LSTNS 아까 이거 온도 문제 풀었던 거 옛날에 온도 문제 풀던 거 옛날에 온도 이거 드라바를 안 썼을 때는 393쪽에 있는데 393쪽에 10번 내폭만 해도 2.3 밑으로 내려왔었거든요.
드라마 왔었을 때는 저기 뭐야 트레이닝이 2393쪽에 그쵸 그러니까 여러분 이거 이런 거 그래프 볼 때 그냥 이런 거 보면 아무 소용이 없고 항상 옛날 거랑 비교해서 보는 게 항상 필요하죠.
그쵸 공부할 때 알겠죠 지금 별로 덜 중요해서 제가 스스로 뒤 슬라이드까지 이동하지는 않지만 알겠죠 드라마 쓰면 항상 이렇게 느려져요.
여러분 느려지는데 모양이 좀 이쁘게 나와 그래요.
그리고 나중에 화창 훈련 더 시켜야 돼요.

참석자 1 12:29
좀 그렇고 그래서 사실 이거 뭐 아직 거접학도 안 됐죠 50까지 했는데도 과정 합이 안 됐잖아 더 해야 되는 거지 사실은 이게 이게 될 때까지 해야지 그렇죠 그러니까 사실 그런 거고 그다음에 그다음에 이제 넘어가서 110.4.22 405쪽 넘어가면은 이제 스태킹 순환층이 나오는데 그 순환층을 쌓는 거지 옛날에 이제 빅롤 네트워크처럼 쌓는 거죠.
쌓는 거 보면은 쌓을라 그러면 이제 LSTM이 너무 무거우니까 지완료 쓰기 시작하는데 근데 이제 다른 많은 교과서에 나오는데 지완료 성능이 훨씬 좋아요.
보통은 그냥 많은 경우에 그냥 GRU만 나오는 경우도 많아요.
그래요. 알겠죠? LSN은 저희가 나와 GRU만 쓰죠 지환이 우리나라 사람이 했다는 게 신기하죠.
그죠? 그죠 수학 잘해 필드 상도 받으시고 그렇죠 다른 분이지만 진짜 그래요.
그러고 보면 카이스트가 참 잘하긴 하는 것 같아요.
어떡하 거기는 서울대구나. 필드상 받으신 분은 서울대구나 이 없어요.

참석자 1 13:34
어쨌든 계속 가면은 GRU가 어쨌든 지환류를 써서 지금 보면은 옛날하고 다른 게 한 번 쌓고 또 쌓았죠 그쵸 이런 적이 한 번도 없었어.
이제까지 지하 또 지하셨어요 그렇죠 여러분 그게 이제 스티킹이라는 뜻이에요.
알겠죠 이렇게 여러 개 쌓아놓는 것도 한다. 그 스테킹이라는 뜻이에요.
여러분 이해되죠? 이렇게 하는 것도 잘 되는 경향이 있더라.
그래서 여기 보면 실제 이제 결과를 보면은 2.3으로 내려오는 거 여기도 약간 느린데 드라바우드 안 썼는데 드라바우드 안 썼나 드라바우드 드라바우드는 리코트라고 썼네.
뒤쪽에서 이렇게 어쨌든 아까보다 그냥 드라봤었을 때보다 스티킹을 하니까 50번에 아까 한 2.4까지 못 내려갔는데 가대 적합이 되죠 언젠가 빨리 그쵸 아까 드라바서 안 됐잖아요.
여기 가대 적합이 일어났죠. 어쨌든 그쵸 빨리 그걸 보여주고 있어요.
그리고 마지막으로 양방향 RNN이 나와야 되는데 양방향 RNN 교과서 이거 봅시다.

참석자 1 14:49
여러분 이게 그냥 이거는 교과서 408쪽 보면은 이거는 아까 온도 예측크 작업하는데 원래는 이제 옛날부터 그냥 데이터를 주입했는데 항상 뒤집어서 최근 것부터 넣어가지고 훈련시킨 거예요.
그리고 다음 거 쉽게 말하고 그래도 결과가 상당히 괜찮게 나온다.
여기 상당히 가려 적합도 일어나고 그렇죠 그런 걸 보여주고 있죠.
지금 숫자는 17번밖에 안 되는데 그렇죠 은근히 잘 된다.
그래서 그런 거를 보여주고 있고 그래서 특히 이제 NSTM이니까 또 이제 옛날 거 기억하니까 이런 게 된다.
그냥 그냥 심플하면 잘 안 되는데 그래서 이 실제로 여기 유명한 게 요 사립부 쪽에 있는 그림인데 교과서의 그림이 여러분은 여기 이거 입력이 아니라 이건 출력이죠.
바꿔야 돼요. 그쵸 그러면 이제 이게 입력이 들어가서 여기 출력이잖아요.
당연히 그렇죠 실수가 있죠 그쵸 잘못됐으면 고치세요.

참석자 1 15:54
입력으로 돼 있으면 출력이 그렇죠 말도 안 되지 그쵸 그래서 어쨌든 abcd가 자체 이제 원래대로 그냥 abcd 넣기도 하고 아래는 여기는 EDC b에 이렇게 서 훈련을 다르게 시킨 거지 얘는 이 두 개를 써서 얘를 이제 합쳐서 더 스템 할 수도 있고 컴퓨터네이트 할 수도 있고 그래서 그걸 가지고 이제 또 다시 또 하나 골라야겠죠 적당한 거를 그렇죠 그런 식으로 만들어서 쓰는 방식이에요.
알겠죠 이것도 바이드레이셔널도 은근히 많이 쓰여요.
쓰였었어. 지금도 여러분이 졸업 논문 쓰거나 막 이럴 때 그냥 막 이거 갖고 와서 그냥 트랜스폼 쓰지도 않고 이거 갖고 하는 사람이 있는데 좀 약간 좋지 않아요.
지금 시대에 트랜스포머가 더 가볍기도 해요. 사실 이거보다 무겁지도 않아 그래요.

참석자 1 16:41
그래서 심지어 근데 여기 또 이제 이게 교과서 사례 9쪽에 코드가 있는데 바이 디렉션을 하는 게 아예 빌트인으로 다 펑션으로 있어가지고 그냥 우리가 짤 필요도 없어요.
있어요. 바이 디렉션을 해 주면은 이렇게 넣어주면 얘가 두 개 만들어지는 거예요.
양쪽으로 아예 저렇게 아까 뭐 그리 했던 식으로 그런 게 되거든요.
그래서 편해요. 그런데 얘는 실제로 성능이 그렇게 안 좋게 나온대요.
근데 테스트 쪽에서는 잘 되는 경향이 있고 이렇게 바이러스 라이브 그렇대요.
알겠죠 그래요. 그냥 끝납시다 이러고 이러고 그다음에 412쪽에 주식시장에서 이거 쓰려고 시작하는 생각하는 사람이 많았는데 별로 잘 안 된다 이런 얘기 나와 있고 그렇죠 여러분 그래요.
그다음에 정보 차익 거래라고 이거 사실 거래 정보가 불균등해서 오는 거기 때문에 우리 정보가 없는데 어떻게 몰라 우린 정보가 없는데 어떻게 훈련을 시키냐 이 얘기예요.
알겠죠 불가능하다 그래요.

참석자 1 17:45
논문으로 자꾸 나오는 것도 별로 돈이 안 되니까 나오는 거지 조직해서 돈을 벌면 논문을 쓰겠어요.
이거를 우리 정보과학회나 이런 얘기가 나오는 거 해봤는데 안 되니까 당연하죠.
기술

참석자 1 18:00
그래서 다음 걸로 넘어가면 일이 텍스트 NLP지 NLP 텍스트 얘기하신 경우 여기에 이제 드디어 아닌가요?

참석자 1 18:16
이 주황색 먼저 보면은 여기에 여기 보면 주황색 페이지 이거 있죠.
이렇게 여기 여기에 11.4절의 트랜스포머가 나오죠.

참석자 1 18:32
뒤에 보면은 자연어 처리를 위해서 뭔가 텍스트 데이터 준비하는 거랑 단어로 표현하는 거 보면 이제 집합과 시퀀스 뭐 이런 게 나오죠.
그쵸 집합과 시퀀스는 순서가 없는 게 집합이고 순서가 있는 게 집합스잖아요.
그렇죠 단어를 앞에서 옛날에 그 이름이 뭐야 저기 우리 센티멘탈 어네시스라는 거 있잖아요.
영화 같은 거 가지고 그런 거 할 때 우리가 단어가 인코딩을 어떻게 썼어요?
토큰 가지고 결국은 숫자 만들어서 그다음에 원한 인코딩해서 원하냐 멀티아 됐죠 멀티아 이 단어가 있냐 없냐 갖고 있잖아요.
그쵸 그거는 시퀀스에요. 집합이에요. 집합이지 그쵸 그런 거죠.
이제 앞에서는 집합으로 했었어요. 그렇죠 근데 이제 시퀀스로 하는 거는 뭔가 순서가 있는 거지 다 문장에 그렇죠 문장의 단어들에 그렇죠 그런 거죠.

참석자 1 19:21
그래서 지금 집합으로만 해도 잘 되는 것도 있고 시퀀스로만 해도 잘 되는 것도 있고 뭐 그렇다는 거지 그 시퀀스로 해야지 되는 것도 있고 시퀀스가 훨씬 더 복잡하겠지 그래서 이게 그래서 이제 텍스트 분류할 때는 그냥 집합으로만 해도 충분한데 텍스트 분류하는 거 있었잖아요.
여러분 세티 멘터라이스 같은 거 근데 이제 뭔가 우리 세티피티 같은 거 하려고 그러면 그러면은 트랜스폼 같은 걸 써야 된다는 거지.
RNN이나 옛날에 rn RNN이 최고로 잘하는 거였는데 이제 클래스 훨씬 잘하죠.
아무도 RNN 안 쓰지 그리고 맨날 뭐 그래요 재민이가 재민 아이라고 그랬지 재민이 아이가 한 달 동안 무료래요.
여러분 좀 잘 만들었나 봐 나도 안 써봤는데 아직 아이스라고 우리 이때 사이즈 써주는 것도 좋을 것 같아요.
지금 전에 제가 구글 LM 설명했었잖아요. 노트북 LM 되게 좋잖아요.

참석자 1 20:19
어디서도 사실 걔네들이 만들었거든요. 걔네들이 알파고도 맨 처음에 했는데 오픈 AI가 더 떠서 되게 배 아프겠죠.
그렇죠 어쨌든 열심히 한 것 같아요. 그래요. 자연어 처리 쪽에 그래서 들어가면은 이거는 11.1절은 그냥 여기 다 보면 재미있어요.
여러분 그냥 언어 개발자 언어 공학자가 없어질 때마다 더 잘 되는 경향이 있는 거에 놀라는 그런 내용들이에요.
그래서 참 슬프죠. 여러분 외대가 왕악오악하시는 분들 엄청 많은데 이분들이 없어져야지 잘 된다는 그런 슬픈 얘기는 얼마나 기분이 나빠 그래요.
그다음에 여기 언어 학자를 되게 언어 학자가 없어져야지 잘 된다는 그런 스텝스한 얘기들이 있고요.
그다음에 그냥 넘어갑시다. 그래서 그래서 우리도 이제 막 이렇게 AI 어쨌든 어쨌든 여러분 외대 교수님들 계속 무시하면 안 되는 게 외대의 언어 쪽 교수님들은 우리나라가 최고로 잘 나갈 때 우리나라가 아니라 저기 계속 발전할 때 계셨던 분들이라서 서울대보다 높기도 하고 그랬어요.

참석자 1 21:24
커트라인이 그 당시에는 왜냐하면 돈을 워낙 많이 버니까 외대 나오면 돈을 워낙 많이 벌어가지고 근데 실제로 외대 사람들이 돈이 많지 그래서 진짜로 왜냐하면 해외에 수출하고 이러기는 돈을 훨씬 많이 벌잖아요.
저 제 친척 중에서도 이제 굳이 성균관대 서울대 떨어서 가자 주장하시는데 매대 가셔서 다시 돈을 어마어마하게 버셨지 사우디아라비아랑 모여 가셔가지고 그럼 어쨌든 그래서 뭐 지 며칠씩 전담해 어쨌든 무슨 얘기냐면은 그랬는데도 불구하고 지금은 이제 아니라는 걸 다 알고 계시기 때문에 더 굉장히 이제 소프트웨어 공급 쪽이나 이런 거 되게 교육을 열심히 시키려고 하는 거지 그냥은 안 하고 그래요.
대충 들으시고 그래서 그다음에 텍스트 데이터 쪽에 대해서 어떻게 처리할 것이냐 일단은 요 그림 볼까요?
여러분 텍스트가 있으면 이걸 이렇게 표준화시킬 필요가 있고 표준화라는 거는 좀 정형에 안 맞는 것들은 날려버리는 거고 토크는 좀 토크는 의미 있는 단위로 끊어버리는 거예요.

참석자 1 22:28
근데 여기 별로 얘가 그렇게 좋진 않은데 셋 같은 건 이제 불규칙 동상이니까 그냥 셋으로 나오는데 규칙 동사 같은 거 있잖아요.
스타드 같은 거 있잖아요. 스탑드는 중사 맞지 아닌가 ED 붙는 거는 ED를 따로 뗄 수 있다고 ing 붙는 거 아예 따로 떼고 알겠죠 그런 식으로 토큰을 한다고 이해되죠 여러분 그리고 토큰 각각에 대해서 옛날처럼 이제 하나씩 숫자가 붙죠.
그렇죠 근데 이거를 가지고 지금 여기 인덱스 벡터 인코딩이 적혀 있는데 여기 여기 보이는 건 여러분 지금 원한 인코딩 적혀 있는데 교과서도 틀렸지 이거 멀티 하시죠?
여러분 이거는 그렇죠 봐봐요. 여기 멀티 하시잖아 그쵸 멀티 하시죠?
이게 원하시지 요거 요거는 원하시지 얘는 우연히 그렇죠 근데 멀티샷이 섞여 있다는 건 멀티샷이지 뭐 그렇죠 그렇잖아요.
알죠? 여러분 그래요.

참석자 1 23:26
그리고 또는 임베딩이라고 나오죠 여러분 그렇죠 임베딩 개념이 되게 중요한데 실제로 지금 인베딩으로 거의 이제 자연어 처리는 트랜스포머 같은 건 임베딩이라는 걸로 하고 있는데 그것도 뭔지 봅시다 볼게요.
어쨌든 그래서 어쨌든 여기 벡터 인코딩이라고 붙어 있는데 벡터라는 게 이제 어쨌든 토큰 하나하나가 이런 숫자로 나오는 게 아니라 이렇게 뭔가 시퀀셜한 데이터로 표현되는 거잖아요.
숫자들이 여러 시퀀셔가지고 그렇죠 원하 인코딩도 여러분 멀티한 인코딩 다 시퀀스지 그쵸 순서가 중요한 숫자들의 모임이잖아요.
그쵸 그리고 인베딩도 그런 놈이거든요. 벡터예요.
벡터 벡터가 뭔지 알죠? 여러분 벡터라는 숫자들이 일렬 순서가 있는 거잖아요.
벡터 라이제이션이라고 부르기도 해요. 그래서 벡터화시켜야 된다고 항상 그렇죠 전에 멀티핸드 인코딩 만드는 것도 벡터화시킨다고 그랬었어요.

참석자 1 24:24
그죠 알겠죠 그래서 여기 교과서에 차례차례 이제 12.2.1에 텍스트 표준화 스탠다이제이션부터 하고 그래서 예를 들어서 이렇게 문장이 두 개가 이렇게 나왔는데 여기 보면은 또 여기 있어 이렇게 뭔가 다르게 생겼지만 세미콜론도 쓰고 왔다 갔다 하지만 이런 거 비슷하게 물음표 두 개 쓰고 이러는 거는 다 별로 중요하지 않으니까 이런 거를 그냥 표준화를 시켜서 이렇게 같은 형태로 만들고 한다는 그런 걸 의미하고요.
그다음에 그다음에 이제 항상 아까 그림에 나왔던 거 하나씩 하나씩 오는 거예요.
여러분 11.21에서 이제 토큰화 시키는 거 토키 쪼개는 거죠.
최소한 우리가 인식할 수 있는 단위 의미 있는 단위로 쪼개는 게 토큰화고 알겠죠 여러분 따로 설명 안 해도 되겠지 그쵸 그다음에 이제 뭐를 해야 되냐면 항상 그 토크 나 할 때 토크나 할 때도 여기서 나오는구나 토크나를 당연히 이거 보통은 다 이걸 얘기하죠.

참석자 1 25:32
여기 보면은 블릿이 나오죠. 318쪽에 3로 이어지면서 첫 번째가 단어 수준 토크나 두 번째는 앵그렌 토크나 세 번째는 문자 수준 토크나 이렇게 나오죠.
그쵸 세 가지가 나오고 있죠 교과서에 그렇죠 근데 저는 당연히 지금 단어 스토크나만 얘기했어요.
의미가 있는 단어로 그렇죠 근데 그거 말고도 변종이 이제 n그램이랑 문자 순이라는 게 있는데 n그램은 n이 이제 2나 3 뭐 이런 거 쓰는 거라서 두 개씩 섞어 쓰는 거예요.
그 두 개나 세개 그니까 예를 들어서 2 그램은 그러니까 2개씩 더 캣 시원 이런 식으로 이렇게 섞어서 2개씩 끊어버리는 거고 3그램은 3개씩 옛날에 워낙에 그 RNN 같은 거 쓸 때 잘 안 되니까 이 짓을 한 거지 여러분 키만 넣어주면 잘 안 되고 그러니까 히워드도 넣어보고 막 캐세스도 넣어보고 잘 안 되니까 그랬던 거였어요.
여러분 이해되죠 그러니까 지금 RNA에서는 이게 필요한데 이쪽으로 와서는 저 트랜스포머 쪽에서는 이런 짓 전혀 안 하고요.
그러고 그래요.

참석자 1 26:31
근데 앵글에 그리고 또 약간 그것도 있지 뭐냐면은 전에 원아 인코딩하고 멀티 멀티 핫 인코딩하고 해서 집합으로 만들어서 할 때도 앵그램 쓰면 더 잘될 때도 있죠.
그러니까 아예 그냥 키워즈랑 히 이즈를 다른 단어로 보는 거야.
토큰으로 그러면 뭔가 다른 의미기 맞잖아요. 사실은 근데 엄청 보키블러리가 늘어나겠죠.
그쵸 근데 이제 학습은 더 잘 되겠지 느리겠지 뭐 그렇죠 돈도 많이 쓰고 그렇죠 이도 많이 쓰고 그다음 마지막으로 문자 수준으로 하는 거는 이제 a b 그니까 더 캣이면 PH 이거 하나씩 하나씩 토크 나온다는 건데 이거는 소리 소리 음성 인식 같은 거에서만 필요하겠죠.
거의 그렇죠 그렇죠 소리 소리를 음향 이런 쪽 그래서 실제로는 그래서 그냥 보통 토핑 하면 이것만 얘기해요.

참석자 1 27:23
딱 그 다 단어 수준으로 하는 거 알겠죠 이해되죠 여러분 그냥 보통은 그리고 이제 여기 교과서에 그래서 419쪽에 앵그램 앵그램이 나와 있는데 2그램으로 한다고 그러면은 원래 이제 한 글자짜리도 있지만 원래 더 켓 셋 온더 메시면은 더 캣도 하고 더 셋트 더켓도 넣어주고 키 셋도 넣어주고 되게 많아지겠죠.
여러분 그렇죠 2개씩 2개씩 끊어가지고 이렇게 하는 거예요.
그러면 이제 단어가 이것만 해도 이렇게 지금 엄청 집합이 많지 그쵸 그래서 이거를 이제 이런 걸 모아가지고 이제 순서가 또 별로 안 이렇게 해서 순서는 다 없애버리기 때문에 백오브 월즈라고 불러요.
백오브 월즈 백기 여러분 원래 여러분 백이 그 셋 같은 거야 그쵸 셋을 백이라고 부르는 사람들도 있어.
자료 구조에 따라서 백이 가방이잖아요. 가방에 뭐 들어가면 순서가 없잖아요.
그래가지고 가방에 막 쳐놓고 어디 있어 뒤져야 되잖아요.
그런 걸 의미해서 백이라고 많이 불러요. 백업을 bow라고 많이 불러요.

참석자 1 28:26
백업 월즈로 집합을 만들 때 보통 이제 앵드림을 많이 써서 순서가 없어지는데 순서 없어지는 게 너무 괴로우니까 그래도 좀 두 개씩 묶은 것 정보도 넣어주고 회의시 묶은 거 넣어주고 이런다는 거예요.
알겠죠 그래가지고 그렇게 끝났고 지금 일단 속도나 얘기했고 지금 뭐 하고 있냐면은 사실 소수로 요거 요거 요거 표준화하고 토큰화하고 그다음에 이제 인덱스 붙이는 거 해야 될 거 아니에요?
그쵸? 인덱스를 붙이기 위해서는 뭐가 필요해요?
여러분 토큰에서 인덱스 같이 하려면 뭔가 토큰들을 구별해야 되니까 당연히 사전이라는 개념이 필요하죠.
뭐가 다룰 게 뭐가 있지 그쵸 거기다 번호 매기고 그쵸 인덱싱 매기는 게 인덱싱이라는 게 번호 매기는 거잖아요.
그쵸 추천 하나씩 뽑아내는 거죠. 그쵸 그래요.

참석자 1 29:06
그래가지고 지금 16.2.4 32 어휘사전 인덱싱인데 이거는 이제 여러분 외워야 되는 게 어휘사전을 보키블러이라는 거 여러분 보키블러리라는 말 여러분 그냥 다 쓰는 API가 있는 거니까 외워야 돼.
그렇죠 사전은 보키블러리죠. 어휘 어휘는 그쵸 어휘 사전이 보키블로리.
그리고 전에도 옛날에 여기 이제 드디어 나오는데 421쪽에 당연히 이제 모든 단어를 사전에 다 넣으면 너무 이제 인코딩할 때 힘들어지니까 뭐가 있냐면은 넘버로 워즈를 보통 제한하고 그래서 거기 넘어가는 단어는 여기 아웃오브 키밸러리 ov라고 하는 거를 그냥 다 보통 그쵸 쓴다고 그랬죠 그쵸.
사전을 끝도 없이 만들 수는 없으니까 사전의 어휘 개수를 우리가 보통 제한하고 거기에서 없는 거는 5v라는 걸로 표기하고 여기다 토큰 번호 하나 줘요.
1 2 4라 번호 하나 주죠 그쵸 그래서 보통이 이제 1로 한다고 그랬죠 그쵸 그리고 enk로 많이 나오기도 해요.
unk 언노운이에요.

참석자 1 30:19
언노운 unk라고 나오면 이게 언노운인지 알아야겠죠 여러분 그쵸 당연히 그렇죠.
그래서 unk 이렇게 나오면 이게 이게 플레임이 뭐냐 그러면은 언노운이라고 쓰는 거 싫어할지도 몰라요.
여러분 알겠죠? 눈치인데 사실은 공부 안 해도 알 수 있는 걸지도 모르지만 알겠죠 이거 모르면 좀 그렇잖아요.
알겠죠 up o v가 뭔지도 몰라도 안 되고 알겠죠 체험에 낸다고 알겠죠 클로즈드 북으로 이쪽 세계 공부했으면 모를 수가 없는 거라서 알겠죠 ov 보키밸러리 알겠죠?
unk가 어느 놈인지 모르면 간첩 그래요. 그다음에 여기는 또 마스킹 토크 그래서 이제 유명한 게 미리 예약된 토크들이네.

참석자 1 31:06
토큰 번호들이 이제 0부터 시작해서 쭉 갈 거 아니에요 근데 이제 의미를 매길 때 좀 밑에 저번에 01 2를 없는 걸로 봤었죠 그쵸 전에는 기억 안 날 것 같은데 영이 이제 여기 보면은 ov가 1번 쓰고 보통 약간 룰이야 세상에서 정해진 0번을 마스킹이라고 그래서 이제 실제로 단어가 아닌 거예요.
스타트 오브 센텐스 뭐 이런 거 있죠? sos라고 살려주세요가 아니고 스타트 오브 센텐스로 sos를 또 그렇게 부르기도 하고 마스킹이라고 부르기도 하고 그런 것들을 다 모아서 마스킹 실제로 뭔가 의미에 영향을 주지 않는 것들 있잖아요.
그런 거를 마스킹 토킹으로 해서 인덱스 0을 주고 단어가 아닌 것들이 그다음에 패딩을 하기 위해서 2번을 쓰기도 하고 그래요.
2번 그러니까 뭔가 자리 채우려고 그냥 이건 그냥 자리 채우는 놈이다 하고 0 1 2를 써버려서 전에 3개 다 원래 인덱스에서 3개는 사라지고 쓰는 거 있었거든요.
그랬어요.

참석자 1 32:02
어쨌든 그리고 이제 이거를 코드를 보여주고 싶어가지고 12.24에 텍스트 벡터라이제이션 층이라는 거를 실제 코드를 어떻게 짜는지 보여주고 있어요.
0이랑 1은 여기는 이제 무키 블로 해서 0이랑 코드가 보면은 이게 421쪽에 맨 마지막 줄에 보풀러를 만들 때 그냥 아무것도 없는 건 영 unk는 1 이렇게 뭔가 디셔리 만들어놨죠.
여기 이건 예약된 걸로 쓰려고 이러는 거고 그래서 스탠다이제이션 여기서 하나 쓰면 되겠다.
422쪽에 표준화하는 거는 거의 이제 로어 만드는 거 그렇죠 소문자로 만드는 거고 대문자 소문자 별로 상관없으니까 토크 아이즈는 스프링 시키고 그냥 썰렁하게 목표를 만들 때 이렇게 먼저 만들고 나서 그다음에 이제 각 데이터 쪽에서 겹치지 않는 거에 대해서 지금 이제까지 발견된 걸 넣으면은 이렇게 vka로 디시를 만들 수 있어서 각 단어별로 번호가 뭐다 이렇게 만들 수가 있는 거죠.
코드가 잘 익히나 여러분 그래요 됐어요.

참석자 1 33:07
이렇게 해서 만들면 돼 당연히 할 수 있겠지 그냥 이게 상식적으로 각 단어 유니크한 단어별로 번호를 부여하는 거야.
EBS 만들어주고 있는 거예요. 영일 제외하고서 그렇게 만들어주고 있는 거고 그래서 인코드 한다는 거는 지금 스탠다드 아이즈 토크 아이즈 한 다음에 고키블러리의 수정 겟을 하죠.
겟을 하는 거는 이게 뭐예요? 여러분 왜 그냥 요 딕션이 있는데 g을 하는 거는 이제 없을까 봐 그쵸 없으면은 1을 주죠.
1 언노운이죠. 그쵸 그렇게 해주는 거고 그리고 나중에 디코드 할 때는 게스트 데스트 없을 때 unk를 씌워주고 그쵸 이해되죠 여러분 단어가 없으면 사진이 없으면 이렇게 하고 있는 거죠.
그다음에

참석자 1 33:56
그다음에 실제로 데이터셋이 여기에 연습으로 이렇게 3개를 넣어주면은 결과가 여기 이 아이 라이트 라이트 t 리라이트 인 하면 이렇게 나옵니다.
아가 이고 라이트가 번호 매겨졌기 때문에 여기에 대해 이게 사전 전체라고 그러면 사전 이거 갖고만 한다.
그러면은 이 인덱스 맥이면은 2 3 이렇게 2 3 한 다음에 5 0이고 이랬나 보죠 그쵸 근데 1번이 뭐야 스테일은 단어에 안 들어간 거지 근데 이제 이런 식으로 하기 위해서 그래서 어쨌든 실제로 실제로 이게 여기 지금 아까처럼 이렇게 우리가 짜는 게 아니라 텍스트 베터라이이션이라는 이런 층이 있어요.
지금 423쪽에 맨 위에 두 번째 줄에 있어요. 그쵸 하위 3쪽 맨 위에 두 번째 줄에 있죠 그쵸 텍스트 벡터라이제이션이라는 거 뭐예요?
여러분 인포트하고 텍스트 있어야지 보이죠. 그쵸 테스트 벡트레이션이라는 계층이 있어요.
이거 갖다 쓰면 돼요. 갖다 쓰면 되고 그리고 이게 아웃풋 모드가 INT 나왔잖아요.
그쵸 인테저로 나오겠다는 거죠.

참석자 1 35:08
그러면 텍스트들이 그렇죠 이거 말고 뭐가 있느냐 뭐가 있는지가 교과서에 있는지 막 뒤에 쭉쭉 나오는데 이거 다 언제 가르치나 싶기도 하고 근데 뭐 있는지를 저는 이제 여러 번 왔다 갔다 했으니까 공부해 놨지 이거 말고 크게 세 가지가 더 있거든요.
크게 세 가지가 그게 미리 봐놓을까 426쪽에 가면은 466쪽에 가면은 여기 보면은 이제 426쪽 제가 422개를 표현한 했거든요.
여기에서 코드로 나오는 거는 바로 안 보이네요. 텍스 트레이지 코드는 이 안에 426쪽이 아니라 정확하게는 429쪽이구먼 429쪽 429쪽 봐.
429쪽 잘못 적어 놨네. 329쪽에 코드가 보이면은 거기 아웃풋 모드 한 다음에 멀티 아 보이죠.
멀티아 여러분 멀티아 보여요. 329쪽에 329쪽에 코드 11 3에 아웃풋 모드는 멀티알 이런 거 보이죠.
다시 할게요. 이거 코드 11 3이에요. 그 전체를 보고 하면 아 것 같아.
인텐드 말고도 14 이 멀티샷이라고 있잖아요.

참석자 1 36:39
여기자 멀티샷 그러니까 인테저 말고도 멀티샷으로 만들 수 있고 숫자 하나 튀어나오는 게 아니라 멀티샷으로 하면은 어떤 텍스트 문장이 들어온 거에 대해서 시퀀스를 아까 아까 yt랑 시퀀스로 쭉쭉 나왔잖아요.
이거는 멀티에서 어떻게 나오는지 여러분 상상이 되죠.
부피 별로 중에서 무슨 무슨 단어가 있음 하고 이 되는 거지 그쵸 그런 게 있고 그다음에 443쪽에 이거 멋지게 하시네.

참석자 1 37:11
왜 이렇게 다 이렇게 튀기려고 그랬지 433쪽이구나.
11시 9 11 9 4333쪽 11 9 거기 보면은 카운트라고 적혀 있죠.
그쵸 카운트 카운트라고 보여요. 여러분 카운트 그쵸?
카운트 카운트가 보이죠 그쵸 보이죠. 그 멀티아보다 좀 나아진 건데 멀티앗은 무조건 있다 없다를 표시하잖아요.
각각 0 0 나오고 1 0 아니면 1이면 이 나온 적 있어 이런 거잖아요.
근데 이건 카운트는 거기서 나아가서 뭐겠어요? 여러분 여러 번 나왔으면 그 개수만큼 0 1 뭐 아니면 세 번 나왔으면 3 적혀 있고 10번 나왔으면 열 적혀 있고 리라이트 같은 거 두 번 나왔잖아.
아까 리라이트 리라이트 보면 우리가 2로 표시되는 거 이 알람 옛날에 있다 없다만 구분했는데 얘는 이제 느낌이 오죠.
여러분 그런 것도 괜찮잖아. 그쵸 그렇지 않아요 여러분 그리고 하나 더 있는 게 마지막인데 현상 이게 334쪽에 코드 12시 10에 tfidf라고 적혀 있죠.

참석자 1 38:20
그쵸 tfidf 보이죠 여러분 이게 마지막 오인데 tfidf 이거 유명한데 tfidf가 저는 이게 순서가 이렇게 여기 보면 주황색 값으로 위에 있어요.
그쵸 주황색 값으로 CF IDF 정규화 이야기 적혀 있죠 그쵸 이게 보면은 이게 플레임이 적혀 있는데 어디 안 적혀 있네 플레임 안 적혀 있나 tfid 플레임이 433쪽에 적혀 있네 이야기야 433쪽에 맨 아랫줄에 적혀 있네.
tfidf는 텀 프리퀀시 인버스 다큐먼트 프리퀀시 적혀 있죠 그쵸 433쪽에 맨 마지막 줄에 tfidf의 플랜이 적혀 있어요.
텀 프리퀀시 인버스 다큐먼트 프리퀀시 적혀 있죠 보이죠.
여러분 그렇죠 단어 우리나라로 번역은 단어 빈도 영문서 빈도 이렇게 적혀 있네.
그렇죠 그렇죠 이게 뭔 소리냐 이게 이제 이것도 정교한 건데 일종의 보면 코드를 보면은 명확히 이해될 수가 있는 턱.
여기 보면은 아까 지금 우리가 카운티도 봤잖아요.
카운티 왜 하는지 알겠죠 여러분 몇 번 나왔냐 이거 보려고 하는 거잖아요.

참석자 1 39:49
그쵸 그쵸 그래서 여기 텀 피크시 큐드 프리커시는 뭐냐면은 아까 원래 우리가 카운트 했던 거 원래 다큐멘터리에서 몇 번 나왔는지 있잖아요.
이거 그게 아까 카운트로 했던 거죠. 그냥 이것만 썼던 거잖아요.
원래 카운트는 근데 이제 이게 이거보다 더 중요한 거는 다른 문서에서도 이게 얼마나 많이 나오는지가 더 중요하잖아요.
사실은 다른 문서에서도 많이 나오는 건 별로 덜 중요하잖아.
그러니까 예를 들어서 어나 뭐 이런 거 있잖아요. 다들 다 나오잖아요.
그럼 덜 중요한데 지금 요 지금 문장에만 있으면 예를 들어서 브릴리언 칸테스틱 이런 건 이 문장이밖에 없고 딴 데 안 나와 그러면 좀 중요하잖아요.
여러 번 나오긴 해도 여기서 많이 여기서만 이 문장에서만 되게 많이 나온 거야.
여기서 요 센세스에서만 이해되죠. 그래서 지금 여기 전체 데이스터 셋에서 지금 이게 몇 번 나오는지를 역으로 나눠준 거예요.

참석자 1 40:43
그러면 이게 원래 이제 그냥 숫자가 많다고 중요한 게 아니라 전체 다 다른 문서에는 없는데 여기만 많은 비율이 나오겠죠.
그쵸? 정규화가 되는 거지 어 같은 건 이제 되게 낮아지겠지.
어른 온데반데 다 나오니까 덜 중요한 거잖아요. 아이도 그렇게 별로 안 중요하잖아.
근데 주로 이제 이렇게 특정 잘 안 쓰는 단어가 여기 높아지겠죠 tfidf가 여러분 여행지 추천이나 이런 것도 또 그런 것들도 뭐 할 때도 맨날 나오는 건 별로 안 중요하고 가끔씩 나오는 게 중요하니까 뭔가 특성을 알려주는 거기 때문에 그래서 tfidf를 실제로 많이 써요.
알겠죠? 그래요. 그래서 tfidf는 외워야 돼요.
여러분 또 외워야 돼. 시험을 큰 등으로 낼 수밖에 없고 지금 한꺼번에 지금 제가 진도를 어텐션 좀 열심히 하려고 지금 이렇게 좀 나가고 있어요.
알겠죠? 됐어요. 슬라이드로 만들었거든 아깝잖아 해주고 싶어서 그래서 해봅시다.

참석자 1 41:40
여러분 이제 지금 일단 네 가지 나온 거 여러분 할 수 있겠어요 슬라이드를 이렇게 따로 안 만들었는데 그렇게 중요한 것 같지는 않아가지고 또 그런데 교과서에 이렇게 다 막 여기저기 섞여 있는데 나 이렇게 공부하면 너무 정신이 하나도 없어가지고 뭐 뭐가 있는지를 딱 아는 상태로 공부하는 게 좋지 않나 뭐 뭐였었다고요?
여러분 인테리어라는 게 인테리어 시퀀스라는 게 되게 자연스럽고 그쵸 그다음에 멀티야 그쵸 머치 아수라를 살 수도 있지 멀티앗이 훨씬 더 길겠죠 여러분 멀티앗은 전체 단어 보키블러리 크기만큼 있을 테니까 원래 시퀀스 그냥 인테저 시퀀스로 하면은 그 문장의 길이만큼 나올 거 아니야 인코딩이 벡터 길이와 다 제각각이겠지 멀티아으로 하면 다 똑같이 나오는 거고 다 뭔 말인지 알아요 여러분 몰라 지금 질문하세요.
여러분 한번 보여줘요. 그래요 합시다.

참석자 1 42:33
여기 보면 아까 어디 갔냐 아까 원래 보던 거 예를 들어서 한 거가 있었지 bow 하는 거 말고 그냥 장난으로 했던 거에 너무 많이 줄어가지고 그냥 원래 하던 거에 스펙트라이제이션 하던 거

참석자 1 43:02
요거 요거 요기 몇 쪽이 있냐 텍스 리트레셔스 사용하기 요기 몇 쪽이냐면 이거 인테저로 했던 거잖아요.
그래서 여기 보면은 아이라이트 유라이트 앤 아이 스틸 유라이트 게 이렇게 적혀 있는 건데 이거 몇 쪽이냐면 아이라이트 유라이트 여기 여기 422쪽에 422쪽에 인코디드 센텐스 하고 나오는 거지 인코드 해가지고 이거는 텍스트 벡터라이지 쓰는 거는 다음 쪽에 있구나.
이거는 합이 24쪽에 있는 거네. 합의 24쪽에 여기서 420 424쪽에 424쪽에 실제로 텍스트 벤트레이션 써가지고 하는 거가 나와 있는 거죠.
이거는 이제 아까 제가 얘기했듯이 423쪽에서 아웃풋 모듈을 INT로 해가지고 나온 거예요.
따라오고 있어요. 여러분 미안하네. 괜찮아요.
정신없는 것 같네. 약간 다시 해볼게요. 여러분 지금 우리가 제가 뭐 했냐면은 여기 423쪽에서 다시 할게요.
여러분 텍스트 미트라이징이라는 걸 처음으로 제가 얘기해 줬죠.

참석자 1 44:16
그리고 그래서 텍스트 디렉터라이제이션 층을 쓰는 거를 여기 이제 아웃풋 모드가 인태 INT라는 걸 써가지고 한다 그랬고 그쵸 그쵸 여러분 그쵸 그리고 실제로 이걸 써가지고 뭔가 커스텀하게 좀 대충 해가지고 텍스트 리트라이제이션을 쓰는 코드가 그 밑으로 있고요.
텍스트 트라이제이션 하는 게 그리고 여기 지금 가운데 INT 여전히 있고 스탠다드 자인이나 스플릿은 내가 만든 거 썼어요.
원래는 디폴트로 안 써도 되는데 여러분 이해하기 쉬우라고 이렇게 쓴 거예요.
여러분 원래 스탠다드 자이즈랑 스플릿이라는 거는 디폴트로 원래 쓰는 함수가 내부적으로 있는데 바꿔주고 싶을 때 이렇게 쓸 수 있어요.
이 교과서에서 그렇게 했어요. 이해돼요 여러분 미안해요.
여러분 괜찮아요. 뭐 하는지 알겠어요?

참석자 1 45:05
그래요 그래서 했을 때 그리고 이제 데이터 셋이 이건데 이거를 여기다가 어댑트를 시키면 이게 이제 전체 보케블 전체 데이터 셋이고 데이터 셋이 샘플이 몇 개 있는 거예요 3개 3개 그쵸 샘플이 3개 있지 한 샘플이 이렇게 하나 각각 이렇게 있는 거고 이게 각각이 이제 인코딩이 돼야죠.
그쵸 벡터 라이즈가 벡터가 되는 거야 그쵸 그쵸 원 하수로 하면은 보케블러리 하면 이제 어쨌든 여기 여기에 나오는 것만 하니까 그쵸 이렇게 되는 거죠.
여러분 이게 왜 이렇게 필요하냐면 여러분 여러분들 어떤 예를 들어서 지금 우리 학교 규정 같은 거 예를 들어서 막 이렇게 넣었어 규정이 막 많을 거 아니에요 문장들이 그렇죠 근데 거기서 쓰는 단어들만 이제 뭐 갖고 하는 거지 바뀔 건 필요 없잖아요.

참석자 1 46:02
이해되죠 여러분 그런 거지 그래가지고 거기 걸 이제 가지고 와서 겟 도큐블러리 한 다음에 근데 우리 어댑트라는 거 쓴다는 것도 봤죠.
여러분 어쨌든 적용하려고 그러면 데이터셋 넣는 거 오픈북에 내면은 쓰실 수 있으면 좋겠어요.
여러분 이거 따라서 이게 있다는 거 알고 그렇죠 어렵대요.
이거 별표 쳐 봐봐요. 그렇죠 어쨌든 아기도 이거 쓰려고 그러면 스트 써야 되니까 됐죠.
일단 이거는 좀 못 해가지고 일단 여기 고생하는 거 봐 오젝트를 써서 적용하는 이게 데이터셋이라는 걸 알려주는 거예요.
알겠죠 벡터 라이네이션 방법 알려주고 INT로 할지 머티 사주로 할지 아까 뭐 카운트로 할지 TF IDF로 할지 알려주고 그쵸 그래서 알려주고 48분이나 됐네 시작 해봅시다.

참석자 1 46:50
그래서 실제로 이걸 만약에 하면 테스트 센테스를 줘가지고 이제 얘를 가지고 아까 만들어놓은 거 가지고 어댑트에서 이제 사전 알려주고 했는데 새로운 단어 새로운 사전을 새로운 문장을 주고 하잖아요.
새로운 문장 새로운 문장을 주고 이제 인코드를 시켜요.
팩트라이즈 불러 부르면 이렇게 이렇게 7 3 5 9 이렇게 5 7 10 나온다고요 나와요.
그런데 이제 원래 이제 단어들이 이거를 이제 나중에 디코드를 해보면은 아 와트 r라이트 n 여기 나중에 이제 여기 uak가 나왔죠.
이 사전에 없었던 거지 여기 뭐야 t이 옛날에 학습시켰던 데는 없었던 거지 그래서 원론으로 나왔고 그쵸 이해되죠 여러분 이해되죠.
이거는 디코드 하는 방식은 또 이렇게 되는 거예요.
이해되죠 여러분 그렇죠 그런데 이제 보여주고 싶은 거는 요게 인코딩 했을 때 모습이 이렇게 시퀀스로 73,591 50으로 나오잖아요.
이게 이제 INT로 했을 때 이렇게 나오고 여기 일이 이제 언노운이지 그쵸 스트리 언노운이라서 그쵸.

참석자 1 47:56
근데 여기 보면은 오는 여기 리라이트는 두 번씩 나오고 막 이랬죠 그쵸 그런 상황이었어요.
그쵸 그래서 55 똑같은 게 보이죠. 그렇죠 오 그쵸 그리고 지금 제가 아까 뭐 있다고 그랬어요 이거 말고 인테리어가 제일 원시적인 거고 제일 기본적인 거 원시적인 게 아니라 원시의 근본이 근본이 돼.
근데 이러면 여러분 이게 실제로 다 인코딩이 다 다르게 되겠지 아까의 길이가 다를 때마다 길이가 다 다른 거 이해되죠 여러분 다른 건 이해되지.
근데 이제 똑같은 길이로 만드는 게 나머지는 다 똑같은 길이로 만들어요.
모스 멀티아 멀티아 하면 어떻게 되겠어요? 단어가 이게 전부 몇 개야 대충 하나 둘 셋 넷 하나 둘 셋 넷 다 일곱 여덟 아홉 열 10개지 10개의 무키블러리가 있죠.
여러분 10개의 토큰이 있잖아요. 그러면은 전체 원래 길이가 항상 10개로 고정이 되는 거예요.

참석자 1 48:46
이해되죠 10개 그리고 멀티 하시면 어떻게 되겠어 아가 여기 각각의 이제 다른 화면에서 여기 전부 다 여기인데 기본적으로 나눠 놓는 건 맞아.
아이 라이트 아이 라이트 레이지 리레이트 여기가 여기고 나머지 장용영 이런 식으로 되겠지 그게 멀티샷이죠.
여기 리라이트 두 번 나와도 한 번만 어쨌든 어쨌든 무조건 다 1 아니면 0이야 그치 멀티샷은 그렇지만 일이 여러 개 나오겠죠 그쵸 이 멀티 아시죠?
시간 다 됐네. 그다음에 마지막 두 번째 세 번째가 뭐야 카운트 카운트는 만약에 여기 이게 라이트였으면 라이트는 두 번으로 해주는 거지 그게 카운트죠 그렇죠 약간 멀티보다 약간 더 뭔가 정보 더 주려고 하는 거예요.
그쵸 이해돼요 마지막 tfidf는 뭐겠어요? 다른 데 나오면은 뭔가 정보를 여기 이걸 나누는 거예요.

참석자 1 49:32
다른 데 나왔는지로 단에 몇 번 나왔는지로 여기 지금 다 몇 번 나오는 똑같은 게 한 번도 안 나오네 분 나쁘게도 만약에 여기 아이도 있으면은 아이가 여기 아이가 리라이트 여기 라이트가 여기도 있고 여기도 있었는데 딴 데서 라이트가 맨날 나와 그럼 그것만큼 라이트가 온데온에 다 나오면 라이트가 100번 나오면 100으로 나오는 거지.
별로 안 중요한 거야. 라이트 나가면 평화 밖에 안 나왔으면 그냥 그대로고 점점점 이제 뭔가 숫자가 작아지는 거지.
많이 나오는 상황이 여기저기 이거 별로 안 중요한 거예요.
여기서 만약에 여러분 예를 들어서 여러분이 뭐 찾을 때 여러분 예를 들어서 우리 졸업 논문 규정이 찾고 싶어 졸업 논문이 여기만 나와 그러면 그 결기서 이게 중요한 거잖아요.
근데 온동 에 나오는 학사 학사면 그건 별로 안 중요한 거잖아요.
그쵸 학습시킬 때 관심을 가져야 되는 거를 카운트로 하는 게 아니라 tfit표라는 게 훨씬 더 바람직하죠.

참석자 1 50:22
그쵸 그래서 tfidf라는 걸 많이 써요. 알겠죠?
됐어요. 여기까지 하고 그리고 나중에 트랜스포머 가면은 이거 다 안 써.
인베딩이라는 걸 써요. 알겠죠? 지금 이거 지금 기억할 거는 텍스트 벡터라이제이션 한 다음에 벡터 라이즈라이션을 지금 배웠던 거 있죠?
뭐였어요? 다시 한 번 INT 멀티아 카운트 tfif 있었죠.
그리고 마지막에 임베딩이라는 건데 사실 제일 많이 쓰는 건 임베딩이다.
트랜스폼 마켓처 들어가면 나와요. 알겠죠 이렇게 정리를 아무것도 안 해도 되지 사실은 인터넷 찾아봐도 안 나올 걸 어쨌든 그래서 나는 사실 슬라이드를 만들어야 되는데 그냥 조까지 있으니까 안 만들었는데 알 거예요.
계세요 알겠죠? 처음에 이렇게 이거 다 적어봐라.
이런 건 안 낼 건데 알고 있어 봐야겠죠 됐죠 여기까지 할게요.


clovanote.naver.com