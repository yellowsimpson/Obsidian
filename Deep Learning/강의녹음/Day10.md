딥러닝 day10
2025.04.09 수 오전 10:02 ・ 49분 8초
심승환


참석자 1 00:01
2장 신경망의 수정체 개선

참석자 1 00:12
2.

참석자 1 00:19
집에 간다고 하지 마시고 여러분 지난 시간에 계속 보여드렸던 계약 정서 넣어주시고 고함수 얘기했었어.
판사 드리고 이분도 얘기했고 2.4.34 차이구나

참석자 1 00:42
2.4 교과서에 너희들이 그레디언트 기반 세대 4

참석자 1 00:59
87쪽에 있는 거죠. 187쪽 87쪽에 들어온 내용을 지난번에 하다가 멈췄는데 제가 슬라이드랑 겹치는 내용이 많아서 사실 근데 이제 한 번 더 이 책으로 다시 복습을 한다고 생각하고 봅시다.
중요한 내용이니까 이건 변하지 않는 영원히 변하지 않는 약간 좀 근본주의 근본이죠.
딥러닝에서 특히 딥러닝에 들어가서 분사량이 들어가니까 그래서 다시 이제 87쪽에서 아웃 80쪽에서 교과서에 이렇게 이런 내용이 있었잖아요.
그렇죠 여기에 이제 신경망이 항상 이렇게 다트 연산 정급이죠.
정곡 그죠? 하나씩 하나씩 곱하는 거 맞죠? 웨이트랑 드론 인풋 피처 그쵸 피처가 근데 이게 중요한 게 이 인풋이 다시 강조하지만 여러분 핸스플로우 플레이라는 데 서도 느껴봤겠지만 요전 단의 레이어의 인풋이에요.
그러니까 꼭 이게 진짜 인풋이 아니라 맨 처음에 데이터의 인풋이 아니라 레이어를 많이 쌓으면 그전 레이어의 인풋이에요.

참석자 1 02:12
그쵸 그런 거 알고 있죠? 여러분 이게 맨 처음에만 그런 게 아니라 항상 레이어로 우리 쌓잖아요.
그쵸 기억나죠? 여러분 이런 들이 쭉 있는 거 얘가 꼭 진짜 입력이 아니라 진짜 맨 처음에 데이터 인풋 데이터가 아니라 중간 레이어에서 튀어나온 뉴런의 결괏값이 요 결괏값이 다음에 또 인풋이 되는 거지 그쵸 인풋 중에 하나가 그런 식으로 돼요.
그쵸 이게 순서는 사실 거꾸로인데 그렇죠 그런 얘기했었고 왜 그런지도 알아요 순서가 진짜 왜 거꾸로인지도 알잖아요.
여러분 샘플리지 개수가 차원이에요. 여러분 차원 얘기 진짜 여러 번 했죠?
차원 인풋의 차원 인풋의 차원이 맨 처음에 배치 차원이 있죠 여러분 그렇죠 여러분 배치 차원이 유지가 돼야 되잖아요.
계속 배치 차원은 여러분 사실 여기 이것도 다시 핸스 플로우 플레이그라운드 다시 얘기해 드리면 어 블라드 스프로가 아니지 스프로 플레이 그라운드

참석자 1 03:24
이거 보면은 여기에 이게 사실 여러분 여기 계산하는 거 마치 제가 데이터 하나하나에 대해서 하는 것처럼 설명을 했어요.
계속 여기서 근데 사실 여기 지금 요 배치라는 게 있잖아요.
배치 사이즈가 10이죠. 여기 예를 들어서 그럼 여기 10개씩 한꺼번에 계산돼서 이게 값이 날아가는 거예요.
차원은 계속 유지가 된다. 끝까지 차원은 유지가 돼요.
그 차원은 대체 차원이 그쵸? 그러기 위해서 점검을 할 때 이렇게 정복을 하면 안 돼 거꾸로 돼야 된다고 인풋이 먼저 잡혀 있어야 된다고 그래야 맨 처음에 차원이 유지가 되잖아요.
이게 이게 정복하고 나면은 맨 앞에 차원로 사람들이 쭉 나 살아남고 중간에 이렇게 곱해지는 것이 날아가잖아 없어지잖아요.
알겠죠? 여러분 교과서가 이렇게 틀린 게 많으면 세상에 틀리면 이거 엄청 많겠죠 CTPT가 다 틀리겠지 그러니까 이해돼요.
여러분 CTPT는 다수가 말하는 걸로 그냥 맞는 줄 알고 살아요.

참석자 1 04:20
알겠어요 여러분 그래요. 차트 피치를 믿지 마세요.
알겠죠? 믿어야 그러니까 다수의 의견을 따르는 게 아니라고 이제는 그래요.
알겠죠? 그래요. 그래서 쿠아프로 다수의 의견으로 당첨되셨는데 잘 모르겠어요.
네 그래가지고 참 우리 어떡하냐 하류를 되게 재밌거든요.
어떻게 잘 난간을 극복하고 싶었어요 연구관 얘기해줄게 그다음에 계속 가면은 교화 함수에 이제 제가 89쪽에 교화 함수 여기 있죠 고함수 도함수가 이제 영어로 여러 가지 다양한 표현이 있어요.
그레디언트가 도함수죠 그쵸 디리버티브 그쵸 같은 말 사실 여기 도함수 얘기하는 건 91쪽에 얘기했지만 사실 디리버티브라고 그쵸 편미분이었어요.
그렇죠 편 도함수 그쵸 그래요. 그리고 무함수 이게 기울기라는 건 항상 미분이 가능해야지 뭐가 나와 그렇죠 미분이 안 되면 기울기를 알 수가 없잖아요.
그쵸 미분 가정해야 되고 그렇죠 미분 가정하는 것도 교과서에 89쪽에 맨 처음에 나오는구나.
그림 215가 매끄러운 함수라고 적혀 있지.

참석자 1 05:34
매끄러운 거 스무드 그쵸 매끄러운 게 영어로 스무드인데 스무드 해야지 이렇게 접선을 만들어가지고 그렇죠 기울기를 알 수가 있잖아요.
그쵸 딱 꺾어지면은 거기 기울기를 알 수가 없으니까.
그렇죠 잡손을 못 만드니까 그런 얘기죠. 그래요.
그렇게 돼 있고 그래서 91조까지 했어요. 지난 시간에 편도 함사 다 끝났어요.
우리 현미군 여러분 알아야 된다. 그래서 이분 무조건 안 좋았지만 내가 라스 그런 거다 이러면서 끝났어요.
그쵸 지난 시간에 치 그래요 다 했지 여기다가

참석자 1 06:16
뭘 보고 있냐면은 92쪽 9쪽 진도 진도 92쪽 쪽 천부라고 지난 시간에 안 했던 거.
그래서 여기 보면은 문단이 문단이 두 개 있는데 문단 2개에서 예를 들어 w1은 w 제로 마이너스 스텝 곱하기 뭐 이렇게 적혀 있는 거 보여요.
여러분 요거 요거 요거 요거 w1은 wb 예를 들어 요거 교과서에 있는 두 대밖에 안 돼요.
이거 보이죠. 여러분 그 부분이 의미하는 바를 다르게 다양하게 사람들이 막 얘기하는데 알아먹으라는 건데 이 제가 w1 w 제가 다른 w가 아니라 과거의 w가 w 제고 현재의 w 미래의 w가 w1으로 표시한 거예요.
여기서는 이게 사람들이 표현하는 게 다양하죠. 원래 w wo 하면 이제 원래 바이어스 때부터는 웨이트가 w 제고 첫 번째 피처에 여기 이런 식으로 하는 거잖아요.

참석자 1 07:13
여기 w는 그게 아니라 같은 w w j 같은 건데 wj가 이제 옛날 현재 wj가 wj고 미래 다음에 업데이트 하에서 바꿀 를 wg w1이라고 한 거라는 거 이해된 대안이 뭔지 다 알아먹죠.
여러분 이게 지금 무슨 말인지 모르면 골치가 아파요.
지금 그렇죠 무슨 말인지 모르면 안 돼요. 모르면 나한테 와요.
알겠죠 뭔 말인지 알겠지 지금 내가 이거 이거 미래 고칠 거라고 똑같은 놈이라고 이거 다 똑같은 배치인데 옛날 거 w 결은 옛날 거 지금 거 옛날 거라 지면 지금 거 w1을 바꿀 거 같은 거야.
그래요 근데 어떻게 바꾸느냐 사실 이게 w1 마이너스 w 제가 이 변화율이잖아.
사실은 그렇죠 그렇죠 뭐 하는지 알아요 여러분 지금 여기 그레디언트 w제에 대한 fw 제 있지 fw 제 그죠 그래요 fw제로가 정체가 뭔데 로스 로스 로스 로스겠지 여러분 딱 이제 알잖아.
로스 그쵸 손실함수 손실 함수 우리 최대 목표는 어쨌든 손실 줄이는 거예요.

참석자 1 08:22
그쵸 손실을 줄여야 돼. 그쵸 러닝하는 건 전부 다 여러분 뭔가 손실 에러 줄이는 거지 손실 함수가 에러죠 그쵸 에러를 줄이려고 해요.
그쵸 나 때문에 에러가 얼마큼 변하냐 그 기울기 있죠 그렇죠 베이전트 그쵸 그거를 빼서 그쵸 해결하는데 계속 업데이트하는데 그냥 업데이트하고 스텝이라는 거 죠 스텝 이 스텝이 정체가 여러분 사실 스텝이 아니라 뭐예요?
원래 원래 보통 제가 다른 데서는 뭐라고 불렀어요?
이스텔이라 안 부르고 알아야 돼. 여러분 제발 이제 이제 여러분 시험 봐요.
시험 봐. 스텝 말고 뭐라고 그러는데 원래 이게 정상적인 용어가 아니야 이게 교과서가 또 이분도 뭔가 쉽게 설명하려고 해서 정상적인 용어가 아닌 스텝이 아니고 뭐라고 그랬어요?
몰라요 여러분 실망이에요. 어 러닝 레이트 러닝 레이트예요 러닝 레이트 러닝 레이트가 더 정상적인 용어예요.
무슨 스텝이야 그쵸? 러닝 레이트야 외워요 외워 시험에 나와요.
내 거예요.

참석자 1 09:21
그레디언트에다가 러닝 레이트 곱해서 한다고 외워요.
러닝 레이트 왜 곱하는데 이거 값이 너무 커도 곤란하고 너무 작아도 곤란해서 적당 이게 사실 러닝이 보통 0.0000 얼마예요?
너무 많이 하면 이게 막 발산하거든 그쵸 그래서 러일레티 또 0.000001 00 더 너무 이제 안 될 것 같으면 너무 또 잘 사는 것 같으면 더 줄이고 막 이런 식으로 해요.
그렇죠 아주 잘 스케일이 잘 맞으면은 0.1로 할 때도 있고 이해되죠 여러분 보통 0.001 많이 써요.
알겠죠 그래요. 그리고 이 스텝이 여기 저기 스텝 적혀 있지만 사실은 여기 스케일을 조정하기 위한 자금 값 자극값 자과 값은 0.001 이 정도 알겠죠.
그래서 이게 용어가 이게 이게 이거를 스텝을 러닝 레이트 lr이라고 막 부르고 불러 li라고 많이 불러요.
lr 러닝 레이트 lr이라고 부르겠지 API에 막 나와요.

참석자 1 10:19
여러분 예를 들어서 저기 펜스 플로우니 파이토치 이런 데 막 나온다고 알겠죠 거기서 스텝이라고 그러지는 않고 비정상적이잖아요.
그쵸 lr이라 불렀다가 이제는 러닝 레이트로 그냥 약간 점점점점 있잖아요.
파라미터가 길어지는 경향이 있어 옛날에는 lr로 했다가 바꿨더라고 이제 이렇게 하면 또 컴파일이 안 되고 막 이래.
근데 얘네들은 하여간에 이쪽 세계 이쪽 뭐야 저기 텐스플로우나 파이프치 파이썬 하는 데 있죠.
그냥 컴파일 안 되게 만들어버려 그러니까 죽여버린다고 사람 디플리 케이트 해가지고 API가 바뀌어가지고 옛날에 이렇게 했던 코드가 이걸로 바꾸고 안 돌아가게 만들어 놓는다고.
근데 지금 저한테 우연치 한 친구들 그쪽은 그냥 워닝 하면서 너 아니야 혹시 막 이러면서 버전 바뀌면 죽이진 않는데 혹시 혹시 내가 번호 바꿔서 했는데 실수하는 거 아니야 이러면서 그냥 워닝만 하고 그냥 넘어가죠.
워닝은 여러분 아니야 그냥 친절한 거지 친절한 거지.
근데 얘네들은 그냥 안 돼.

참석자 1 11:16
코드가 맨날 안 돌아가 버전 바뀌면 그렇다고 어쨌든 예를 들어서 이제 어쨌든 이런 용어가 그래서 사람들이 이제 lr이라는 게 뭔지 모를까 봐 이렇게 바뀌었어요.
이 텐서플로우 같은 경우에는 어쨌든 여러분 용어를 알아야 되는 게 중요한 이유를 알겠어요.
여러분 여기 교과서는 왜 스텝이라고 했냐면 약간 또 러닝 레이트 하는 게 이 사람은 식상한 거 싫어해가지고 다 바꿔버렸어.
지금 약간 교과서 쓰는 사람들 좀 그렇잖아요. 좀 뭔가 나의 뭔가 인사이트를 주고 싶은 거지.
근데 이게 스텝인가 스텝 사이즈라고 부르기도 해요.
사람들이 이거를 러닝 레이트를 왔다 갔다 하는데 사실 나는 이게 스텝 같아 이 곱하기 전체가 부포가 전체가 스텝 발자국이잖아 한 번 옮기는 거니까 난 이게 이게 전체가 발자국 같다고 느낀다고 어떤 교과서는 이거 전체를 스텝이라고 불러요.
스텝 사이즈라고 불러요. 어떤 교과서는 교과서 바꾸는 게 취미인데 이번에 안 바꿨는데 알겠죠?
여러분 그래요.

참석자 1 12:09
너무 이제 제가 지겨워가지고 똑같은 거 못해서 안 바꿨는데 이길 것들은 자꾸 팔굽나면 뭐가 더 나와가지고 냅두고 있어요.
괜찮은 것 같아요. 이길 것 제가 진짜 그래요. 그래서 그거 여러분 이해하시고 알겠죠 그다음에 2.4.3절이 확률적 경사학은 또 돼 있잖아요.
확률적 이거 영어로 뭔지 여러분 영어로 뭐였어요?
이거 이거 사실 약간 한글로 배우면 안 좋은 점이 이거 여러분 사실 영어가 더 중요하거든 왜냐하면 펜서플라 파이토치 이런 거 라이브를 했을 때 전부 다 영어로 나오는데 이렇게 나올 리가 없잖아요.
영어로 이거 뭔데 여러분 나한테 배웠거든요. 그치 병상학 영어로 배웠어요.
나한테 그냥 이거 영어로 봤으면 더 나왔어. 사실은 경상관법이 영어로 뭔데 일단 그리드 디스트예요.
여러분 이거 외워요. 우리나라 말로도 공부하는데 빠르게 하기 위해서 알아야 되는데 사실 영어로 아는 게 되게 중요해요.
여러분 그리드 디슨트예요.

참석자 1 13:03
여러분 알겠죠? 여러분 이거 드레디슨트 시험에 나와요.
확률적은 뭔데 확률적은 원래 프레버블리스틱이잖아요.
근데 그게 아니에요 여기서는 나한테 배웠다니까 나 슬라이드에 있어요.
여러분 미니 배치 미니 배치 나오기 전에 미니 배치는 미니 배치지 그 위에 있는 거 있잖아요.
외워봐. 여러분 여기 안 적혀 있어 이게 문제야 번역이 여기 확률 제 93쪽 가 보세요.
93쪽 93쪽 93쪽에 확률 적하고 신나기 씨 있고 가로 열기 스톱 적혀 있죠.
93쪽에 a 4 5 나오고 아주 쉽네 하고 나온 다음에 확률적 하고 나오잖아요.
그 진한 글씨로 확률적이고 뭐라고 나와요? 여러분 토캐스틱이에요.
알겠죠? 이거 gd야 SDD SGD 성균 변사극 제목이 사실은 영어로 영어 책에서는 영어 책도 샀는데 스토캐스틱 브레드디스트로 돼 있어요.
영어 책에. 근데 그 용어를 알아야 돼.

참석자 1 14:06
사실은 이 코뮤츠 전사방법이라는 용어를 아는 게 아니라 왜냐하면 파이2 치나 도 되게 이게 똑같이 거기서는 s 치라고 부르겠지 누가 확률적인 상환법을 부르면 모를 거 아니에요 여러분이 그렇죠 어쩔 수 없이 영어를 알아야 돼.
그렇죠 시험 범위 알겠다 이런 거 알겠어요 SGD 알겠죠 그거에서 뭐라고 나오냐면은 여기 여기도 벌써 나와 있네.
또 여기도 여러분 여기 93쪽에 5번 있죠 5번 5번에 w 마이너스는 러닝 레이트 곱하기 그지 적혀 있죠.
여기 러닝 레이트로 바뀌었지 다시 제대로 그쵸 아까 스텝이라고 불렀던 거 그거 다시 보시고 그레디언트가 뭔지도 알잖아요 여러분 그쵸 그쵸 그레디언트가 여러분 정확히 뭐라고요?
여러분 이 w에 대한 에러의 변화율이야 그쵸 다양하게 표현할 수 있어 로스트 펑션의 변화율이라 할 수도 있고 그렇죠 이 w에 대한 그쵸 그쵸 여러분 이 w가 w 마이너스 하면 이제 한꺼번에 되잖아 비례 것과 가압해서 다 한꺼번에 되잖아요.

참석자 1 15:10
그렇죠 이 다양한 표현이 가능하다는 거 이해되죠 여러분 그쵸 그래요.
제가 그래서 이거 만약에 시험에 w 마이너스는 한 다음에 가열 가로 곱하기 그레디언트 하면 러닝 레이트가 나와야 되고 러닝 레이트 곱하기 가로 나오면 그레디언트가 나와야 되고 그거밖에 없잖아 답이 그렇죠 알겠죠 그래요 이렇게 치사하게 어쨌든 뭔지 알겠죠 여러분 그래 그다음에 달달 외우지 말고 얘기하세요.
여러분 그다음에 미리 그리고 이게 교과서에 나오는 게 방금 전에 이야기하는 것이 미니 배치 확률 석 경사각법이 적혀 있죠.
그쵸 교과서에 미니배치 스토케스티크레드 디센트라는 굳이 말을 썼죠.
그래서 이게 이제 애매하니까 93쪽에 93쪽에 이제 다시 다시 보면은 여기 여기 여기 교과서 보여주고 싶은데 이런 이게 밑에서 진정 여기 93쪽에 아래에서 두 번째 단락에 진정한 STD라는 것도 적혀 있는 거 보이죠.

참석자 1 16:14
여러분 프로 STD 그쵸 93쪽에 두 번째 아래 두 번째 단락에 두 번째 줄에 진정한 SGD라는 것도 있죠 그렇죠 진정한 sga가 하나만 하는 거고 저거 설명 다 들었죠 저한테 그렇죠 그래요.
그러니까 제가 얘기하는 게 여러 가지로 나온다는 거죠.
알겠죠? 그래요. 이거 그냥 여러 번 말 들으면 더 잘 이해될 것 같아서 제가 지금 이러고 있어요.
알겠죠 다양하게 똑같은 말을 배우면 이해가 잘될 것 같아서 단단히 외우지 말라고 그런 얘기했고요.
여기 로컬 미니바 이런 얘기 다 나와 있는데 그래서 여기 보면은 94쪽에 보면은 94쪽에 이제 뭐 하는 거냐 경사 하강법이 결국은 원래 이제 랜덤하게 웨이트 값이 정해져 있다가 일로 와서 그쵸.
일로 와서 지금 로스 값을 최선으로 하겠다는 거고 지금 이게 색깔이 로스 값이겠지 그쵸 그리고 이 그림이 지금 이렇게 막 2차원으로 되어 있는 거는 최소한 파라미터가 2개라는 얘기야.
그쵸 사실은 파라미터가 2개가 아니죠.

참석자 1 17:19
여러분 엄청 많지 얼마나 힘들겠어 그쵸 파라미터가 2개가 아니라고 근데 이거를 여기 찾아가는데 이쪽 방향으로 갈까 이쪽 방향으로 갈까 막 고민되잖아.
그쵸 이쪽 방향으로 제 빨리 가게 해주는 게 이제 아티마이저라는 거라고 그랬죠.
그쵸 아티마이저가 여러 가지 기법이 있어가지고 값이 빨리 줄어드는 쪽으로 더 가속해서 막 가보고 이러는 거 있잖아요.
스텝을 막 확 늘려버리고 막 이런다고요 여기 저 잘 되는 것 같으면은 갑자기 성적이 이렇게 좋아졌어 그러면 그 방향으로 더 강화시키고 이러는 거죠.
그쵸 훈련을 더 거의 강화시키고 이러는 거 그냥 똑같이 훈련하는 게 아니라 그렇죠 그래요.
그런 얘기가 있는 거죠. 그래서 여기 694쪽에 지금 시한색으로 최적화 방법이라고 또는 옵티비아이저 같은 말이라고 돼 있죠.

참석자 1 18:03
여러분 최적화 방법 최적화 방법 옵티마이저 이거 전부 다 그레이저 웨이트가 업데이트하는데 어떻게 할 거냐에 대한 취득 이라는 거죠.
그리고 여러 변종에서 모멘텀 개념이 중요하다고 적혀 있죠.
그쵸 모멘텀 모멘텀 열은 뭐야? 가속시키는 거지 그쵸 모멘텀 열 물리에 있는 거지 그쵸 변화량 이런 건데 그래요.
그래서 그런 게 있고 95쪽 그림에도 지역 해수가 전역 해수가 그림이 있다.
그렇죠 제가 설명 잘했죠. 그렇죠 열심히 그쵸 알죠 여러분 이게 뭔지 여기는 플래투로 또 빠졌네.
그치 플래트도 사실 중요한데 평면이 있는 거 이 교과서는 이렇게 빠져 있는데 사학 교과서에 많이 나오는데 이거 그래서 이 책이 약간 좀 부족한 게 있는데 핸존 머신러닝이랑 진짜 차 좋아요.
그 책 뒷다발로 찍는데 그 책이 거의 레전드야.

참석자 1 18:51
근데 제가 맨 처음에 그 책을 하다가 머신러닝이라서 제목이 이제 여기 그게 빠졌어.
플래트 개념이 있잖아요. 지금 평평하면 못 가잖아.
거기서 이제 기울기가 없는 줄 알고 그쵸 더 이상 내려가서 말 못하잖아요.
그 개념 보세요. 그래요. 그다음에 그다음에 이제 2.4.4절이 96쪽이 역전파 알고리즘이 이제 나오는데 역전파 알고리즘 백프라포데이션 알고리즘이라고 저기 한글 영어로 바로 2.4.4절에 첫 번째 단락인데 마지막 문장에 네 번째 줄이죠.
있죠 그쵸 8모니즘 팩트라 표기 알 보이시네요. 그쵸 어디 있냐면 여기 여기 교과서를 보여주고 싶어 교과서에 역점 알고리즘이나 나오는 거 보이죠.
여러분 안 돼요. 14페이지 이거를 설명을 이거를 교과서 갖고 하면 너무 오래 걸릴 것 같아.
그래가지고 제가 옛날에도 항상 만들어놓은 게 있었는데 또 빨리 설명하는 걸 계속 고민하고 있어요.
아 이거 다음에 줄게요. 이거 이게 고 계셔야 돼.

참석자 1 20:00
빨리 점령하면서도 뭔가 인사이트가 있는 거를 저는 지금 인사이트를 기르고 있는 중인데 기대하시라.
여러분 아직 못 만들었어요. 더 해볼게요. 좀 약간 더 준비해 볼게요.
지금 이건 너무 길어서 설명해 이렇게 길게 설명해야 되는 게 결론인 것 같아서 그래서 너가 맞고 그다음에 설명해 줄게요.
여러분 섹트라포게이션 체임론 이런 얘기 있는데 좀 더 뭔가 좀 잡힐 듯한 설명을 하는 게 필요하겠죠 그죠?
전혀 그렇지 않아서 그리고 2.5절에 그래서 넘어가고 그냥 2.5절은 2.5쪽 2.5 대기 쪽 대기 쪽에 있는 거 대기 쪽 대기 쪽을 봅시다.
여러분 베기 쪽 대기 쪽에 그림 요거 녹화할 때는 이거 설명 녹화 못했으니까 그래가지고 다시 여러분 이걸 의미하라는 거죠.

참석자 1 20:52
이게 정체가 어쨌든 층 층 막 이렇게 나오고 이 하나 서 넣을 게 많고 그렇죠 마지막에 예측 값이 나오는데 실제로는 이거 갖고 이렇게만 돌아가는 거는 완전히 그냥 인플런스 할 때만 그런 거고 실제로 이제 우리가 트레이닝 할 때는 손실 함수를 단수 구해서 그쵸 진짜 타깃 넣어가지고 손실 함수를 구하기 위해서 진짜 타깃이 진짜 값이 있어야 되고 그래서 손실 값이 나온 걸 가지고 가중치를 업데이트를 해야 돼요.
그쵸 업데이트를 근데 다중 차액이 지금 여기 되게 많고 여기도 되게 많잖아요.
그렇죠 이거를 어떤 놈을 확 줄이고 어떤 놈을 갖고 그냥 조금만 변하고 이런 거 있잖아요.
이런 거를 옵티마이저라는 놈이 해주는 거예요. 얘 때문에 그러니까 이게 보면 변화율이 되게 큰 놈이 있고 작은 놈이 있고 그럴 거 아니에요 여러분 이해되죠?
어떤 예를 들어서 오른쪽으로 자전거 타고 오른쪽으로 넘어지고 있으면 사실은 몸을 왼쪽으로 기울이는 거 있잖아요.
이게 굉장히 중요하잖아요.

참석자 1 21:47
다른 거 허리를 세운다 안 세운다 아니면 눈을 앞뒤로 한다 이런 거 덜 중요하고 그렇잖아요.
그러면은 그렇게 확실히 영향을 주는 놈 그 변화율이 큰 놈 있잖아요.
그놈을 확실히 변해야 될 거 아니에요 그래서 그렇죠 그런 거를 옵티마이저가 해준다고요.
이게 변화율이 큰 놈에 대해서 더 업데이트 변화 많이 시키는 놈을 한다고 하는 거 이걸 사실 다 수학인데 다 은근히 당연해 은근히 다 그렇게 안 하면 어떻게 할 건데 약간 이런 게 있어요 알겠죠 여러분 그리고 이거는 벌써 다 익었으니까 이것도 나중에 이제 머티어예요.
지금 여러분이 여기서 뭔가 더 할 건 없어서 그냥 쓰면 돼 알겠죠 그리고 이것도 웃긴 게 약간 또 이것도 여러 개 보는 게 더 낫다는 게 결국은 결론이지 뭐가 좋을 데이터에 따라서 뭔가 리얼 레트워크 형태에 따라서 다르고 여러 가지가 뭐가 좋을지 모르니까 여러 개 해보고 결국은 여기 매장 교과서는 RMS 스트롭이라는 거 쓰거든요.

참석자 1 22:35
옵티마이저가 여기 지금 맨날 아르베스 플랍 쓰시는데 아르베스 아르베스 플랍이 여러분 플린이 뭘 것 같아요 여러분 루트민스퀘어 프라토게이션이겠지 뭐 그렇죠 아니 이제 이제 여러분 툭툭 하면 저 알아야 된다고 약간 외워야 된다는 거지 용어를 그쵸 RMS가 뭔데 알아야 된다고 알겠죠 이 시험을 다 낼 거예요.
알겠어요 이거 모르면 약간 이상한 루트 민스케어 그쵸 미니 그게 min인가 mean인가 그거 min이라고 그러면 바보 알겠죠 채소가 아니야 그쵸?
뭐예요? 평균이야 평균 알겠어요 여러분 사실 채소 만드는 거 맞거든 거 근데 민스퀘어가 지금 평균 일단 그렇죠 어때요?

참석자 1 23:22
여러분 좀 약간 약간 뭔가 개념이 제대로 잡힌 사람과 안 잡힌 사람을 구분하는데 약자를 아느냐 모르느냐가 플레임 아느냐 모르느냐가 굉장히 중요하거든 그냥 외우고 있는 사람인가 의미를 알고 있는 사람인가 그쵸 그래요 어쨌든 이게 아티마이저 여기에 대해서 이제 여기 그림 읽는 당연히 이렇게 이제 좀 그렇죠 알겠죠 여러분 그다음에 교과서에 13 이거 뭐 제가 이거 강의도 열심히 해놨으니까 넘어갈까요?
그래요 이거 보면은 이거 봅시다. 여기서부터 예 대기 쪽 대기 쪽부터 뭐야 대기 쪽 먼저 입력돼 이탈이 있다고 나오죠 대기 쪽에 아래에 코드가 나오죠 그쵸 코드 보이죠 여러분 그래요.
요거 요거 요렇게 로드 데이트 하고 그렇죠 맨 처음에 그러면 여기 이제 데이터가 들어가죠 그쵸 위에 배치 그쵸 크기만큼 들어가면 원래 이제 이게 m 리스트 로드 데이터 하면 7만 개인데 스레인에다가 6만 개 해주고 여기다 만 개 해주고 이러는데 이거 외울 필요 전혀 없죠 그냥 그랬다는 거지 그렇죠 그랬어요.

참석자 1 24:26
여기 보면 그래서 교과서에 103쪽 위에 필름 데이터가 6만 784 이렇게 나오잖아요.
그쵸 이렇게 나오는 게 사실은 원래 트레 이미지 자체가 원래는 이게 원래 이거 이거 이거 쉐입은 6만에다가 20 4 28이지 28 28이거든요.
원래 이렇게 3D였어요. 이미지지만 이제 얘가 채널이 하나라서 흑백이라서 이렇게 돼 있었는데 근데 이거를 류쉐입을 해버렸죠.
그쵸 그래서 이렇게 류쉐입 할 때 여러분 원래 이렇게 쉐입을 튜플로 줘야 돼 튜플로 그쵸 그쵸 여러분 콤마 이 괄호 있어야 돼 알겠어요 여러분 됐어요.
여기 제가 여기 여기 이거 이거 마이너스 1 같은 거 주면 된다고 그랬죠 여기 제가 강의 자료 녹화했는데 그렇죠 그냥 어차피 당연한 거니까 당연한 거는 마이너스 주면 알아서 채워주죠.
그쵸 일일이 다 보통 이렇게 안 해. 보통 코드 쓸 때는 다 여러분 마이너스 1 쓰는 게 더 멋있어.
그렇죠 그렇잖아요.

참석자 1 25:31
여러분 이거 6만 알았으면 여기를 마이너스 죠 6 만났으면 여기를 마이너스 있죠 여러분 그렇죠 나머지는 그냥 실입 맞춰 주는 거니까 어차피 엘리먼트 개수만큼 나머지 채워줄 거 아니에요 그쵸 그 차원이 여러 이거 다 마이너스 쓰면 미친 짓이고 그렇죠 어떻게 하라는 거예요?
그쵸 하나는 마이너스를 쓸 수 있다는 거예요. 알겠죠 그래요 마이너스를 안 쓰면 더 멋없다고 써도 멋 없는 게 아니라 사실은 그냥 당연히 그렇게 한다는 거죠.
보통 이제 28 곱하기 28을 아니까 여기 마이너스 1 채우고 여기 마이너스 1 채우지 그냥 보통 해보겠습니다.
잘 모르겠으니까 굳이 알아보기 싫으면 그렇죠 이해되죠 여러분 그래요.
그다음에 여기 굳이 이제 또 원래는 얘네들이 다 이게 트레인 이미지 얘네들 데이터가 이게 28 곱하기 28에 이태저거든요.
uint 파일이에요.

참석자 1 26:19
그쵸 이미지 uint 파일이라는 거 여러분 했죠 그쵸 이게 정체가 뭐냐면 0부터 255까지 그쵸 그런데 이거를 여기 플로팅으로 포인트로 바꿔버리죠.
그쵸 그리고 250으로 나눠버리지 그쵸 그래서 0하고 이거 뭐 한 거예요?
여러분 스케일링 한 거죠. 그 피처 스케일링 할 때 그렇죠 0하고 이사회로 바꿔버렸어요.
그렇죠 0하고 의사로 바꿔버렸어. 0하고 1 사이로 전부 다 피츠 스케일링 해버린 거예요.
피트 스케일링 기억나죠 여러분 크게 두 가지 방법이 있죠.
왜냐하면 평균 표준 편차를 0하고 1로 만드는 거랑 스탠다드 제이션이랑 그다음에 민맥스 스케일링 그쵸 그거 두 가지 있었잖아요.
제가 강의 자료 있으니까 그거 한 거예요. 그쵸 그리고 왜 그러면 윈맥스 스케일링을 주로 하느냐 그냥 이게 전부 다 같은 스케일링이면 좋으니까 학습하기가 파라미터 비슷한 게 좋지 맞잖아요.

참석자 1 27:09
그렇죠 그것도 있었고 또 이게 기본적으로 소수로 연산하는 게 최적화되어 있기 때문에 GP나 이런 쪽이 소수 연산하기 좋게 소수로 만들어주는 거 영화 이 사이로 알겠죠 그래요.
어쨌든 보통 이렇게 해요. 에지 타입으로 해도 되고 사실은 이거 나누기 그냥 255점 이래도 돼요.
사실은 점 하면 여러분 소시자 그래가지고 근데 뭐 그런 거는 남들이 이제 코드를 오픈 소스 같은 거 보면 여러분 막 다양한 표현이 있는데 그게 왜 그런지 알아야 되니까 제가 설명해 준 거고 그리고 무조건 그런 거 나왔을 때 여러분이 그냥 넘어가지 말고 채팅 피트한테 물어가지고 이렇게 설명 잘해주거든요.
그런 건 안 틀려 물어봐요. 다 이해하시면서 하세요.
알겠죠? 그래요. 지금 시험에서는 최초부터 뭐 써요?

참석자 1 27:51
여러분 그다음에 이거는 이 지금 모델 데이터 준비하고 그다음에 이 모델 자체가 썰렁하게 이렇게 뭔지 잘 모르겠지만 시퀀셜하게 댄스 댄스 이렇게 적혀 있네요.
그쵸 댄스가 잘 뭔지 모르지만 댄스가 밀집이라는 뜻이죠.
그렇죠 밀집 뭔가 똑같은 한 건데 서로 다 연결하는 거라서 데스라 부르고 있어요.
웨이트로 해봐. 무조건 다 만들죠. 그쵸 무식하게 앞에 거랑 뒤에 거랑 그쵸 층별로 그렇죠 그래요.
여기 50cd의 정체가 뭐냐 이런의 개수. 그쵸 강의를 또 하고 있는 녹화할 때 사실 다 했을 것 같은데 그만 해야지 그래요.
됐죠 여러분 여기 이게 정체가 512 저기 다 뭐냐 잠깐만요.
이거 왜 마우스가 어디 갔지? 얘 때문에 그렇구나.
여기 보면은 여기 댄스 5102 10이잖아요. 여기서는 아까 텐스 플로 되는 여기 여기 얘 얘 얘 지금 댄스가 얼마 이걸 코딩했으면 댄스가 얼마일까요?

참석자 1 28:54
여러분 4 맞아요. 알겠죠? 이해되죠 여러분 여기는 두 개고 여기 마지막에 이게 한 개가 있는 거예요.
여러분 이 마지막에 데스트 1이라는 게 있는 거예요.
여기 이해돼요. 여러분 보세요. 여기는 지금 계층이 하나 두 개 있죠?
여기 있는 계층이 여기 이거 명확히 이해하시라고요.
계층이 이거 입력이에요. 그쵸 하나 둘 세 개 있는 거예요.
알겠어요 출력도 출력도 개수로 공개된 거다 알겠죠?
이해하세요? 여러분 아니면 데스 1이 있는 거예요 데스 1 왜냐하면 여러분 선배들이 진짜 모르더라고요.
내가 일부러 강조하는 거 여러분 선배들이 저한테 러닝을 시켰지 강조하라고 다 틀리더라고 알겠어요.
시험에 이런 걸 내는 게 아니라 이걸 모르는 것 같아.
잘 출력도 여러분 계층이야 플루트 계층으로 넣어야 돼.
알겠어요 여기는 지금 아이고 이 사실 여러분 이게 충격 계층이라서 딥율 네트워크이 아니고 사실은 그냥 켈로우 뉴 네트워크 알겠죠?

참석자 1 29:59
여러분 네 그래요. 그다음에 여기 액티베이션 10개가 마지막에 10개가 나왔어요.
이건 왜 그러냐 소프트맥스로 해놨잖아요. 소프트맥스가 여러분 다 더하면 1 되는 거랬죠 여기 출력 값을 전부 다 10개인데 10개의 값이 다 더해서 1 대 1 무조건 만들어주는 거예요.
원래 값이 이상하게 튀어나와도 그래서 이게 10개의 확률이 나오는 거지 이게 정체가 뭐냐면 n 리스트라서 숫자 0부터 9까지 숫자의 확률들이거든 같아 그렇게 해 학습시킬 거라 가지고 그랬어요.
여러분 여기 넬로 안 쓰면 여러분 미친 짓이고 그렇죠 여기 여기 비선형 안 써요.
액티베이션 안 쓰면 여러분 아무것도 리니어가 되거든요.
그쵸 그냥 통과시키니까 여기에 반드시 지선정 함수 넣어줘야 돼요.
근데 렐루로 쓰는 게 정석이에요. 알겠죠? 지금 렐루 말고 셀로 이런 것도 있는데 뒤에 나오지만 멜루가 제일 많이 쓰는 거야 알겠죠?
그래요.

참석자 1 30:53
그다음에 이게 모델 정의한 거고 그다음에 이렇게 컴파일이라는 걸 써서 교과서를 지금 계속하고 있죠.
후 강의를 하는 게 맞나 이렇게 강의 자료도 다 봤을 텐데 그래서 왠지 얼굴 보고 얘기 안 하면은 안 가르치는 느낌이 들지.

참석자 1 31:12
여기 다 강의 자료 강의 때 했는데 노화에다가 가야지 그냥 지금 시대로 본다면 피해야 돼요.
그렇죠 그렇죠 강의 열심히 하세요. 거기 그거 녹화하는 데 엄청 오래 걸렸어요.
여러분 녹화하면 오래 걸려 하여간에 원래 그렇잖아요.
여러분 그래요. 이게 열심히 했으니까 이거 보셔 알겠죠.
그래서 그다음에 2.5.1절부터 이거 제가 아예 강의 자료에 안 올렸지 이거는 또 다시 공개하는 거 제가 설명 이거 이거를 이 사람이 이런 걸 한 이유가 아까 제가 텐서 플로우 플레이그랑 자꾸 보면서 뭔가 자꾸 설명해 주려고 그러잖아요.
그쵸 그거를 여기 깨우치려고 이 사람 이거 갖고 하고 있는 거예요.
알겠어요 여러분 이해되죠? 내가 지금 뭐 뭐 하고 있는지 다시 안 하려고 알겠죠?
텐서 플로우 플레이 그라운드로 다 설명 열심히 똑같은 걸 한 거예요.
알겠죠 내가 이걸 왜 안 하는지 해서 그게 나은 것 같아서 얼굴 보고 하니까 여러분 알겠죠 됐죠 그래요.

참석자 1 32:07
다시 그래서 이거 이 사람이 이걸 설명해 준 거고 넘어가야지 이제 그만 합시다.
역전파는 제가 설명을 잘해줄게요. 슬라이드를 하나 만들어 놓겠습니다.
그래서 3장 들어가면은 상장은 또 거의 휙 넘어갔지 3장도 상장 안 했죠.
사실 팀장은 약사 역사 개념인지 금방 할 수 있어요.
그러면 113쪽 그림 여기 보면은 지금 보고 우리가 쓸 때 맨날 임포트하고 텐서 플로우 점 QRS 점 뭐 이러고 있거든요.
여러분 그게 어떻게 된 거냐면은 원래 케레스가 먼저 있었어요.
그러니까 이거 지금 테스 플로랑 나오기 전부터 온갖 라이브러리들이 많았거든요.
춘추전국 시대라는 거 온갖 라이브러리들이 많아서 딥러닝 사이클 런이랑 이런 딥러닝 사이클러 딥러닝이 별로 없지만 시아노라는 것도 있었는데 여러분들 모르죠 망했지 어쨌든 나한테 나가는 라이버리가 많아요.
여러분 모르는 그래서 그걸 어쨌든 통합시키려고 테라스 방이 나왔어요.

참석자 1 33:13
그래서 테라스 뭐 하냐면 온갖 라이브러리들을 쉽게 쓰게 하기 위한 대방 뭔가 래퍼 같은 거였어요.
교과서에는 이게 이 사람이 케라스 만들었어요. 케라스 상시라고 적혀 있죠.
여그지 영어 책 이런 거 전혀 안 나와요. 우리나라에 책 팔아 먹으려고 기보 시켜서 이렇게 한 거라고 알겠어요 여러분 케라스 좀 유명하니까 하여튼 그래서 약간 여기서 뒷담을 하면 텐스 플로우가 이제 이 사람이 텐스 플로우에 입사했어요.
그때 그러니까 구글에 입사했어요. 이미 그래서 이렇게 책을 또 쓰고 막 이러는 거예요.
근데 이거 어떻게 되냐면 여러분 지금 하이테츠가 더 유명한 거 알아요 지금 파이토치가 어피 소스가 훨씬 많아요.
왜 그랬냐면은 최소 프로가 너무 어려웠어요. 너무 할 수 있는 게 많아서 여러분 가마솥 갖고 밥 지으면은 여러분 밥을 희한하게 만들 수 있는 거 알아요.
여러분 밥을 별 걸 다 만들 수가 있어요. 바바솥으로 밥을 지으면 못 찾는 사람 태관이겠죠.
여러분 그랬어요.

참석자 1 34:09
펜스 플로우가 할 수 있는 게 너무 많은데 일단 짜지를 못해 대부분의 멍청한 사람이 이 일이잖아 그래 그리고 어떻게 그래서 파이토치는 멍청한 사람도 짤 수 있었어요.
그래서 어떻게 돼? 이거 테스플라이가 망하게 생겼어.
아무도 안 쓰면 망하는 거잖아요. 여러분 그래서 과감하게 2019년 9월에 결단을 내렸어요.
옛날이지 그게 2019년 9월이면 이렇게 바로 팔기 전이잖아요.
그때 어쨌든 다 그냥 버렸어요. 옛날 거를 그냥 캐라스로 다 쓰기로 했어요.
텐스 플로우 점 캐라스라고 그래가지고 모든 API를 캐라스 API로 바꿔버렸어요.
텐스 플로우 2.0부터 왜냐하면 안 그러면 사람들이 안 써가지고 너무 늦었지 벌써 파리코치 다 물들었고 사람들이 그래서 지금도 여전히 타겟팅치가 많은데 텐스 플로우 훨씬 성능이 좋아요.
여러분 실제로 약간 좀 진지한 컬러는 텐스 플로우로 봐야 돼요.

참석자 1 34:55
어쨌든 그리고 케라스가 그래서 어쨌든 이 사람도 케라스에 입사시키고 이 사람 이 책도 쓰고 그랬어요.
여러분 나는 원래 펜스프로 쓰던 사람이니까 잘 썼네 이러면서 이거 쓰고 있고요.
알겠죠 그래요 펜스 플로우 베이 원래 아름답던 거 다 사라졌지 API가 근데 뭐 괜찮아요 지금 눈에 쓰기 편하고 또 여러분 테스 플로우도 알아야 되고 타이치도 알아야 돼.
왜냐하면 오픈스가 워낙 많으니까 두 개 비교해 주는 것도 제가 그것도 다 준비해 놨는데 나간 다음에 할게요.
중간고사 전에 했으면 좋겠는데 다음 주죠. 다음 주 그래서 어쨌든 그러면 이 책이 잘 안 나와 있어요.
그쵸 지금 무슨 얘기인지 알겠죠 근데 그런 게 되게 중요해요.
어제 제가 저기 자동차 공학회에 무슨 세미나를 들었는데 거기도 보니까 다 정치더구먼 정치 그러니까 KTRS라는 게 되게 유명하거든요.
피스코알티스라고 컨테이너 마이크로 서비스 있잖아요.

참석자 1 35:53
그런 거를 이제 좀 인베리 시스템을 쓰게 만든 게 있는데 걔를 그냥 쓰면은 미국 주도가 돼버릴 것 같으니까 유럽에서 또 새로 또 만들고 다르기만 하면 되는 거야.
이제 아니 무슨 얘기인지 알겠어요 여러분 어쨌든 그래서 이게 이렇게 많은 게 좋긴 해요.
여러분 약간 여러분 공부하기가 힘들잖아요. 팔트지도 공부해야 되고 테스어도 공부해야 되고 우리는 우리나라 말도 공부해야 되고 영어도 공부해야 되고 그런데 일자리가 많아져 여러분 여러분 일자리가 많아질 수밖에 없겠죠.
DW랑 어쨌든 벤츠는 무조건 다른 라이브리를 쓰기로 했어.
그러면 거기도 일자리 탄생 알겠죠 계속 그런 거지 계속 뭔가 다르기만 하면 된다고 해서 주장하면서 돈 투자하고 있다.
정부에서 정치할 있죠 이게 소프트웨어도 정치예요.
소프트웨어가 여러분 얼마나 무서운지 아냐 윈도우즈 여러분 못 벗어나잖아 우리가 못 벗어나죠.

참석자 1 36:45
안드로이드 못 벗어나잖아 그쵸 iOS도 한 번에 한 번 못 벗어나잖아.
그쵸. 소프트웨어가 얼마나 중요한지 다 알잖아.
이 사람들이 그러니까 달라야 되는 거예요. 그쵸 그래서 일자리가 많아 일자리가 많아서 좋지 하여간에 끊임없이 사람 뽑아내야 돼.
그렇죠 먹고살 만하면 또 개발하고 또 개발하고 재미있는 건 또 이제 도저히 유럽에서 또 약간 유럽이 혼자서 다 못하겠으니까 우리나라도 들어갈 수 있고 그래서 우리나라 일자리도 보고 좋은 거죠.
여러분 그렇죠 그래요 LG전자가 막 다 한다고 물어봤더니 다 한대 나는 사람들이 정치적인 이유로 여러 가지 다 하는데 다 준비한다.
기술적으로 중요한 게 중요한 게 아니다. 여러분 그런 게 있다고 근데 LG전자가 어쨌든 살아남으려면은 일러에 자꾸 초대를 하라 그러면 어떻게 해야 되겠어요?
여러분 잘해야지 초대 받을 거 아니야 그쵸? 뭔가 있어야 되잖아요.
그쵸 그래서 여러분도 러닝 메이트 같은 거 제대로 알아봐야겠죠.

참석자 1 37:40
스텝 사이즈라 러니메이트 그런 거 있죠 개념이 명확히 알아야 되는 거지.
그렇지 그래야지 뭔가 기술적으로 훌륭한 걸 할 거 아니야 그쵸 그래야지 뭐 어쨌든 정치적인 것에서 끼어들 수가 있는 거지.
그래요 계속 어쨌든 그래서 킬라스 이런 얘기했는데 그래서 파이 피치 펜스 플로우 이런 거 여러 가지가 있는데 이게 이렇게 많은지에 대한 그런 거 설명을 삼으시면 되고 그다음에 여기 이제 교과서에 이걸 또 이제 잘 이해시키려고 또 비슷하게 펠라스에 대한 API를 간략히 설명한 게 나와요.
근데 또 이제 제가 이거 은근히 플레이 그라운드로 제가 다 설명됐잖아요.
그렇죠 이 성 회의까지 됐다는 것까지 그쵸 그래서 또 넘어갈게요.
여러분 알겠죠 그래서 어디 보냐면은 36조 131쪽 가보세요.
131쪽 131쪽 가봅시다. 131쪽 다른 거 앞에 거는 안 해도 될 것 같아요.
시간 없어 3.6조 앞에 그레노트 테이프도 제가 그냥 같이 해줄게요.
나중에 또 뭐 백트라프 이션 한번 해야 될 것 같아.

참석자 1 38:50
3.6조 141쪽 오면은 여기에 뭐가 있냐면은 어쨌든 여기 보면 140 이쪽에 맨 처음에 진한 글씨로 층 적혀 있죠.
진한 글씨 중요해요. 여러분 진한 글씨는 다 외우죠.
책에 나 보면서 진한 글씨로 나오는 건 다 알아야 돼요.
알겠죠? 얼마나 중요하면 진한 글씨 해놨겠어요 그쵸 층이 그리고 여러분 142쪽에 또 맨 위에 가중치 웨이트가 또 진한 시로 돼 있죠 그쵸 층에 웨이트들이 들어 있지 그쵸 정확히 말하면 층이 여러분 문헌 자체에 있는 게 아니라 뭐에 있는 거라고 선에 있는 거야.
그렇죠 조심하세요. 여러분 배열 이거 이거 텐스 플로우 플레그레 너무너무 좋아하죠 제가 그렇죠 계속 그거 보여주고 있어요.
거기 점들이 그렇죠 거기 뉴런들이 아니라 선에 있다고 값이 봐봐요.
여기 다시 거기 주입식 여기 값이 여기 있는 게 아니라 여기 있어.

참석자 1 39:42
그쵸 숫자들이 여기다가 여기서 나오잖아 여기서 나오는 거 아니야 여기서 나와 그쵸 웨이트가 어디 있다고 선에 있어 층이라고 하는데 층은 사실 선을 의미해.
알겠어요 여러분 근데 사실은 이걸로 도식화되잖아 정의할 때는 얘로 정의하잖아.
댄스 하고 4지 4 근데 사실 여기 여기 웨이트 이게 여기 웨이트가 여기 4개가 아니라고 알겠죠 사가 여기 4 곱하기 여기 앞에 있는 거 선 연결하는 거니까 여기 하나 두 개 있지만 사실은 또 홍수가 하나 있죠.
x 제로 그쵸 그래서 4 곱하기 3이야 그쵸 웨이트가 3 곱하기 3이 있어 그쵸 이거 다 그쵸 12개야 그쵸 숫자들이 알겠죠?
여러분 웨이트가 정체를 실체를 명확히 아세요? 여러분 그거를 교과서에 자꾸 막 나오는 거 있잖아요.
제가 지금 너무 뛰어넘은 것도 그 얘기가 많아요.

참석자 1 40:31
알겠어요 여러분 이거 제대로 알려주려고 자꾸 코드를 알려주려고 그러는데 난 이게 나은 것 같아 알겠죠?
코드를 알려주니까 모르더라고 여러분 선배들이 그래서 저도 학습이 돼가지고 이러고 있어요.
이게 이번에 성공하려나 어쨌든 여러분 성적을 본 것도 알겠죠 그래요.
그다음에 그리고 여기 보면은 또 141쪽에 계속 진한 글씨 밑집 연결층이라 좋겠지 밑집 연결층 뭐라고 그랬어요?
여러분 데슬리 퀄리티 레이라고 적혀 있죠. 데슬리가 여러분 정말 밀도 있게 그렇죠 굉장히 복잡하게 약간 이렇게 붙어 있죠 그 댄스가 여러분 댄스의 반대말이 뭐게요?
여러분 스파스에 스파스 스파 스파스 섬긴 거 별로 없는 거 그쵸?
밀도가 낮은 거 밀도가 높은 게 벤스고 밀도가 낮은 게 밀도가 빈서트죠 벤트 그쵸?
알겠죠 여러분 스파스라가 어디서 봤죠? 여러분 어느 분이 스파스 카테고리 팔 아니 저번에 안 했네.
빨리 빨리 배울게요.

참석자 1 41:34
지난번 아까 2장에서 그리고 내가 진행한 것 중에 맨 거 잠깐 보여줄게요.
여러분 이거 이거 하고 넘어갈 거 있어 미안해요. 스타스 단어를 한번 해 주는 게 좋을 것 같아서 제 강의 자료 녹화도 했는데 여기 봐 여기 여기 여기 이게 몇 쪽인가 2.5절에 스타스라는 단어가 나오는데 가장 먼저 하는 스펙스 이 몇 쪽이냐면

참석자 1 42:11
103쪽 103쪽에 중간에 와디즈 컴파일하고 루스트는 스파스 적혀 있죠.
스파스 카테고리 표 콘셉트 좀 보여요. 여러분 내가 뭐 얘기하는지 여기 스파스 스파스라는 용어 나오죠 그쵸?
이거랑 반대말이 데스라고요. 왜 여기 스파스라는 말을 쓸 거 고객님들 왜 데스라는 말을 쓰느냐에 대해서 약간 설명해 줄게요.
여기 스파스라고 쓴 거는 여기 여기 지금 y 값이 숫자 중에 숫자 0부터 9까지 중에 하나예요.
그런데 나중에 제가 녹화한 거 여러분 보시면 알겠지만 사실 보통 분류하는 거 이런 거는 다 원화 팩터라는 거 쓰잖아요.
그러니까 원래 이게 보면 여기 마지막에 실제로 이게 이게 댄스가 여기 10개 나오잖아요.

참석자 1 43:00
마지막에 데이터가 이게 출력값이 사실 생긴 모양이 만약에 숫자가 2라면 001 00 해서 이게 전부 다 해서 10개 10개잖아 이런 식으로 나오잖아요.
이게 이게 진짜 답이잖아요. 근데 이 이렇게 10개의 벡터가 나와야 되잖아요.
10개 10개의 엘리먼트에서 벡터로 나와야 되잖아요.
원래 정답 값이 이게 생긴 거야. 그렇게 학습시키니까 이게 학습 데이터 자체가 원래 생긴 게 똑같아야 될 거 아니야 출력 데이터랑 출력 데이터가 확률이니까 이렇게 10개의 100를 써야 될 거 아니에요 그쵸 10개의 엘리먼트가 있는데 100를 써야지 원래 입력을 주입해야 되잖아.
원래는 똑같이 챙겨 먹어야 되니까. 근데 그런 거예요.
여러분 원래 이게 원래 여기 보면 예측이랑 진짜 타깃이랑 똑같이 생겨 먹어야 될 거 아니야 예측 자체가 지금 이렇게 소프트맥스로 나온다는 거는 여기 10개에 10개의 0하고 1아님 숫자가 나오는 거예요.

참석자 1 43:57
사실은 사실 정확히 나올 때 0.1 0.2 0.7 00 0 이런 식으로 나온다고 이런 식으로 해서 다 더해서 1대이 나온다고요.
그래서 이러면 이거 이렇게 이구먼 이런다고 숫자 이라는 걸 의미하는 거죠.
그렇죠 뭔 말인지 알겠어요. 여러분 내가 지금 그래서 이거 실제 진짜 타깃은 어떻게 챙겨 먹어야 되냐면은 0 0 1 이거 다 0으로 나와야 된다고 이렇게 이렇게 이렇게 줘야 된다고 타깃을 근데 그렇게 만들어서 준 적이 있어요.
없어요. 여기서 없어요. 그냥 어떻게 했어요? 여기 y 값을 줄 때 나중에 피트 하는 거 보면은 제가 강의했다고 안 했는데 트레인 레이블 그해줬잖아요.
그쵸 여기는 그냥 0 아니면은 여기 첫 번째 데이터는 숫자 0이야.
두 번째 데이터 숫자 이야 이런 식으로 있다고요. 그쵸 데이터가 그냥 하나만 있잖아요.
하나씩만 원래는 10개씩 있어야 되는데 한 샘플에 대해서 그래서 데이터가 적잖아요.
데이터가 적잖아. 뭔가 적은 걸 주파수라고 부르는 거야.

참석자 1 44:59
알겠어요 많은 건 밴스고 그래요. 여러분 진짜 스팟스트는 여러분 그래서 나중에 나중에가 아니라 여러분 이제 진짜 AI 업계에 무조건 일하게 되지 그쪽에서 일하면은 뭔가 스타스 기법이라는 게 되게 많아요.
유런의 웨이트도 줄이려고 그러고 나중에 드라아웃도 있지만 드라아웃도 스타스 하게 만드는 거지.
웨이트를 스파스하게 만든다는 게 뭐냐면은 별로 뭐 좀 사실을 없애고 싶은 거야.
알겠죠? 여러분 값이 없다는 거 느낌이 그냥 하나잖아.
하나만 들어가는 거잖아. 이거는 y 값이 원래는 10개씩 들어가야 되는데 상품 코스 10개면 이게 만약에 우리 이미지 넷 같은 경우에 천 개의 이미지를 분류하거든요.

참석자 1 45:34
여러분 천가지 그리고 천 개의 원 아펙터가 들어가야 된다고 하나가 한 데이터에 대해서 근데 거기서 이제 만약에 실제 이제 라벨이 23이다 99다 이런 식으로 매겨져 있을 거 아니에요 그렇게 출력 데이터를 주면 이게 스파스라는 말로 써가지고 이건 데이터를 이렇게 원아 팩터로 만들어서 데이터 많이 주는 게 아니라 정답 값이 생긴 모양이 그냥 내가 그냥 레이블로 주겠다 그러면 스팟이라는 걸 쓰는 거예요.
어쨌든 그래스코 스파스가 여기서 스파스라는 거에 개념을 여러분이 잡으시라고 알겠죠 이쪽에서 스파스 처음 나오는 건 이 용어 알겠어요?
여러분 데이터가 적은 거 댄스는 데이터가 많은 거 그쵸 크기가 큰 거 그래서 여기 지금 댄스 네트워크이라고 말 쓰는 거는 여기 지금 갑자기 또 이제 여기서 나오는 데스트는 밀집 레이어라고 하는 거는 왜 밀집이냐면은 여기 얘랑 얘랑 다 연결해가지고 웨이트가 다 있어.
그쵸 웨이트가 다 있잖아 웨이트가 전부 다 웨이트야 그쵸 이렇게 안 하는 게 있다는 거지.

참석자 1 46:38
그러니까 그쵸 나중에는 베스가 아닌 게 그렇죠 여러분 베스가 아닌 게 있겠지 웨이트를 공유해서 쓰게 하고 이런 게 하나 이틀을 가지고 같이 계산해서 여기 여기 넣고 넣고 넣고 하는 거 나중에 생겨요.
이렇게 커버레이션으로 해도 그래요. 여러분 거기서는 웨이트를 다음 층에다가 다 이렇게 연결해서 2층이랑 2층에 있는 걸 다 연결하는 게 아니고 여기 다 연결했잖아요.
그쵸 공유하기 시작하거든요. 웨이트를 웨이트를 공유해서 넘긴 홈솔루션은 그래요.
여러분 나중에 보여 기말고사 보면 알겠죠 아니 일단 댄스트가 근데 기본이야 보면 여러분 나중에 트랜스포머고 뭐고 나중에 전부 다 댄스트가 기본이에요.
댄스가 기본인데 이제 공유하기 시작하는 게 스파스하게 나 쓰는 거가 대표적인 콘솔루션이에요.
알겠어요 여러분 그래요.

참석자 1 47:30
어쨌든 그래서 댄스라는 말이 사실은 풀리 커넥티드라는 말과 덴슬리 커넥티드라는 거랑 덴슬리랑 풀리랑 같은 말이에 풀리 완전히 완전히 연결했지 밀집 연결 완전 연결 같은 말 모든 뉴런들을 모든 층의 뉴런들을 다 연결해 버리지 다 연결해서 뭐 하는데 웨이트로 두는 거잖아요.
그쵸? 웨이트가 다 들어가 그쵸 알겠어요 여러분 아까 스파스 크로스 엔트로피 카테리백 크로스 엔트로피 거기서의 스파스는 웨이트가 아니고 그냥 값이 적다는 의미로 쓴 거였어요.
그냥 정답 레이블을 내가 벡터로 만들지 않고 그냥 한 값으로 쓰겠다는 걸로 쓴 거였고 근데 거기서 스파스는 그런 맥락에서 나온 거 맞아요.
데이터가 작아 데이터가 많아 뭔가 여기는 지금 연결을 다 다 연결하고 앤슬리 다 연결 프리리 커넥티 뭐 이런 이해되죠 여러분 완전 연결이잖아요.
그쵸 같은 말이에요.

참석자 1 48:24
그래서 밑은 연결 완전 연결 같은 말 알겠죠 그래서 댄스라는 용어가 아까 API 이름이 있었던 거 기억나죠?
여러분 아까 댄스라는 말 썼잖아 우리가 레이어 이름 댄스 댄스라는 거는 이미 다 연결한다는 거예요.
웨이트 다 가져가겠다. 웨이트를 다 가져가는 게 학습에 유리하거든.
아니 기본적으로 뉴런이 많지 않아도 다 연결해서 쓰면은 다 내가 추상화시키겠다는 거니까 그렇죠 그랬어요.
여러분 여러분 10분 쉬었다가 합시다. 10분 쉬었다가

참석자 1 49:05
저기 늦게 온 사람들 얘기하세요.


clovanote.naver.com


딥러닝 day10_1
2025.04.09 수 오전 11:01 ・ 48분 50초
심승환


참석자 1 00:00
그렇죠 또 밀집층이요. 그냥 보유하고 그렇죠 알겠죠 높은 거 그리고 이제 심지어 우리가 지금 테레스 API에서 이름이 댄스라고 쓰는 것도 봤어요.
그쵸 그다음에 또 여기 진화형 교실로 순환측 합성 부칙 이런 거 나오잖아요.
그쵸 근데 그거 아직 안 배웠어요. 우리 그쵸 여기 설명할지 모를 것 같아서 그냥 나중에 할게요.
여러분 알겠죠? 그거는 기말고사 범위 알겠죠? 그래요.

참석자 1 00:27
그다음에 여기 뭐 또 이제 나오는 게 테라스 API 이해한다고 또 테라스 API에 있는 것 또 일일이 짜주고 있어요.
또 코드로 이해되죠 여러분 근데 또 그런 거 제가 안 하고 그냥 넘어간다고 계속 주장하고 있죠 그렇죠 그래요.
그래서 145쪽 보고 한번 145쪽 135쪽 보면은 이게 그림이 나오잖아요.
층에서 모델로 하면서 135쪽이 3.2.2절 내용인데 층에서 모델로 하면서 이 그림이 나오죠.
뒤에 나올 건데 어쨌든 여기서 보여주고 싶은 게 이 안에 지금 이게 그 유명한 그림 3 9라고 적혀 있는데 트랜스포머 11장이라고 나와 있잖아요.
트랜스포머는 거의 지금 챗gpt도 다 이거고 유명한 계기인 거야.

참석자 1 01:12
딥시크도 이거고 다 이거야 전부 다 지금 그리고 비전도 이것도 지금 자연어 처리뿐만 아니라 되게 잘 돼 있는 스토머가 근데 얘가 얘도 보면 여러분 들여다보면은 잘 모르지만 베스트에서 들어 있는 거 보이죠 여러분 댄스 댄스가 들어있잖아요.
여기 데스 댄스 댄스 댄스 이 안에도 다 댄스가 섞여 있고 그래요.
그렇다고 그래서 어쨌든 우리가 배우는 것이 쌓여가지고 뭔가 모델이 될 거다 그래요.
끝이에요. 알겠죠 그리고 이제 트랜스포머 때문에 LSD에 많이 주시고 시퀀셜한 리크로트한 뉴 레트워은 죽었다고 했는데 알고 보니까 디스크가 나중에 또 부도서가 더 잘 되고 있고 약간 뭐 뭐냐면 사라진 것 같이 보여도 사실은 그 원리를 알면은 더 잘 쓰면 되게 좋아지는 게 많아서 근본은 다 전제로 이해하는 게 중요하다는 얘기를 하고 싶어요.
알겠죠? 스 CNN이 중요하다고 댄스가 안 사라지는 거냐 아니면 그 안에 다 들어 있어요.
알겠죠?

참석자 1 02:09
리얼 리그레이션이 머신러닝 필요 없냐 그게 아직 다 있다고 그 안에 머신러닝이 필요 없는 게 아니라 머신러닝을 더 잘 알아야지.
딥러닝을 잘한다고 알겠어요. 선형 대수를 잘 알아야 돼.
알겠죠? 여러분 미적분을 잘 알아야 되고 8 곱하기 잘해야 되고 더하기도 잘해야 돼.
알겠죠? 그건 기본적으로 할 수 있어야지 그렇죠 그래요.
더하기 곱하기는 할 수 있어야 돼 그런 얘기예요. 그다음에 이거 이거 핀 메소드 나오고 실험 선택하기 이런 게 나오는데 교과서에 있는 거 어쨌든 강의에 제가 녹화해 놓은 거 있잖아요.
막 녹화해 놓은 거를 제가 일요일 월요일에 다시 볼 수 있게 해놨어요.
제가 이제 출석 반영하느라고 잠가놨어요. 여러분 출석 반영할 때 헷갈리잖아요.
나중에 들은 거랑 그래서 출석 반영 때문에 제가 금요일 저녁으로 딱 막아놨었고 출석 반영했거든요.
그래서 다시 풀었어요. 알겠죠? 볼 수 있어요. 여러분 그래요.
보라면 보세요. 난 열심히 녹화했으니까 지금 아까워서 알겠죠 그래요.

참석자 1 03:12
어쨌든 그래서 지금 교과서를 다시 보면은 136쪽에 보면은 토탈 단계라는 게 있는데 이게 이게 지금 나중에 봤지만 항상 데이터를 먼저 준비하고 그렇죠 여러분 아까 전에 데이터 영화 외지에 만들고 이런 거 했잖아요.
부처 치킨링 같은 거 그다음에 모델을 정의하고 그쵸 시퀀셜 이래가지고 데스 노 이런 거 있죠 그다음에 뭐 하냐면 항상 컴파일이라는 걸 해요.
테라스는 알겠죠 거기 컴파일 단계에서 파라미터가 뭐가 있냐면은 손실 함수 정하고 옵티마이즈 정하고 측정 정하고 하는 게 교과서 141쪽에 이렇게 분리 지 나와 있죠 그쵸 파라미터가 이런 게 있어요.
로스 옵티마이저 매트릭 이런 게 있다고요. 그래서 이제 모델에서 나중에 이제 훈련시킬 때 손실을 뭘로 볼 거냐 훈련할 때 중요한 거잖아요.
여러분 이제 훈련을 하기 위한 뭔가 설정하는 거지 사실 뭐 그냥 설정만 해놓은 거예요.
나중에 훈련할 때 이렇게 해라 이러면서 그때 루스 펑션을 다른 말로 우리티 펑션이라고도 적혀 있죠.

참석자 1 04:20
그쵸 목적이지 사실 이게 목적이잖아요. 훈련의 목적 그쵸 도대체 뭐가 중요한데 잖아요.
그렇죠 그래요. 그리고 옵티마이저라는 게 뭐냐면은 파라미터 업데이트를 할 때 어떤 식으로 업데이트 할지에 대한 거죠.
그쵸 어떤 걸 더 학습의 속도를 높이기 위한 옵티마이저를 뭘 쓸 건지 알겠죠 이 옵티마이드 중에 여러분 아까 맨날 RMS 럼 나오지만 여기에 BGD도 있어요.
BGD BGD가 뭐예요? 여러분 BGD가 뭐예요?
여러분 플레이 배치 잘했어요. 배치 그레디스트 이게 정체가 뭐예요?
여러분 이건 무식하게 가는 거잖아요. 모멘텀 같은 거 안 쓰고 정도로 그쵸 데이터가 작고 이럴 때는 이렇게 하는 것도 괜찮아요.
그러니까 학습이 너무 안 돼 아스트라 같은 말로 그렇게 쓸데없이 막 강화시켜서 한꺼번에 잘 되는 걸로 업데이트하고 이러면 안 되고 그냥 우직하게 다 꼼꼼히 하는 게 잘될 때도 있어서 비즈이 또 있어요.
여전히 아트 바이저에 알겠죠 그래요.

참석자 1 05:13
그다음에 측정 지표는 뭐냐면 이게 퍼포먼스 매트릭이라고 그쵸 원래 이게 진짜 손실 우리가 손실 함수랑 다를 수가 있어요.
전에 제가 바이너리 클래시파이피케이션에서 측정 지표가 뭐라고 그랬어요?
여러분 기본적으로 뭐 뭐 있었죠? 되게 많았잖아요.
제가 머신러닝 시간에 한 거라고 수칙 지나갔지 그것도 그렇죠 뭐 있었더라고 그러죠.
거기에 바이너리 프리스케이션 프라블럼 여러분 저기 문제가 크게 두 가지 항상 컨트리스 밸리 프리딕션이라 그렇죠 거기서는 그냥 뭐예요?
무조건 항상 스퀘어드 에러죠 그렇죠 또는 무트니 스케어드 에러 또는 미인 스키월드 에러 RMS이거나 mse이거나 s이거나 이렇지 그렇죠 다 같은 놈이야 사실은 그렇죠 또는 에솔루트 에러 그쵸 평균 하면 미인 에트로트 MA 그쵸 이런 애들이고 그다음에 이거 컨트리십 큐디션이고 그거 말고 제시 근본 중의 근본인 문제는 뭐라고요?

참석자 1 06:10
여러분 바이너리 클래시피케이션이죠 그쵸 그게 근본이지 SM 그쵸 o x 이게 근본이죠.
여러분 거기서의 성능 지표는 뭐예요? 여러분 컴퓨스 매트리스 기억나죠?
여러분 모르면 알아야 돼. 여러분 시험 범위에 들어가요.
그 기본이라서 컴퓨터 메티스 있었지 그쵸 그쵸 여러분 그리고 또 저 성능 지표는 뭐 있었어 그래서 에큐레시 이런 거 있었잖아요 그죠?
정확도 그쵸 프리시전 리콜 막 있었잖아요 그렇죠 있었어 그렇죠 모르면 안 된다 그랬지.
근데 보통 에큐로시를 많이 쓴다고 그랬어요. 제가 그렇죠 에큐로시가 뭔데요?
맞춘 거 그쵸 전체 중에서 맞춘 거 비율 그쵸 맞춘 거에는 이제 레스인 걸 레스라고 한 거 노후인 거 노라고 한 거 있죠 그것도 있는 거죠.
그쵸 그런 거 다 그게 액트로시죠 홍대표가 그쪽에 있으면 에트로c예요.
MSD가 아니라 그렇죠 보통 그런데 문제는 실제로 에큐로시 자체는 이게 이게 미분 가능한 함수가 아니에요.

참석자 1 07:10
그냥 숫자 부른 숫자라 가지고 미분이 안 돼 얘는 그래서 실제로 아까 봤지만 거기 매트릭은 계속 액티를 쓰는데 로스 평션으로는 액티비티를 못 써요.
MSL 로스트 북에서도 쓸 수 있고 다 쓸 수 있지만 인스퀘어드에라는 로스 펑션 이자 매출이었다고 그랬어요.
여러분 그런데 저쪽 아까 저기 숫자 분류하는 것도 그냥 멀티 클래스 스케이션이지만 그쵸 다중 분류죠 그쵸 그쪽에서의 직접 지표는 다 항상 에큐리시지만 보통 저기 홍실 남수는 뭐 했었어요?
여러분 아까 감독님 구경했잖아 스팟으로 시작하는 거 뭐 했어요?
스파스 카테고리칼 프로스 앤트로피라는 거 썼어요.
그쵸 프로스 앤트로피 포스 엔트로피 강의하면 너무 오래 걸릴 것 같아서 제가 강의 안 했는데 다 아셔 알겠죠?
콜센트로피가 사실은 음메 로그예요. 사실은 확률의 평균 음의 로그 평균 의외 로그가 뭐냐 지수의 지수 값이 지수 원래 여러분 2분의 1이면은 여러분 음의 로그가 얼마 만약에 로그 e를 취하잖아요.

참석자 1 08:18
로그 2 2분의 1이면 음메 로그가 얼만데 1이잖아 그렇죠 이 마이너스 2승이면 음메 로그면 1이잖아.
이에 마이너스 2승이면 음메 로그 하면 2잖아. 이 마이너스 58승이면 은혜로 구하면 8이죠.
이게 뭔가 확률이 낮으면 낮을수록 음의 로그 값은 커지죠.
확률이 낮으면은 로또 같은 거 할까요? 로또 얼마나 잘해요?
그쵸 그럼 음료 로그 값이 커지면은 그게 그게 여러분 엔트로피고 프로스트로피는 그거랑 진짜 확률을 곱하는 거예요.
그래가지고 평균 내는 거라서 어쨌든 굉장히 비슷해 액트레시랑 결괏값이 진짜 확률이랑 비슷하면 콜센트로피가 적게 나와요.
유명해 알겠죠 그리고 그 제 강의 자료도 있는데 제가 강의하면 너무 롤리 같아서 거기 신나가지고 한참 걸리거든요.
그래가지고 너무 재미있어요. 여기 그거는 머신러닝이나 AI 전문위원에서 하시고 아니 여러분 계속 지나갔으니까 그냥 보시고 알겠죠.
시험에는 나와야겠죠.

참석자 1 09:17
나온다는 게 크로스 엔트로피라는 거 모르면 안 된다고 어쨌든 여기 손실 함수는 다이애플리피케이션이나 멀티 프레스패션이나 그런 크레시피케이션 프라블럼에서는 손실 함수는 프로세 트로피를 써요.
알겠죠. 근데 이제 카테고리 타크로센티핀 이런 게 적혀 있지만 API에서는 알겠죠.
그리고 데이터를 그냥 저렇게 어애렉터 안 주면은 뭐였냐 원나피을 안 주면은 스파스라도 붙어야지.
그렇죠 원나피 안 들어주면은 스파스 떨어질 거고 그래요.
알겠죠? 강의 자료 있었어요. 제가 강의 자료 봤는지 아세요?
녹화해 놨었어 녹화한 거 있었어요 그래요 그게요.
그다음에 면은 교과서에 지금 147쪽에 여기 14,147쪽에 여기도 액트리시를 메트릭인데 앞치마에 있는 RM 스트랍이라고 적혀 있는 거 보이죠.
그쵸? 못 쓰는 민스키어 대로 이런 거 보이죠 여러분 이거 민스키어 대로를 쓰는 게 맞아.

참석자 1 10:13
참고로 클래시피케이션 프라블러에서는 민스키웨어를 쓸 수 있어요.
여러분 그러니까 뭐냐면 워나 팩터로 주면 이제 그게 되겠지 워나 팩터로 될 거 아니야?
1하고 0 0.7이랑 2랑 빼고 이러면 되잖아. 그럼 이스키가 0.3에 제곱하고 이럴 거 아니에요?
여러분 원래 0이었는데 0.1로 예측했으면 0.1에 제곱하고 더 하면 되잖아요.
사실 된다고 안 될 건 없어요. 여러분 시키는 대로 해요.
여러분들이 다. 근데 크로세팅이 훨씬 잘 돼요. 왜냐하면 그것도 설명하면 또 한참 걸리는데 숫자가 훨씬 더 예쁘게 나와 어쨌든 그래서 얘기하고 싶은 거는 여러분 이런 거는 교과서에 나오겠어요 안 나오겠어요.
제가 다 열심히 찾아보고 제가 해보고 세트 패턴도 다 물어보고 막 괴롭혀가지고 다 해보고 깨달은 거죠.
알겠죠 근데 그런 거를 어쨌든 열심히 해봅시다.

참석자 1 11:04
여러분 계속 어쨌든 그래서 여기 im 스트랍이고 이거 인스퀘어 제로 프로시 이렇게 했는데 여기 중요한 게 매트릭에 이렇게 뭐가 붙어 있냐면은 어레이죠 어레이 매트를 여러 개 줄 수도 있는 거야.
FC 말고도 다른 것도 줄 수 있다는 거지 그쵸 그쵸 여러분 여기다 MSA도 줄 수 있는 거고 예를 들어서 그렇죠 디스크웨어도 줄 수 있어 이해되죠 여러분 그래요.
이렇게 하고 교과서에 138쪽에 뭐라고 들어와 있냐면은 138쪽에 여기 148쪽에 137쪽에도 있네.
이 안에 137쪽에 옵티마이저 하면서 뭐 뭐 있어요?
SGD RM스트라 아담 여기 막 있죠 그렇죠 이런 것들이 있다고 제가 강제로 있죠.
그렇죠 보통 사람 이분은 아레스크라 엄청 좋아하시고 그쵸 보통은 사람들이 아담을 제일 좋아하고요.
아담이 잘 되는 걸로 유명하고 그다음에 SGD도 스피스틱 그레덴티센트잖아요.
그쵸 얘가 이제 여기다가 모멘텀도 줄 수도 있고 그런데 여러 가지 이제 쓸 수 있다는 거죠.

참석자 1 12:10
그다음에 뒤에 148쪽에 손실 함수에 여기 여러 가지가 있는데 지금 맨날 봤던 거는 민스퀘어드 에러 요거 요거 당연히 쓸 수 있을 것이고 그다음에 스파스 카테고리 그리고 이거 봤죠 그렇죠 여러분 봤죠 스파스 봤죠?
방금 이거 그랬죠 여러분 방금이라는 게 저기 리스트에서 제가 설 스파스 설명했던 거 기억나죠?
여러분 이런 게 있을 때 근데 이제 나올 거예요. 계속 앞으로 바이너리도 있고 그렇게 우리가 이거는 스파스 아닌 너나 테러이랑 파트로 캐스 거 대충 이제 일단은 케이 다이브던스가 뭐냐 이거는 크로스 엔트로피랑 거의 유사한 건데 프로스 엔트로피에서 원래 엔트로피를 뺀 거예요.
이게 뭐 하는 짓이냐 원래 엔트로피가 진짜 확률의 정보량이고 진짜 실제적인 확률에 프로스 트로피는 예측 확률 정보량이거든요.
평균량이라서 그거의 차이라서 차이라서 제 강의 자료 다 있어요.
그리고 이제 이건 이 과목에서 할 게 아니라 다른 다른 과목 머신러닝이나 거기서 할 거죠.
사실 그래요.

참석자 1 13:20
코스타리 시밀러리티도 되게 유명한 코스타리 시뮬리티 코스 시밀러리티가 사실은 포스 엔트로피랑 거의 유사해요.
이게 그래서 코센시 빌드 정거하는 거예요. 그래요.
그래서 나중에 시간 되면 나중에 봅시다. 그다음에 측정 지표 측정 지표로 지금 아까 에큐리시를 주로 썼는데 그냥 에트로시 썼는데 그냥 여기 에큐리시라고 해놨는데 사실은 엄밀하게 하면 카테고리칼 스카스 카테고리칼 에큐리시 막 여러 가지 바이어리피지 해놨잖아요.
전부 다 뭉뚱그려서 에큐리시라고 해주면 알아서 해주고 있어요.
지금 다 보통 그 문제에 맞게끔 AUC가 여러분 에어리어 언더 커브라는 거 전에 프리스트에 리콜 그림 그려놓고 PR 커브라고 있었는데 제 강의 자료에 있는데 컴즈 렉티스 데 있거든요.
다 머신러닝 내용이야 이게 전부 다 머신러닝 컴퓨터에 나와서 나오는 내용이에요.
크리스천 리콜도 여러분 다 머신러닝 뭔지 이거 모르면 안 된다고 그랬어요.

참석자 1 14:19
알겠죠 했어 대충 했어요. 머신러닝에 있어요. 아니 여기 있었어 내 강의자료 있어요.
어딘지 너무 표정이 그래서 한번 보여줘야지 잠깐 보여줄게요.
여러분 또 이렇게 여러분 이거는 기본으로 또 시험에 이거는 여러분 머신러닝이니까 내지는 알고 있어야 돼요.
여러분 물으면 곤란해요. 어디 있냐면은 제가 여러분한테 MLDL 베이직스에서 내가 줬지 여기 있잖아요.
여기 이렇게 해서 여러분 제가 액트리시 프리시전 리콜 다 했어요.
순식간에 했지만 아닌가 했잖아 했는데 순식간에 했지만 됐죠 볼게요.
그리고 PR 코브 있죠 피알 코브 프리시전 리콜 해서 에어리어 언더 커브 요 밑에 그렇죠 면적이라서 이게 정말 정확한 놈이 1이 나오고 바보 같은 랜덤 같으면 이게 0.5가 나오겠지 그렇죠 그런 경우 근데 이게 클로피도 당연히 좋겠지 그렇죠 그런 게 다 뭐라고요?
매출이라는 거지 알겠죠 그건 지표예요. 알겠죠 됐어요.

참석자 1 15:35
그래서 이게 재미있는 게 이제 이런 거는 성능 지표이지만 이게 손실로는 못 쓰는 거야.
보통 손실하고 성능 지표가 겹치는 거는 여기 이 사람은 안 적어놨네.
투표에다가 MSA도 추출 투표일 수 있거든요. 민스퀘어 에로도 직제 필 수 있어요.
알겠어요 여러분 엑셀루트로도 스즈 벨 수 있어요.
안 적어놨는데 이해돼요. 엑스로테일러가 되게 좋잖아요.
그럼 사실은 원래 값에서 예측한 값이 얼마큼 벌어졌느냐는 건데 만약에 집값 예측하는 문제면 집값 예측의 딘 에트로트 에러가 만약에 5가 나오면 5달러가 보통 벌어졌다는 얘기잖아요.
여러분 그렇죠 5달러 오차가 있다는 얘기죠. 괜찮잖아요.
그렇죠 됐어요. 여러분 그래요. 그다음에 설명이 나중에 나오겠지만 그래요.
그리고 검증 데이터 이것도 제가 강의 자료에서 있었던 거죠.

참석자 1 16:33
검증 데이터 이거 강의 자료에서 검증 데이터를 쓸 수도 있다는 거 원래 이것도 다 여러 번 했던 거니까 그냥 원래 트린 데이터 다 쓰는 게 아니라 본인 데이터 분리해가지고 그렇죠 쓰는 홀드 아웃 밸리데이션이다 라고 거 한다고 그랬죠.
그쵸 그래요. 그래서 키 탈 때 밸리데이션 데이터 따라 줄 수 있다는 묶어서 얘기했죠.
지금 141쪽에 적혀 있죠. 141쪽에 141쪽에 코드 맨 위에 코드에 밸리데이션 데이터 하면 이렇게 따로 줄 수 있어요.
그쵸 이거 원래 이 파라미터가 없다가 새로 생긴 건데 그렇죠 그런 게 있었죠 그쵸 이해되죠 여러분 그래요.

참석자 1 17:17
그래서 이것도 지금 폴드 밸리인데 밸리데이션 하려고 그랬을 때 데이터 만들 때 이것도 제가 강의 자료에 없었던 것 같긴 한데 이거 이렇게도 많이 해요.
사실은 이걸 강의를 이렇게 자세하게 할 필요가 있나 여기 오면은 굳이 이제 랜덤 커뮤테이션 만들어가지고 여기 린드 커뮤니케이션 만든 거 해가지고 셔플 시켜가지고 섞어야 데이트를 이렇게 섞는 게 좋거든요.
이렇게 공부할 때 여러분 숫자가 데이터가 몰려 있을 수 있잖아요.
그쵸? 엔리스트 데이터가 예를 들어서 0만 앞에 쫙 있고 1만 뚝 있고 2만 뚝 있고 이러면 어떻게 되겠어요?
영만 공부하고 1만 공부하고 이러면 구분 잘 못할 거 아니에요 그쵸?
0 1 2 3, 4 5 6 7 8 9 같이 봐야지 공부가 되지 그쵸 그쵸 여러분 제가 여러분 공부시킬 때 BGD랑 SGD랑 그다음에 미니배치랑 같이 가르쳤죠.
그거 하나씩 배우면 여러분이 뭔지 모를 거 아니야 비슷한 것끼리 같이 배워야지.
차이점을 배우면서 여러분 공부 되잖아요.

참석자 1 18:15
그쵸 제가 여기 할 때도 이거 굳이 이렇게 맨날 이거 같이 막 설명해 주잖아요.
그렇죠 왜 그래요? 차이점을 알아야지 여러분이 제대로 이해하는 거잖아요.
다 뭔가 뭔가 차이점 차이점과 공통점을 알아야지 뭐든지 다 이해하는 거잖아.
그렇죠 그래서 제가 여러분한테 강조하고 싶은데 공부할 때 여러분 그냥 쫙 읽으면 될까요?
그 책을 어떻게 해야 돼요? 순서 먼저 목차를 봐야 돼요.
목차를 내가 지금 뭐 하고 있는지 계속 알아야 돼. 그렇죠 공부할 때 아 미니 배치를 공부하시라고 미니 배치를 할 때 공부를 어떻게 해야 돼요?
잘 섞어서 공부해야 돼. 잘 섞은 다음에는 탑다운으로 공부하시라고 탑다운으로 공부하세요.
탑다운으로 미시적인 위에 갇혀 있지 말고 내가 지금 뭐 하고 있으면서 이거는 뭐가 다르고 무슨 맥락이고 뭐 하고 있는지 계속 파악하라고 알겠죠.
그래요. 미니 백치 이게 지금 뭐 하는 짓이냐 미니 배치를 예쁘게 만드는 중이에요.

참석자 1 19:11
대체 잘 썩고 있어 하나씩만 공부하지 않게 하려고 똑같은 정답만 공부하면 안 돼 문제를 잘 섞어서 공부해야 돼요.
알겠죠? 그래요 그리고 그래서 이제 여기 서플 된 거에서 밸리데이션 하는 거랑 트레이닝 하는 거랑 지금 나눈 거죠 그쵸?
여러분 그렇죠 이렇게 앞에를 밸리데이션 했었네요.
뒤에를 지금 이걸로 썼는데 그렇죠 이거 뭔지 알겠죠?
이 앞에 데이터를 지금 밸리데이션 쓰고 이거는 이런 거 정답 없어요.
사실은 그렇죠 거꾸로 해도 돼 그렇죠 넘 트리 인피스를 가지고 거꾸로 할 수도 있죠 그렇죠 그래요 됐지 그다음에 이것도 그냥 그냥 보여줄까?
이것도 교과서 142쪽 있죠 추론하는 거 보면은 140 우리가 바로 여기 142쪽 2쪽이 표적이 별로다.
142쪽이 제일 아래쪽 볼래요 여러분 미안해요.
여기 미안해. 142쪽에 제일 아래쪽이 아니라 141쪽에 이거 다 한 번에 합시다.
여기 141쪽에 위에 여기 이벨류에이트라는 거 저 보여요.

참석자 1 20:19
여러분 이거 이벨류에이트 어디냐면은 141쪽 딱 중간 부분 약간 위쪽에 마일즈 이베레이트라는 거 보이죠 여러분 요거 보이죠 여러분 이밸류에이트 하면은 여기 뒤에 있는 데이터랑 정답 값을 가지고 매트릭 값을 꿔줘요.
로스 값이랑 매트릭 값이랑 뽑아주거든요. 그래서 원래는 보통 테스트 데이터 갖고 많이 해요.
테스트 데이터 갖고 여기서는 밸리데이션 데이터가 넣어왔어요.
알겠죠? 이벨루에이트라는 건 순전히 이게 성능을 평가 이베이트가 뜻이 검증하는 거잖아요.
여러분 사실 이벨리언트가 평가하는 거잖아요. 그쵸 평가할 때 이렇게 해본다는 거 알겠죠?
얘가 진짜 영향을 잘하나 밸리드 데이터는 어쨌든 여러분 학습할 때 쓸 적은 없잖아요.
그쵸 그리고 원래는 우리 이 테스트 인풋 테스트 타겟 넣어준다는 거 이해되죠?
여러분 됐어요. 그다음에 여기

참석자 1 21:27
여기 배치 사이즈를 안 주면은 전체 데이터에서 한 개만 튀어나오고 배치 사이즈 주면은 128개씩 해가지고 값을 주고 있어요.
그다음에 마지막에 이것도 여러분 이거 이것도 여기 다 나와 141쪽에 이것도 여러분 지금 시험에 나올 수 있어요.
잘 봅시다. 여러분 제가 강의 녹화해 안 했는데 이거 3장 녹화를 안 했잖아요.
제가 여기 보면 요거 141쪽에 프레딕션즈는 마드라고 이렇게 보이는 거 보여요.
여러분 141쪽에 3조 6조 7절에 코드가 지금 두 줄 있잖아요.
첫 번째 줄이 틀리시지 여기 여기 여기 네오차놓던지 좀 중요해 이거 보여요.
여러분 이거 이렇게 할 수도 있어요. 이게 뭐냐면은 이 모델이라는 게 정체가 뭐냐 뭐예요?
여러분 이거 이 모델이 앞에 이렇게 맨 처음에 이거 모델하고 캐라 시퀀셜하고 이렇게 모델 컴파일 이렇게 한 거 있잖아요.
이거 여기 맨 처음에 모델이 이렇게 정의한 거죠. 그쵸 이거 지금 이 시퀀스 데스트 원 하면 이거 정체가 뭐예요?

참석자 1 22:30
여러분 이거 이거 정체가 뭔가 이거 얘가 이 모델이 인플레트워크인가 인류 네트워이라고 이건 맞지만 이거 김유노 네트워크이 아니야 그쵸 뭐예요?
근처 이거 선호 행위잖아 이거 선호 행위인 거 알겠어요 여러분 선량액이야 이거 완전히 그쵸 액티베이션 포션도 없잖아요.
그쵸 출력하나만 덜렁 나오잖아요. 그쵸 액티베이션 펑션이죠.
스 데스로 이렇게 딱 공급해가지고 나오는 선우이라는 거 알겠어요 여러분 모르는 질문하세요.
지금 얼른 괜찮아요. 선우인 거 알겠어요 여러분 이게 선정액이야 왜 저 댄스가 붙으면 입력에 대해서 전부 다 점이 생기잖아요.
그쵸 이 값이 나오잖아요. 그냥 선정 얘기잖아요.
그쵸 하는 게 맞지 선형 회기를 포함하지 다 당연히 되겠지.
소형 회기를 이게 이거 완전 선형 위기예요. 의기에 플러스 알파가 하나도 없어 그냥 선형 회기야 완전히 알겠어요.
학습하는 것도 똑같애 선생이에요. 알겠어요 모르면 질문하세요.
여러분 용감하게 됐죠.

참석자 1 23:34
근데 어쨌든 선전형인데 이거를 나중에 이제 진짜 모르는 데이터에 대해 새로운 인풋에 대해서 예측 값을 뽑아낼 때 이렇게 모델 하고 이렇게 불러주면 된다는 거예요.
알겠어요 여러분 괄호 열고 여러분 객체에다가 이렇게 막 파랗게 넘겨주는 거 있죠?
이런 거 못 봤죠 여러분 봤나 처음 봤는지 모르지만 대봐야겠죠.
그게 사실은 이게 여기 여기 뭔지만 이게 캐라스의 시퀀셜이라는 거 갖고 했잖아요.
테레스 시퀀셜 객체잖아요. 이게 객체 만든 거잖아요.
페레스였고 여기에 다 언더바 언더바 폴이라는 함수를 만들어 놓으면 이런 메소드 교과서 적혀 있잖아요.
언더 바운드 바 폴 언더 언더 바이 메소드 이런 거 만들어 놓으면은 저절로 불려진다는 거지.
객체에 대해서 불러대면 이제 언더바운드하고 콜로 정의한 게 빌려져요.
앞에서 교과서에 있었는데 제가 생략했는데 이해돼요.

참석자 1 24:32
여러분 여러분들 이거 할 수 있어 객체에다가 내가 a 함수 짜잖아요.
클래스 만들 때 그러면은 그 객체에다가 그냥 불러버리면 저 함수가 들려요.
알겠어요 여러분 파이썬이 원래 좀 그런 게 많잖아요.
쉽게 하려고 그래서 어쨌든 이렇게 불릴 수가 있다는 거야.
알겠어요 여러분 알겠어요. 여러분 그리고 이거 말고는 무슨 방법이 있느냐 밑에 142쪽 제일 아래쪽에 마들 점 플리트 이렇게 하는 게 나와 있죠 그쵸 뭐예요?
여러분 두 가지 방법이 있어요. 두 가지 방법이 있는데

참석자 1 25:11
이게 차이점이 이 콜 방법 rd 방법은 이게 모든 데이터를 한꺼번에 처리하고 여기서는 배치 사이즈를 줘가지고 배치별로 처리할 수도 있어요.
이게 식탁이 넘어가면 대기 탁 끊어가지고 처리할 수 있어요.
됐어요. 여러분 그런 거예요. 이게 지금 여러분 계속 차원이 이게 하나가 아니라 샘플이 여러 개라고 그랬죠.
인풋도 한 개가 아니라 엄청 많이 줄 수 있는 거예요.
기본적으로 한 개만 할 거면은 그러면은 프린트랑 얘랑 차이가 없겠지.
사실은 그쵸 됐어요. 사실은 프린트가 다시 또 마디를 나중에 불러요.
끊어가지고 위에를 이걸 부른다고 여기 제게 여기서는 프린트는 좀 끊어가지고 그래요.
여러분 프린트가 좀 더 빨라요.

참석자 1 26:01
보통은 원래 근데 데이터 한 개만 처리할 것 같으면 이게 더 빠르고 왜 그러냐면은 이거 프린트 안에서 최적화시켜서 얘를 불고 마대를 불고 근데 한 개만 하면은 그냥 여기서 또 세장 돈 준비하느라고 또 힘드니까 얘가 더 느리고 막 그래요.
이런 것도 어떻게 해야 돈을 받습니다. 알겠죠? 여러분 됐어요.
그게 실제로 채팅 티티도 그렇다고 그랬어요. 알겠죠 저도 열심히 피티 활용하고 있는데 그게 맞는 것 같아요.
진짜 말이 돼 됐죠 여러분 그렇죠. 이 책이 또 뒤에도 나오더라고요.
말도 됐죠 여러분 근데 두 가지 방법이 있어요. 됐지 아니 나 가르쳤어요.
여러분 시험에 날 수 있어요. 알겠어요 그래요. 그다음에 4장 4장에 제가 4장 여러분 교과서 4장 146쪽 앞에 여기 이렇게 이 부분 봅시다.
여러분 여기 한번 봅시다. 여러분

참석자 1 27:12
여기에 제가 지금 이거 두 개만 강의 녹차 해놓고 이거를 못한 상태예요.
그쵸 그리고 이거 지금 이게 문제인데 거기 예제랑 잘못돼 있더라고요.
거기 뭐냐고요 문제랑 예제랑 다르지 왜 다른지 알지 문제 자체 늦은 분류는 늦은 분류 프라블럼이라는 말이야.
이게 되게 중요한 얘기지 사실 분리 문제는 분류 문제 회기 문제 그렇죠 이게 컴퓨터 디밸리테이션이고 그렇죠 이게 크리스피케이션이잖아요.
그쵸 여러분 제가 녹화 다 해놨잖아요 그쵸 그쵸 그래서 이제 과감히 넘어가야 돼.
내가 그렇죠 이거 하고 싶은데 쓰면 안 되지 넘어가야 돼.
근데 이제 이게 지금 일단 지금 뭐 하고 있는지 여러분이 알라고 알겠죠 크게 신경망 시작하기 전에 거의 신경망에서 지금은 이제 댄스밖에 안 배웠으니까 댄스 네트워크에 거의 뭔가 모든 걸 다 보여주고 있는 거예요.

참석자 1 28:09
사실상 본인 그리고 이제 이게 이게 같이 봐야 되는 게 중요한 게 미니 레츠지가 제가 미일 레츠즈 가르키는 건데 비교해서 그렇죠 여기 여기 여기에 되게 다른 걸 봐야 될 거 아니에요 그렇죠 그렇죠 일단 얘네들이 일단 문제 자체가 여기도 이거는 이 신경관이랑 상관없는 건데 이 영화 리뷰랑 뉴스 기사 자체는 여러분 텍스트 데이터예요.
그쵸 자연어 처리 쪽이야. 여기 주택 가격은 아직 제가 강의 안 했지만 맨날 주택 가격은 제가 사장님 얘기할 때도 맨날 샘플로 나오던 평수 갖고 뭐 맨날 가격 예측하려고 그러고 이 좀 약간 유명 약간 여러분한테 잘 와닿나 와닿아요.
많이 나오죠. 얘가 그렇죠 여기서 주택 가격 예측은 어쨌든 이거는 커티스 밸류한 값을 예측하는 건데 이거는 피처들이 진짜 숫자들이 있는 것 같고 예측하는 거라서 약간 성격이 달라 얘는 다이어 차이고 자연어 처리 아니고 그쵸.
근데 세상에 있는 문제가 자연어 처리만 있는 건 아니잖아요.

참석자 1 29:11
사실은 그렇죠 이게 약간 좀 교과서가 학점별 사정이죠.
그래서 보통 가을 교과서들은 맨 처음에 보여줄 때 m 리스트 갖고 많이 보여줘요.
숫자 갖고 숫자 분류하는 거 여기 다중 분류에서 숫자 분류하는 거 있잖아요.
다중 분류하는 거에서는 0부터 끝까지 분류하면 좋잖아.
그쵸 앞에서 했던 거 이해돼요 앞에서 앞에서 봤던 맨 첫 번째 예제 있잖아 2장 거기 숫자 0부터 9까지 분리하는 거 있잖아요.
리스트 하고 이 문제가 여기에 해당하는 거 알겠어요?
여러분 이 문제가 엠리스트 문제는 여기에 해당하는 거 알겠어요 알아야 된다고 알겠죠 기억나요?
엠리스트가 이 셋 중에 어디에 해당하는 다중 분류에 해당한다고 데이터가 이미지인 게 중요한 게 아니고 문제가 뭐냐가 중요하다고 다중 분리냐 알겠어요 여러분 이해되죠.
그래서 또 이신 분들은 또 여러분 사실 엠리스 업도 할 수 있었지 엠리스 사업도 하면 어떻게 돼요?

참석자 1 30:09
여러분 숫자 만약에 3인지 내가 3인 숫자가 내가 중요해 3이라는 것만 알고 싶어 3이냐 아니냐 이렇게 할 수 있잖아요.
여러분 그렇죠 그렇게 하면 되잖아요. 그러면 진짜 3이냐 아니냐만 그렇게 학습시키는 문제가 될 수도 있잖아요.
그렇죠 근데 이제 그렇게 되면은 데이터의 불균형이긴 하죠.
3 데이터는 10분의 1이고 나머지 데이터가 또 10분의 9니까 결국 3이 아니다라면 낮추면 90% 맞추게 되잖아.
진짜 그렇잖아요. 그러면 무조건 아니야 아니야 아니면은 20% 맞추는 게 되잖아요.
지금 잘하는 것처럼 보이는 사실은 데이터가 불균형해서 그런 거잖아요.
그렇죠 그런 거죠. 알겠죠. 무슨 무슨 하는지 여러분 사실은 그래서 그 점 함부로 믿으면 안 돼요.
박사님 박사님 함부로 믿으면 안 돼요. 그 사람들은 90%의 확률을 얘기하는 거야.
항상 그리고 맨날 맞추는 거 같잖아. 근데 알지 사실은 내일 비가 안 온다고 말하는 게 더 쉽잖아.
비가 보통 90% 안 오잖아요.

참석자 1 31:01
그렇죠 여러분 되게 유용하죠. 그쵸 그러니까 노력해가지고 자신이 비 온다 안 온다 이렇게 말하면 무조건 안 온다고 그러는 거야.
비 맞잖아 그지 무슨 얘기인지 알겠지 법사님들이 그래 하여튼 그래요.
나는 지금 나라 걱정돼가지고 하여튼 그래서 이게 여러분 데이터의 불균형이라는 게 되게 중요하죠.
알겠죠? 이지 물 문제를 그래서 다른 교과서들은 보통 그렇게 n리스트에서 3이냐 아니냐 이런 걸로 하는데 우리 교과서는 그런 게 싫어가지고 아예 그냥 문제 자체가 positive negative 똑같이 있는 거 갖고 있잖아요.
여기 영화표 일부 문제가 이게 뭐야 imdb 맨날 영화 형 영화평 있잖아 그래 갖고 했어요.
그렇죠 여기서 특이하게 또 멀티 워n이라는 걸로 했거든요.
이렇게 강의 자료 다 있죠 그렇죠 녹화해 놨어요.

참석자 1 31:48
그렇죠 또 거기에 또 벌써 자연스레 나오는 어려운 내용도 등장했어요.
맨 처음에 01이라는 거는 그쵸 0은 패딩이고 1은 스타트업브 챕터스고 이는 아웃오브 키블러 이런 것들이 나와버렸어요.
그쵸 이 시험법에 들어갔어요. 알겠어요 그래서 그렇죠 알겠죠?
그래요 교과서에 제가 교과서를 못 보여줬는데 교과서 한번 보여줄까?
교과서 149쪽 149쪽 한번 보세요. 여기 149쪽에서 여기 코드가 있잖아요 4 2 요거 여기 적혀 있잖아요 그쵸 여기 0은 패딩 이름 문서 시작 2는 파전에 없이 그쵸 여기 나와 있죠 그쵸 제가 이거 강의 전에 제가 뭔지 정확히 알려줬죠.
이게 정체가 뭔지 아웃 오브 고케 원리라고 그렇죠 그렇죠 이거 오오 v라는 유명한 용어가 있어요.
여러분 이거 아주 유명해요. 알겠죠? 오호v라는 거 알겠죠?

참석자 1 32:45
그래요. 그래서 지금 벌써 1장 제가 1절 2절을 제가 녹화를 해놨기 때문에 먼저 대조되는 걸 먼저 보여주면은 대조되는 거를 여기 이게 어쨌든 이진 분류 다중 분류 해위 문제에서 달라지는 거는 일단 스 로스 펑션이 달라져야겠지 그쵸 계속 그랬잖아요.
제가 기술 로스 펑션 로스트 펑션이 결국 폴더 업데이트하기 위한 방법인데 그쵸 그게 다르다 그랬잖아요.
그거 한번 구경할까요? 합시다. 여러분 같이 지금 미니 배치로 공부하는 거예요.
알겠어요 예 지금 봐봐요. 여러분 어떻게 되냐면 몇 쪽에 의하면 되냐면 어디냐면은 여기 컴파일 나오는 부분이 있지 158쪽 158쪽에 3.1절에서의 컴파일 나와 있죠 158쪽

참석자 1 33:52
말하는 거 뭐였지 이스할 때 이게 불편하게 뭐라고 돼 있어요 여러분 로스가 바이너리 크로스 앤트로피라고 나오는 거 보이죠 여러분 158쪽이 맨 위에 컴파인 158쪽이 맨 위에 컴파일 하면서 아티마이드 RMC크럽스고 로스트는 바이너리 크로스 앰플로 써놨잖아요.
바이너리 크로스 엔트로피 그쵸? 이걸 쓰는 거죠?
그쵸? 이거는 정답 데이터가 생긴 모양이 영 안 되면 이예요.
알겠어요 여러분 그럼 정답 테이터가 생긴 모양에 따라서 이렇게 하는 거예요.
그래서 정답을 주는 거야 정답 데이터가 어디서 주는 건데요?
여러분 핏 줄 때 핏 줄 때 t 줄 때 파라미터로 이렇게 x 트레이 y2 주잖아요.
이거 어디냐면 이건 이쪽에 있어요.

참석자 1 34:47
바로 있네 거기 거기 있었는데 내가 굳이 멀리 갔네.
미안해요. 거기 있는데 그냥 쓸데없이 멀리 갔어.
148쪽에 다 있는데 호주 지금 몇 시야 한 10 여기 맞네 이거 여기도 봐 이 페이지 내가 왔다 갔다 미안해요.
여러분 그래서 여기서 로스가 이랬고 알겠죠? 여러분 xt y2 주세요.
YTN이 생긴 모양이 0 아니면 2인 거야 그쵸 각각 샘플에 대해서 그렇죠 그렇게 생겼을 때 바이오리 프로센트를 주는 거예요.
이해돼요. 여러분 됐지 그래요 됐어요. 여러분 그다음에 제가 또 커피 마셔 또 설명을 하시면서 다 할 수도 있죠.
그사람들 할까 제가 고민되네. 먼저 그거 보여줄까요?
이렇게 먼저 소스 루스 로스 여기 보면 이거 4.12 4.2절 하면 4.2절의 정체가 뭐였다고요?
여러분 4.2절이 4.2절에서 컴파이라는 거 볼까요?
4.2절에서 4.2절에서 컴파이라는 거는

참석자 1 36:03
등이 3쪽에 있네 등이 3쪽

참석자 1 36:22
잠깐만요. 이거 원화 필터 안 만들었나

참석자 1 36:31
잠깐만요. 여러분 130,130 161 아무 데나 있으니까 166쪽 봅시다.
166쪽 코드 4 21 정신없어요. 잠 잠깐만 4 21 4 21 보면은 여기 보면은 요거 뉴스 기사 분류인데 여기는 카테고리 8 프로세 이렇게 적혀 있죠 그쵸 알겠어요.
여러분 됐어요. 이거는 이제 정답 값이 어떻게 생긴 거냐면 숫자인데 0하고 1만 있는 게 아니라 여러 개 있는 거죠.
여기서는 몇 개냐 86이에요 마지막에 그쵸 무려 그렇죠 여러분 베스가 마지막에 76이잖아 그쵸 같은 코드 이게 보이죠.
그리고 액티베이션이 소프트맥스죠 그쵸 여기 마지막에 그쵸 전부 더해서 1 되는 거 그쵸 이해되죠 여러분 이랬는데 아까는 아까는 뭐였냐면 거기는 액티베이션이 마지막에 시급 모델이었겠지 그랬어요.
이 바이너리 프로세트 때는 알겠죠 마지막에 개스가 몇 개였어요 너무 왔다 갔다 해서 잠시만요.
근데 아까 또 갈게요. 페이지 몇 쪽이었어요? 여러분 혹시 알아요?
여러분 3.1절에

참석자 1 37:53
158이 15 18인데요. 그거 봅시다. 여기 4 1 코드 여기는 시그 모이드였죠 그쵸 영어 미사에 나오는 거 소트 맥스는 전부 다 나오는 출력이 여러 개인데 알겠죠?
여러분 소프트 베스인데 데스가 1이 나오거나 그럴 일은 없겠지 2개 이상이어야 되겠지 그쵸 워닝이 뜨겠지 그쵸 너 이거 왜 그러냐 이러면서 그렇죠 어떻게 그거는 그쵸 말도 안 되지 그쵸 여기는 s가 1일 수밖에 없어.
여기 이 쓰는 건 이상한 거야. 그쵸 한 개만 나와야지.
0하고 1 사이로 통률이 나와서 하는 거지 알겠어요 명확히 아셔요.
여러분 됐지 시험에 나와요. 시험에는 국어 문제로 나와요.
국어 문제는 문제가 이제 여기서처럼 나오는 게 아니라 이런 문제가 있는데 난치와 출력 계층 어떻게 챙겨 먹었나 데이터는 이렇게 챙겨 먹었지 어 채워라 이렇게 나오겠지 함수를 채우라고 그러고 그래서 저것도 채우라고 그러고 이해돼요.
여러분 그럼 답이 정해질 수밖에 없어요. 여러분 따져봤자 답은 정할 수 있어요.

참석자 1 38:56
알겠죠 알겠어요 그래요. 그리고 이거 제가 강의 자료에도 열심히 해놨지만 아니 강의 자료가 아니라 녹화해도 이것도 그냥 지금 보니까 보이는 김에 아니지 마지막 거 하면서 이제 제대로 미리 배치를 합시다.
그러니까 뭐냐하면 데이터를 다 섞어서 가르쳐야지 그러니까 뭐냐면 마지막에 주택 가격 지 뭔지 모르지만 거기 컴파일 하는 중요할까요?
여러분 거기 컴파일 하는 거 아직 강의 안 했는데 대신 미리 보면은 주택 가격을 예측하는 거는 컴파일 하는데 이거 코드 4 25네 코드 4시 25 이거 이거 좀 안 좋은 건가 보라고 그러지 코드 4

참석자 1 39:47
몇 쪽인가 172쪽이네. 그렇죠 여기 먼저 두 개 할까요?
여기 보면 여러분 로스가 뭐 적혀 있어요? 여러분 스케 이거 뭐예요?
여러분 mse지 그쵸? 매트릭은 MA 했네 그쵸 그쵸 매트릭이 MA가 보기 좋으니까 제곱 때문에 여러분 또 루트 씌워서 봐야 되니까 앱솔루 테로 하면 여러분 어떻게 돼요?
그냥 절대값이니까 이 정도 예측을 벗어나는 정말 만약에 MA가 100이야 그러면 100달러씩 틀리면 5만 5천 통 그쵸 이해되죠?
여러분 msca 하면은 이게 100이 아니라 많이 나오고 이럴 거 아니야 그쵸 이해되죠 아니 스케어 맞지 여기 RMSD 할 수도 있겠지.
사실 루드민스케어에로 가면은 MA랑 거의 똑같겠죠 그쵸 비슷할 거 아니야 루드민스케어에요 완전히 똑같지는 않지만 이해되죠 여러분 제곱해가지고도 쉬운 거니까 알겠죠 여러분 이건 절대값이에요.
여러분 다 구하는 방식은 달라요.

참석자 1 40:50
절대로 절대 값들을 다 더해가지고 평균 낸 거고 어 루트 리스케어요 그러면 제곱을 다 더해가지고 이 주는 거잖아요 달라요 그쵸 좀 더 이제 에러가 더 과장되는 면이 있지 이테스피어에도 알겠어요 여러분 그래요.
그다음에 마지막에 이것도 볼까요? 여러분 여기 마지막에 여기 1 돼 있죠 값을 하나 예측하는 거거든 집값 하나 집값도 예측하고 딴 것도 예측하겠다고 그러면 2개씩 나오겠지.
근데 여기는 1개잖아요 그쵸 그래서 이렇게 된 거야 알겠죠?
지가 하락 예측하는 이 여기에 액티브 상성이 있어요.
없어요 없지 천보지 여러분 이런 거 선형에 대해서는 티베트 검수 없는 거 아 당연히 선형이니까 여기도 마지막에 선형이야 그쵸 왜냐하면 여기는 그냥 값 나오는 것 자체를 이렇게 학습시키려고 하는 거니까 여기 이트레이션 션이 없어 리니어지 사실은 그렇죠 마지막이 그냥 가 가는 게 리니어잖아요.
여러분 이해됐어요. 여러분 됐죠 댄스 여기 얘 웨이트가 있어요 없어요.

참석자 1 41:55
여러분 데스 이거 있잖아요 얘 얘 웨이트가 있어 없어 여기 이 계층에 웨이트가 연결된 선들에 웨이트가 있냐 없냐 마지막에 여기 대서 64 나왔죠 64기가 쫙 나왔죠.
여기 이 마지막에 연결됐잖아요 그렇죠 하나 연결됐잖아요.
그럼 어떻게 되겠어요? 웨이트가 몇 개 있겠어 웨이트가 여기서 여기 여기 왜 여기 계층에 에이트가 몇 개 끼는데 요 계층에서 요 계층 넘어갈 때 선들 있잖아요.
65개 알겠죠? 그런 거 시험에 나와요. 알겠어요 65개 있지 왜 바이스 선호 얘기잖아요.
마지막에 선호 얘기하고 있잖아 알겠어요 여러분 알겠죠?
왜 여기 사정 회기하냐고 그냥 감내측하는 결구 선정 회계 같이 팔았어요.
그렇죠 결국 선정 회기했어요. 아지막에는 그 여 선정이 선형액이잖아요.
이건 마지막은 마지막은 선정액이라니까 여기는 비선형으로 막 따로따로 했는데 그렇죠 랠룰렐로 하면은 막 잘리잖아.

참석자 1 42:59
그렇죠 자라블 그쵸 여기는 그냥 했잖아요 그쵸 됐어요 그래요.
이래서 지금 뭐 했냐 지금 비교 공부를 했잖아. 그렇죠 공부할 때 여러분 이렇게 하셔야 돼.
그렇죠 앞에 거 아리까리 하면 다시 보면서 이렇게 막 비교하면서 공부하는 거 있죠 제가 여러분 고등학교 때 항상 전교 1등 했었고 거기 정무수석 합격한다고 맨날 정무수석해야 된다고 합격에서 이랬었거든요.
근데 공부하는 방법이 이렇게 달랐던 것 같아. 딴 사람 이렇게 공부 안 하더라고.
나 맨날 이렇게 공부했는데 아니 진짜로 공부 잘하는 비법은 빨리 공부하는 기법은 뭔가 다른 거 계속 비교하면서 공부하는 거예요.
여러분 그래서 이렇구나 하고 딱 차이점 생각하고 하고 뭐가 똑같은가 이런 거 있잖아요.

참석자 1 43:37
그쵸 선형 얘기 배웠는데 선영 얘기랑 이거랑 뭐가 다르지 이러면서 그렇죠 이거 공부해야 된다고 알겠죠 그래야지 뭔가 공부를 조금 하고 재미있고 그렇죠 그래서 내가 지금 얘기하는 거 여러분 시험 잘 보라고 공부할 때 이거 그냥 쫙 쫙쫙 공부하면 이게 뭐가 되겠냐고 그쵸 알겠죠 여러분 어떻게 공부하라는지 알지?
미니 배치가 좋은 것 같아요. 그렇죠 미니 배치하는데 데이터를 잘 섞어야 돼.
잘 그쵸 결론 결론 결론 지금 목차 그쵸 목차 되게 중요해.
목차 목차 엄청 중요해 그렇지 목차 왜 중요해요? 여기 목차가 여러분 뭘 다 보여주고 있잖아 문제에 대해서 그렇죠 그리고 교과서가 좋아야지.
여러분 교과서가 안 좋으면 여러분 공부안해도 소용이 없잖아.
이상한 책 갖고 와서 공부하면 여러분 또 이상해질 거 아니야 그쵸.
이상한 책 되게 많아요. 시중에 그래요. 그래서 이 책은 비싸지만 너무 비싸던데 그렇죠 그 마요.

참석자 1 44:30
3억 8천 원 진짜 비싸네 그래요. 여러분 그래서 우리 학교에서 딸 샀죠.
우리 이거 너무 비싸니까 안 살 것 같아가지고 제가 샀어요.
과에 가면 여러분 아직도 혀 있대 애들 보니까 자꾸 온라인으로 보는 거.
그쵸 어쨌든 샀어요. 그래서 지금 지금 5분 4분 남았는데 비교를 잘했고 여기 보면 여기 제가 히스토리 히스토리 이런 거 여러분들이 했던 거 기억나죠?
제가 강의 자료에 다 녹화했죠. 그쵸 이게 이거는 여러분 그냥 변수인데 이게 중요해요.
그쵸 그쵸 여러분 이거 시험에 나오겠어요 안 나오겠어요?
나와요. 알겠어요 여러분 이거 아는지 모르는지 오픈북으로는 낼 거예요.
이거 외우는 건 안 내는데 오픈북으로는 낸다고요 알겠죠?
제가 이거 시험 어떻게 보는지 얘기했나 안 했나 안 했군요.
지금 할게요.

참석자 1 45:17
그러 시험 보는 거에 대해서 시험을 여러분 미리 여러분 공부해야 되니까 이제 복습하시고 해야 되는데 아니 진도는 진도 어디까지 나갈 계획이냐면요.
여러분 7장까지 나가는 걸 목표로 하고 있어요. 넘어가지 다 거기까지 6장까지 확실히 나 7장 중간 정도까지 위에 금방 나가는 오늘 대략 오후장에 별로 내용이 없어요.
여러분 그냥 내가 해서 앞에 다 했던 거 그래서 5장이 휙 지나가고 실장 마지막 실적을 보내야지 그래서 지금 3분 남아서 애매해서 제가 중간고사 안내를 하면은 중간고사 안내를 할게요.
여러분 중간고사 중간고사는 당연히 이제 2시간짜리 이 시간에 여기 수요일 4월 23일 시간은 4월 23일 목요일 수요일이지 이 시간이 10시지 10시에서 당연히 볼 거고 그다음에 범위는 장소는 다 여기 장소는 여기고요.
30 중합 30이네. 그다음에 범위는 배운 거 다 드리고 그다음에 빨리 좀 구상하도 정확히 좀 적어줄게요.
그거 나중에 보세요.

참석자 1 46:36
제목은 아니고 아니 그러니까 저기 실제로 이제 여러분 잘해보자는 거지.
근데 이제 범 방식에 대해서 얘기하는 거예요. 방식 이게 한 시간 한 시간 나눠가지고 오픈 클로즈북 이 클래스도 그렇고 점수 매기기가 편해서 오픈북

참석자 1 47:02
오픈북을 지금 약간 고민하고 있어요. 이 클래스로 볼지 이 클래스로 볼지 정신이 없다고 그래가지고 자꾸 종이로 볼까 종이로 보면 점수 매기는 고통스러운데 아까 고민하고 있어요.
근데 또 오픈북 클로즈드 북 이렇게 한 50분씩 50분 보려고 그래요.
알겠죠 그래서 여러분 클로즈 오픈북에서 도대체 어떻게 하느냐 클로즈드 북 x x는 지금 오픈북인지 클로즈드 e 클래스인지 뭔지 몰랐어요.
채널 거도 거의 반반씩 볼 건데 필기를 미리 해와야 돼요.
여러분 책을 볼 수 있어요. 책을 책 보고 풀어도 돼요.
책 보고 풀어도 되고 인터넷이 끊긴 매체를 쓸 수도 있죠.
노트북이나 이런 거 쓸 수 있어요. 근데 화면을 사람들이 세워서 이렇게 아주 모범적인 사례 이렇게 보면 보면 안 되고 이렇게 안 되고 이렇게 왜냐하면 제가 보여야 되거든요.
화면이 비행기 모드로 그리고 만약에 통신하는 게 들켰다.
f 네.

참석자 1 48:04
콜앱을 와이파이 끊어놓고 사용하는 거 오케이 그니까 인터넷 안 된 상태 비행기 모드 와이파이가 되나 안 돼 안 돼요.
다 끊겨 다 끊기 좋다. 아예 그래요. 비행기 모드 인터넷에 연결하는 게 찍혔다.
애플 다른 불이익은 없어요. 반성문 이런 거 없어요.
알겠죠 그런 거 버터 교수 반성문 쓰게 하던데 나는 반성문 필요 없고 그냥 f 알겠죠 네 그래요.
어쨌든 뭐 굳이 그럴 필요 없다는 거죠

참석자 1 48:38
그래요. 그래서 지금 하여튼 강의 자료 설명하고 보이고 여기 시간이 좀 애매하네.
여기까지 합시다. 여러분 다음 시간에.


clovanote.naver.com