
문제를 해결하기 위한 3가지 전략
1. 처음부터 새로운 모델을 훈련시키는 것(맨땅에 해딩!!)
2. 사전 훈련된 모델을 사용해서 특성 추출하기
3. 사전 훈련된 모델 미세 조정하기(fine tunning)

- 8.2.1 작은 데이터셋 문제에서 딥러닝의 타당성 (맨땅에 해딩!!)
모델을 훈련하기에 '충분한 샘플'은 상대적이다.
모델이 작고 규제가 잘 되어 있으며 간단한 작업이면 수백개의 샘플로도 가능

- 8.2.2 데이터 내려받기
[코드8-6 이미지를 훈련, 검증, 테스트 디렉토리로 복사하기]
```python
import os, shutil, pathlib

original_dir = pathlib.Path("train")
new_base_dir = pathlib.Path("cats_vs_dogs_small")
def make_subset(subset_name, start_index, end_index):
	for category in ("cat", "dog"):
		dir = new_base_dir / subset_name / category
		os.makedirs(dir)
		fnames = [f"{category}.{i}.jpg" for i in range(start_index, end_index)]
		for fname in fnames:
			shutil.copyfile(src=original_dir / fname,
				dst=dir / fname)

make_subset("train", start_index=0, end_index=1000)
make_subset("validation", start_index=1000, end_index=1500)
make_subset("test", start_index=1500, end_index=2500)
```

- 8.2.3 모델 만들기

[코드8-7 강아지 vs. 고양이 분류를 위한 소규모 컨브넷 만들기]
```python
from tensorflow import keras
from tensorflow.keras import layers

inputs = keras.Input(shape=(180, 180, 3)) #(height, weight, channels -> RGB라 3) 
x = layers.Rescaling(1./255)(inputs)      #입력을 255로 나눠서 [0, 1]범위로 조정
x = layers.Conv2D(filters=32, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=64, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=128, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=256, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=256, kernel_size=3, activation="relu")(x)
x = layers.Flatten()(x)
outputs = layers.Dense(1, activation="sigmoid")(x)
model = keras.Model(inputs=inputs, outputs=outputs)
```
```
>>model.summary()

Model: "functional"

┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 180, 180, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ rescaling (Rescaling)           │ (None, 180, 180, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d (Conv2D)                 │ (None, 178, 178, 32)   │           896 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d (MaxPooling2D)    │ (None, 89, 89, 32)     │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_1 (Conv2D)               │ (None, 87, 87, 64)     │        18,496 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_1 (MaxPooling2D)  │ (None, 43, 43, 64)     │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_2 (Conv2D)               │ (None, 41, 41, 128)    │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_2 (MaxPooling2D)  │ (None, 20, 20, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_3 (Conv2D)               │ (None, 18, 18, 256)    │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_3 (MaxPooling2D)  │ (None, 9, 9, 256)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_4 (Conv2D)               │ (None, 7, 7, 256)      │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ flatten (Flatten)               │ (None, 12544)          │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 1)              │        12,545 │
└─────────────────────────────────┴────────────────────────┴───────────────┘

 Total params: 991,041 (3.78 MB)

 Trainable params: 991,041 (3.78 MB)

 Non-trainable params: 0 (0.00 B)
 ```
[코드8-8 모델 훈련 설정하기]
```python
model.compile(loss="binary_crossentropy",
			  optimizer="rmsprop",
			  metrics=["accuracy"])
```

- 8.2.4 데이터 전처리
전처리 하기 위한 과정
1. 사진 파일을 읽는다
2. JPEG 콘텐츠를 RGB 픽셀 값으로 디코딩한다.
3. 부동 소수점 타입의 텐서로 변환한다.
4. 동일한 크기의 이미지로 바꾼다.
5. 배치로 묶는다.

[코드8-9 `image_dataset_from_directory`를 사용하여 이미지 읽기]
```python
from tensorflow.keras.utils import image_dataset_from_directory

train_dataset = image_dataset_from_directory(
	new_base_dir / "train",       #훈련이미지 경로
	image_size=(180, 180),
	batch_size=32)
validation_dataset = image_dataset_from_directory(
	new_base_dir / "validation",  #검증이미지 경로
	image_size=(180, 180),
	batch_size=32)
test_dataset = image_dataset_from_directory(
	new_base_dir / "test",        #테스트이미지 경로
	image_size=(180, 180),
	batch_size=32)
```

[코드8-10 Dataset이 반환하는 데이터와 레이블 크기 확인하기]
```python
for data_batch, labels_batch in train_dataset:
	print("데이터 배치 크기",data_batchshape)
	print("라벨 배치 크기",lables_batchshape)
	break
데이터 배치 크기: (32, 180, 180, 3) #(batch_size, height, weight, channels) 
라벨 배치 크기: (32,) 

```
[코드8-11 Dataset을 사용하여 모델 훈련하기]
```python
callbacks = [
	keras.callbacks.ModelCheckpoin(
		filepath="convnet_from_scratch.keras",
		save_best_only=True,
		monitor="val_loss")
]
history = model.fit(
	train_dataset,
	epochs=30,
	validation_data=validation_dataset,
	callbacks=callbacks)
```

[코드8-12 훈련 정확도와 손실 그래프 그리기]
```python
import matplotlib.pyplot as plt

accuracy = history.history["accuracy"]
val_accuracy = history.history["val_accuracy"]
loss = history.history["loss"]
val_loss = history.history["val_loss"]
epochs = range(1, len(accuracy) + 1)
plt.plot(epochs, accuracy, "bo", label="Training accuracy")
plt.plot(epochs, val_accuracy, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.legend()
plt.figure()
plt.plot(epochs, loss, "bo", label="Training loss")
plt.plot(epochs, val_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.legend()
plt.show()
```

[코드8-13 테스트 세트에서 모델 평가하기]
```python
test_model = keras.models.load_model("convnet_from_scratch.h5")
test_loss, test_acc = test_model.evaluate(test_dataset)
print(f"테스트 정확도: {test_acc:.3f}")
```

- 8.2.5 데이터 증식 사용하기
[코드8-13 테스트 세트에서 모델 평가하기]
```python
test_model = keras.models.load_model("convnet_from_scratch.h5")
test_loss, test_acc = test_model.evaluate(test_dataset)
print(f"테스트 정확도: {test_acc:.3f}")
```

[코드8-14 컨브넷에 추가할 데이터 증식 단계 정의하기]
```python
data_augmentation = keras.Sequential(
	[
		layers.RandomFlit("horizontal"),  #랜덤하게 이미지를 수평으로 뒤집는다
		layers.RandomRotation(0.1),       #[-10%, +10%]범위 랜덤한 입력 이미지 회전
		layers.RandomZoom(0.2),           #[-20%, +20%]범위 랜덤한 입력 이미지 확대, 축소
	]
)
```
[코드8-15 랜덤하게 증식된 훈련 이미지 출력하기]
```python
plt.figure(figsize=(10, 10))
for images, _ in train_dataset.take(1):
	for i in range(9):
		augmented_images = data_argumentation(images) #배치 이미지에 데이터 증식 적용
		ax = plt.subplot(3, 3, i + 1)
		plt.imshow(augmented_images[0].numpy().astype("uint8"))
		plt.axis("off")
```

[코드8-16 이미지 증식과 드롭아웃을 포함한 컨브넷 만들기]
```python
inputs = keras.Input(shape=(180, 180, 3))  #(height, weight, channel)
x = data_augmentation(inputs)
x = layers.Rescaling(1./255)(x)
x = layers.Conv2D(filters=32, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=64, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=128, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=256, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=256, kernel_size=3, activation="relu")(x)
x = layers.Flatten()(x)
x = layers.Dropout(0.5)(x)
outputs = layers.Dense(1, activation="sigmoid")(x)
model = keras.Model(inputs=inputs, outputs=outputs)

model.compile(loss="binary_crossentropy",
optimizer="rmsprop",
metrics=["accuracy"])
```


[코드8-17 규제를 추가한 컨브넷 훈련하기]
```python
callbacks = [
	keras.callbacks.ModelCheckpoint(
		filepath="convnet_from_scratch_with_augmentation.h5",
		save_best_only=True,
		monitor="val_loss")
]
history = model.fit(
	train_dataset,
	epochs=100,
	validation_data=validation_dataset,
	callbacks=callbacks)
```

[코드8-18 테스트 세트에서 모델 훈련하기]
```python
test_model = keras.models.load_model(
	"convnet_from_scratch_with_augmentation.h5")
test_loss, test_acc = test_model.evaluate(test_dataset)
print(f"테스트 정확도: {test_acc:.3f}")
```

